{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b17de61be6664c0ba8cdb150b9667e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0673c62c3f24561b8b7f1d704e85b88",
              "IPY_MODEL_42655a53e2684b24a42f4bcf9807b2a1",
              "IPY_MODEL_cd8f9e62b9e94e6db667ebaf6d3ced84"
            ],
            "layout": "IPY_MODEL_cea7e4fa0d144c10acf406db9376a1ad"
          }
        },
        "f0673c62c3f24561b8b7f1d704e85b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a753e05b09d243fcab9028b634a33b86",
            "placeholder": "​",
            "style": "IPY_MODEL_3fcb0e7b14cb4f9cb7b951420eed67d7",
            "value": "config.json: 100%"
          }
        },
        "42655a53e2684b24a42f4bcf9807b2a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_905c8c6ae4884aba8fca1948eba3a433",
            "max": 1716,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12a5807daafb41eebefa9f1ab3f4284e",
            "value": 1716
          }
        },
        "cd8f9e62b9e94e6db667ebaf6d3ced84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e0f701df9a6448db95be60ddd4e1eb9",
            "placeholder": "​",
            "style": "IPY_MODEL_a98e5fb3019d4a6f91fcf5b89deb4a28",
            "value": " 1.72k/1.72k [00:00&lt;00:00, 44.9kB/s]"
          }
        },
        "cea7e4fa0d144c10acf406db9376a1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a753e05b09d243fcab9028b634a33b86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fcb0e7b14cb4f9cb7b951420eed67d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "905c8c6ae4884aba8fca1948eba3a433": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a5807daafb41eebefa9f1ab3f4284e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e0f701df9a6448db95be60ddd4e1eb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98e5fb3019d4a6f91fcf5b89deb4a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21b00fc5b3024bd4a723a8402a7551c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c13613114ce4efa85a9749c50c1ebe8",
              "IPY_MODEL_c7c7be7247d24b9fbbdddea5c264e370",
              "IPY_MODEL_76d0084cf8e84126b6b82f73059c16c2"
            ],
            "layout": "IPY_MODEL_40002a967c1d43c9bf4e751bce3cc248"
          }
        },
        "2c13613114ce4efa85a9749c50c1ebe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fd11f7b872c4ccabe4e03730a43fbad",
            "placeholder": "​",
            "style": "IPY_MODEL_dbb29dd55d8441f7936371fb813155a8",
            "value": "model.safetensors: 100%"
          }
        },
        "c7c7be7247d24b9fbbdddea5c264e370": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b6286e701b84854b2e78b62139c48cf",
            "max": 557709915,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ac1390d43f14d9ca2005507d9321c67",
            "value": 557709915
          }
        },
        "76d0084cf8e84126b6b82f73059c16c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14c2c3cd7c3d4b659ade0ac671ba0bc1",
            "placeholder": "​",
            "style": "IPY_MODEL_8d64c55289fb48948dbb37feec487e58",
            "value": " 558M/558M [00:03&lt;00:00, 147MB/s]"
          }
        },
        "40002a967c1d43c9bf4e751bce3cc248": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fd11f7b872c4ccabe4e03730a43fbad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbb29dd55d8441f7936371fb813155a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b6286e701b84854b2e78b62139c48cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac1390d43f14d9ca2005507d9321c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14c2c3cd7c3d4b659ade0ac671ba0bc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d64c55289fb48948dbb37feec487e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f2cf487ae5c438a9338faccff9c95ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_166e7731084145b09a0857cf7620caac",
              "IPY_MODEL_66401a5ca63543bab4c7da732a695333",
              "IPY_MODEL_b56dd0149ce74b0590fc95ec8b521452"
            ],
            "layout": "IPY_MODEL_b0b40ee0c6b54b10971a669c3b904065"
          }
        },
        "166e7731084145b09a0857cf7620caac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4832dad227954dc3a0951be99a8c333e",
            "placeholder": "​",
            "style": "IPY_MODEL_b4dbeff46ba642bf88f7905ef3d61898",
            "value": "vocab.json: 100%"
          }
        },
        "66401a5ca63543bab4c7da732a695333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67e7f227cbfd42eb98c7850b1a898bac",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8a24b2acefa4318881a8cc9b8cd2e29",
            "value": 898823
          }
        },
        "b56dd0149ce74b0590fc95ec8b521452": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1551571d98b0417aade431438d9b640f",
            "placeholder": "​",
            "style": "IPY_MODEL_e943167079e74db28bbb9609f0d0b019",
            "value": " 899k/899k [00:00&lt;00:00, 6.97MB/s]"
          }
        },
        "b0b40ee0c6b54b10971a669c3b904065": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4832dad227954dc3a0951be99a8c333e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4dbeff46ba642bf88f7905ef3d61898": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67e7f227cbfd42eb98c7850b1a898bac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8a24b2acefa4318881a8cc9b8cd2e29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1551571d98b0417aade431438d9b640f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e943167079e74db28bbb9609f0d0b019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "693f34ca28294a70bfa78ce9802ac431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ac87d14e8f84042ad0757141399f593",
              "IPY_MODEL_00068aea2e9542b189e0f40d7a19363b",
              "IPY_MODEL_366c94b6468a46979000de332f13a081"
            ],
            "layout": "IPY_MODEL_80c7df802779476fb0919973812c1d82"
          }
        },
        "8ac87d14e8f84042ad0757141399f593": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d2f8b72f61f4d3c8a939084fbd27586",
            "placeholder": "​",
            "style": "IPY_MODEL_bb71f37909144044826713d68b947f8a",
            "value": "merges.txt: 100%"
          }
        },
        "00068aea2e9542b189e0f40d7a19363b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5db16686ff534e248ca19e20ccd45568",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_355ba714cc7348e08dd005c39100f4e0",
            "value": 456318
          }
        },
        "366c94b6468a46979000de332f13a081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3e00108b5674d06b9ae61e384b3183e",
            "placeholder": "​",
            "style": "IPY_MODEL_f77c0806b5344d048211a6cb84777ea9",
            "value": " 456k/456k [00:00&lt;00:00, 5.19MB/s]"
          }
        },
        "80c7df802779476fb0919973812c1d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d2f8b72f61f4d3c8a939084fbd27586": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb71f37909144044826713d68b947f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5db16686ff534e248ca19e20ccd45568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355ba714cc7348e08dd005c39100f4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3e00108b5674d06b9ae61e384b3183e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f77c0806b5344d048211a6cb84777ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3e65a4f2a7048e4ab8f40e826af2627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1eeb41ee272544e6afc511e9287f2b04",
              "IPY_MODEL_1effb916d06440cd9f62b1b78b0ae400",
              "IPY_MODEL_1579c089dcd544baa3e8f155b521c1b2"
            ],
            "layout": "IPY_MODEL_04ec73cfa0b14eaf9632a954fea1dc27"
          }
        },
        "1eeb41ee272544e6afc511e9287f2b04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de700e303dd4462d98bd721e065ef383",
            "placeholder": "​",
            "style": "IPY_MODEL_26aa729ff5ba4a98a5cb287c83ebb921",
            "value": "tokenizer.json: 100%"
          }
        },
        "1effb916d06440cd9f62b1b78b0ae400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5737cbff42c04e01bd5edd2ef6a057ee",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab157b193db445939fe986b8119b927d",
            "value": 1355863
          }
        },
        "1579c089dcd544baa3e8f155b521c1b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a37f04148ed48f9905c0b271a394c37",
            "placeholder": "​",
            "style": "IPY_MODEL_c1381aec2a0a40498b44dfeb1f033336",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 22.4MB/s]"
          }
        },
        "04ec73cfa0b14eaf9632a954fea1dc27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de700e303dd4462d98bd721e065ef383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26aa729ff5ba4a98a5cb287c83ebb921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5737cbff42c04e01bd5edd2ef6a057ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab157b193db445939fe986b8119b927d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2a37f04148ed48f9905c0b271a394c37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1381aec2a0a40498b44dfeb1f033336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b09958f8937f447eb39e4e6de0f1ef68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8f88c8b9c5ac4d2ca429bde418befd7e",
              "IPY_MODEL_e96bfa4a29a44dcca4a68678ce963445",
              "IPY_MODEL_83dc353b8714437bb4d8e986df87df2a"
            ],
            "layout": "IPY_MODEL_778719b331f946f0b396afef9acb2cbb"
          }
        },
        "8f88c8b9c5ac4d2ca429bde418befd7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f631ee8a31945599eba06b95d7dc4c6",
            "placeholder": "​",
            "style": "IPY_MODEL_76389a9a64fc4c78bd8375267b1b57b8",
            "value": "Epoch 2: 100%"
          }
        },
        "e96bfa4a29a44dcca4a68678ce963445": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89d0ad51e66840a98d6856b171f1d0f9",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c126948088d148ffb89d66f2f50d4ab6",
            "value": 9
          }
        },
        "83dc353b8714437bb4d8e986df87df2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7d44d2f37a74ee8ae101096c9a30cf3",
            "placeholder": "​",
            "style": "IPY_MODEL_f8fd6c9eae6b42b095cdee2992bee2c4",
            "value": " 9/9 [02:41&lt;00:00,  0.06it/s, v_num=0, train_loss=1.580]"
          }
        },
        "778719b331f946f0b396afef9acb2cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "3f631ee8a31945599eba06b95d7dc4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76389a9a64fc4c78bd8375267b1b57b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "89d0ad51e66840a98d6856b171f1d0f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c126948088d148ffb89d66f2f50d4ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c7d44d2f37a74ee8ae101096c9a30cf3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8fd6c9eae6b42b095cdee2992bee2c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37b4f1f834db451d95d8dae6c3188845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_896b6ee30aa4459b9c93e83b3da7d797",
              "IPY_MODEL_cb2f321f848f495dbee41368bbc122d2",
              "IPY_MODEL_c0605bce7fe34c77a61b41fd9811ba62"
            ],
            "layout": "IPY_MODEL_3033681c75eb46ff8a2259ed714ec043"
          }
        },
        "896b6ee30aa4459b9c93e83b3da7d797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d57ac4186e694ff392d3eeb265e95250",
            "placeholder": "​",
            "style": "IPY_MODEL_4d162d7e5c7441769a878cad78812865",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "cb2f321f848f495dbee41368bbc122d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f4beb955875488d9ad923e1e018f182",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c09aaa4c4b344d395c835c60ddf9fbb",
            "value": 4
          }
        },
        "c0605bce7fe34c77a61b41fd9811ba62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78fb99caa71248aba864d5bdac801005",
            "placeholder": "​",
            "style": "IPY_MODEL_d69277f1f9af432487fd6b6a45d2e54f",
            "value": " 4/4 [01:42&lt;00:00,  0.04it/s]"
          }
        },
        "3033681c75eb46ff8a2259ed714ec043": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "d57ac4186e694ff392d3eeb265e95250": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d162d7e5c7441769a878cad78812865": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f4beb955875488d9ad923e1e018f182": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c09aaa4c4b344d395c835c60ddf9fbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78fb99caa71248aba864d5bdac801005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d69277f1f9af432487fd6b6a45d2e54f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c7b9d3bd67643cba62d37661b636f8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_588a8a13606b4821bdf5f8b2211bcdbc",
              "IPY_MODEL_b8841d131da24372bfbce33321305d26",
              "IPY_MODEL_118829ee509047ac9cd328a36a34c2ad"
            ],
            "layout": "IPY_MODEL_e27d4aaf0fbf4ee58dc0502297cbaaf9"
          }
        },
        "588a8a13606b4821bdf5f8b2211bcdbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74f9b98b98864440b63672c82fc39f97",
            "placeholder": "​",
            "style": "IPY_MODEL_d7aa374777884b3b9739daad7c55a858",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "b8841d131da24372bfbce33321305d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88b984a92e714065865000060675e515",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5518d6842df4b5686dbdda5ba0df7c7",
            "value": 4
          }
        },
        "118829ee509047ac9cd328a36a34c2ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3be97405278423686f2c1270c8daf94",
            "placeholder": "​",
            "style": "IPY_MODEL_17ba60fa441947b899bcbd7d5c388f82",
            "value": " 4/4 [01:32&lt;00:00,  0.04it/s]"
          }
        },
        "e27d4aaf0fbf4ee58dc0502297cbaaf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "74f9b98b98864440b63672c82fc39f97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7aa374777884b3b9739daad7c55a858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88b984a92e714065865000060675e515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5518d6842df4b5686dbdda5ba0df7c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f3be97405278423686f2c1270c8daf94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17ba60fa441947b899bcbd7d5c388f82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "019f59fd6a3c41e8a790fd0af102ee98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb6885d3a8624c2281ffbfa854afb3b3",
              "IPY_MODEL_efdd9718a4e54aa68422d33cfba2dbe7",
              "IPY_MODEL_561742723c8641b7b01118bb81bcdac4"
            ],
            "layout": "IPY_MODEL_7b477f76ee2346a18e0b494649532ee0"
          }
        },
        "bb6885d3a8624c2281ffbfa854afb3b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23ca8ba19fe44397a611cfcdb617bd28",
            "placeholder": "​",
            "style": "IPY_MODEL_070fd6b935504509bbb730efead75078",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "efdd9718a4e54aa68422d33cfba2dbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0bc5c15fea2437daf75a6801793355d",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eee20a77ccc641c3836217376ba27145",
            "value": 4
          }
        },
        "561742723c8641b7b01118bb81bcdac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3db3ad7c039745419bcab45fbaff8e15",
            "placeholder": "​",
            "style": "IPY_MODEL_2eb24e4bf4564c3fbc931939c2da5b13",
            "value": " 4/4 [01:19&lt;00:00,  0.05it/s]"
          }
        },
        "7b477f76ee2346a18e0b494649532ee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "23ca8ba19fe44397a611cfcdb617bd28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "070fd6b935504509bbb730efead75078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0bc5c15fea2437daf75a6801793355d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eee20a77ccc641c3836217376ba27145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3db3ad7c039745419bcab45fbaff8e15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb24e4bf4564c3fbc931939c2da5b13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Requirements"
      ],
      "metadata": {
        "id": "Lt6bG7Osr5kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score click keybert matplotlib nltk numpy optuna-integration pandas plotly python_Levenshtein pytorch_lightning rouge sacrebleu sacremoses spacy scikit_learn simalign stanfordnlp summarizer torch torchfile tqdm transformers yattag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAPdN-qWveJ1",
        "outputId": "ec084595-53f2-46f0-87ae-3d88427e7aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Collecting keybert\n",
            "  Downloading keybert-0.8.4.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting optuna-integration\n",
            "  Downloading optuna_integration-3.6.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.4/93.4 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Collecting python_Levenshtein\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.2-py3-none-any.whl (801 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.9/801.9 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting simalign\n",
            "  Downloading simalign-0.4-py3-none-any.whl (8.1 kB)\n",
            "Collecting stanfordnlp\n",
            "  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting summarizer\n",
            "  Downloading summarizer-0.0.7.tar.gz (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Collecting yattag\n",
            "  Downloading yattag-1.15.2.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.0)\n",
            "Collecting sentence-transformers>=0.3.8 (from keybert)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Collecting optuna (from optuna-integration)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Collecting Levenshtein==0.25.1 (from python_Levenshtein)\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python_Levenshtein)\n",
            "  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (3.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from simalign) (3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting alembic>=1.5.0 (from optuna->optuna-integration)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->optuna-integration)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.29)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->optuna-integration)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->optuna-integration) (3.0.3)\n",
            "Building wheels for collected packages: keybert, summarizer, torchfile, yattag\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.8.4-py3-none-any.whl size=39200 sha256=e626a292648c2ffbe2ab51732ca2758e7293a14194b1345eed47301d8f273911\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ef/4c/6588bd7072b0cc04225b40e639b991e49ebd4e21fb81f0acee\n",
            "  Building wheel for summarizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summarizer: filename=summarizer-0.0.7-py2.py3-none-any.whl size=284209 sha256=e1211ccf7dcbd9efcdf6de326e71a681478cd21ddbfa1df2d916a6d2bb1db8d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/bb/2d/1fe057c2f729818a5f28c312c3667e8b9d5cfd4af4a39895e7\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5693 sha256=da20c08edd133193a5eca89ccab0d5088171cb86d525743f2521f87968d38775\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/e9/87/1c51daf8e468d5c14931f8ac3344880f903ba96b063675cac2\n",
            "  Building wheel for yattag (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yattag: filename=yattag-1.15.2-py3-none-any.whl size=15668 sha256=b4b8faf4bc5fb1d0ffec40135d50bb4db7c590157b843bd7cd7fd29ed0a78958\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/6e/e5/d526243c27041915f63eacc0804babeb86b6973b0bc1991f06\n",
            "Successfully built keybert summarizer torchfile yattag\n",
            "Installing collected packages: yattag, torchfile, sacremoses, rouge, rapidfuzz, portalocker, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, lightning-utilities, colorlog, colorama, summarizer, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Levenshtein, alembic, python_Levenshtein, optuna, nvidia-cusolver-cu12, optuna-integration, torchmetrics, stanfordnlp, simalign, sentence-transformers, bert_score, pytorch_lightning, keybert\n",
            "Successfully installed Levenshtein-0.25.1 Mako-1.3.3 alembic-1.13.1 bert_score-0.3.13 colorama-0.4.6 colorlog-6.8.2 keybert-0.8.4 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 optuna-integration-3.6.0 portalocker-2.8.2 python_Levenshtein-0.25.1 pytorch_lightning-2.2.2 rapidfuzz-3.8.1 rouge-1.0.1 sacrebleu-2.4.2 sacremoses-0.1.1 sentence-transformers-2.7.0 simalign-0.4 stanfordnlp-0.2.0 summarizer-0.0.7 torchfile-0.1.0 torchmetrics-1.3.2 yattag-1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EASSE Library"
      ],
      "metadata": {
        "id": "BVbqZqwYr9m5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/feralvam/easse.git"
      ],
      "metadata": {
        "id": "d5zVHpYL2ftc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645d323a-49da-4c18-90b1-9a19b7ec344a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'easse'...\n",
            "remote: Enumerating objects: 1964, done.\u001b[K\n",
            "remote: Counting objects: 100% (145/145), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 1964 (delta 118), reused 104 (delta 104), pack-reused 1819\u001b[K\n",
            "Receiving objects: 100% (1964/1964), 33.15 MiB | 15.98 MiB/s, done.\n",
            "Resolving deltas: 100% (1231/1231), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/easse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGU2bo1e3N3-",
        "outputId": "91ee8ccd-1f16-414b-dacb-4ff7d516a707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/easse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYG6R4d53hCN",
        "outputId": "0f6ae543-65b9-44dc-deaa-82f034520fe6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/easse\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main (from easse==0.2.4)\n",
            "  Cloning https://github.com/facebookresearch/text-simplification-evaluation.git (to revision main) to /tmp/pip-install-_qoivg2q/tseval_ede213c3d72842658214ef7f9c5e5c2e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/text-simplification-evaluation.git /tmp/pip-install-_qoivg2q/tseval_ede213c3d72842658214ef7f9c5e5c2e\n",
            "  Resolved https://github.com/facebookresearch/text-simplification-evaluation.git to commit dea8863683ea5946fd50184883c9be7a7339e821\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (8.1.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (3.7.1)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (2.31.0)\n",
            "Requirement already satisfied: sacrebleu>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (2.4.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.1.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (1.2.2)\n",
            "Requirement already satisfied: stanfordnlp in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.2.0)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (4.66.2)\n",
            "Requirement already satisfied: yattag in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (1.15.2)\n",
            "Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (5.15.0)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.3.13)\n",
            "Requirement already satisfied: simalign in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->easse==0.2.4) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->easse==0.2.4) (2023.12.25)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->easse==0.2.4) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->easse==0.2.4) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (2024.2.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (4.9.4)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score->easse==0.2.4) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score->easse==0.2.4) (4.38.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->easse==0.2.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easse==0.2.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easse==0.2.4) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->easse==0.2.4) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->easse==0.2.4) (3.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from simalign->easse==0.2.4) (3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanfordnlp->easse==0.2.4) (3.20.3)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (from tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4) (0.25.1)\n",
            "Collecting gitpython (from tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m692.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->easse==0.2.4) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score->easse==0.2.4) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (0.4.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Levenshtein==0.25.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4) (0.25.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.25.1->python-Levenshtein->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4) (3.8.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score->easse==0.2.4) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score->easse==0.2.4) (1.3.0)\n",
            "Building wheels for collected packages: tseval\n",
            "  Building wheel for tseval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tseval: filename=tseval-1.0-py3-none-any.whl size=8522217 sha256=5d0a1ef73d23076e9a1f8bb7d6442be13f4a7be183c1fb88d6a0a9f4e01448ac\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0mjibo3w/wheels/89/be/e9/c9b30865c44c542db11cefa3afb9fb31d1f7136f5093d2e0b4\n",
            "Successfully built tseval\n",
            "Installing collected packages: smmap, gitdb, gitpython, tseval, easse\n",
            "  Running setup.py develop for easse\n",
            "Successfully installed easse-0.2.4 gitdb-4.0.11 gitpython-3.1.43 smmap-5.0.1 tseval-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqkHgWfp3qs9",
        "outputId": "a601f848-e974-4f40-ac8f-11bde0423d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "root_dir = '/content/'\n",
        "out_dir = os.path.join(root_dir, 'easse')\n",
        "inner_easse_dir = os.path.join(root_dir, 'easse', 'easse')\n",
        "\n",
        "if os.path.exists(out_dir):\n",
        "\n",
        "    # Move the contents of the inner easse folder back to 'easse'\n",
        "    if os.path.exists(inner_easse_dir):\n",
        "        inner_easse_files = os.listdir(inner_easse_dir)\n",
        "        for file in inner_easse_files:\n",
        "            src = os.path.join(inner_easse_dir, file)\n",
        "            dst = os.path.join(root_dir, 'easse', file)\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "        os.rmdir(inner_easse_dir)"
      ],
      "metadata": {
        "id": "N_9vBu1-_mX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessor"
      ],
      "metadata": {
        "id": "j8c9Pdrpzdoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optparse\n",
        "import os\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from functools import lru_cache\n",
        "from multiprocessing import Pool, Lock\n",
        "from string import punctuation\n",
        "import multiprocessing\n",
        "import Levenshtein\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "import shutil\n",
        "import time\n",
        "import pickle\n",
        "import hashlib\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sacremoses import MosesDetokenizer, MosesTokenizer\n",
        "\n",
        "\n",
        "EXP_DIR = '/content/experiments'\n",
        "DUMPS_DIR = '/content/dumps'\n",
        "\n",
        "PSAT = 'PSAT'\n",
        "\n",
        "LANGUAGES = ['complex', 'simple']\n",
        "PHASES = ['train','valid']\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "#######################\n",
        "def get_tokenizer():\n",
        "    return MosesTokenizer(lang='en')\n",
        "\n",
        "def get_detokenizer():\n",
        "    return MosesDetokenizer(lang='en')\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return get_tokenizer().tokenize(sentence)\n",
        "\n",
        "def write_lines(lines, filepath):\n",
        "    filepath = Path(filepath)\n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with filepath.open(\"w\") as fout:\n",
        "        for line in lines:\n",
        "            fout.write(line + '\\n')\n",
        "\n",
        "\n",
        "def read_lines(filepath):\n",
        "    return [line.rstrip() for line in yield_lines(filepath)]\n",
        "\n",
        "\n",
        "def yield_lines(filepath):\n",
        "    filepath = Path(filepath)\n",
        "    with filepath.open('r') as f:\n",
        "        for line in f:\n",
        "            yield line.rstrip()\n",
        "\n",
        "\n",
        "def yield_sentence_pair_with_index(filepath1, filepath2):\n",
        "    index = 0\n",
        "    with Path(filepath1).open('r') as f1, Path(filepath2).open('r') as f2:\n",
        "        for line1, line2 in zip(f1, f2):\n",
        "            index += 1\n",
        "            yield (line1.rstrip(), line2.rstrip(), index)\n",
        "\n",
        "\n",
        "def yield_sentence_pair(filepath1, filepath2):\n",
        "    with Path(filepath1).open('r') as f1, Path(filepath2).open('r') as f2:\n",
        "        for line1, line2 in zip(f1, f2):\n",
        "            yield line1.rstrip(), line2.rstrip()\n",
        "\n",
        "\n",
        "def count_line(filepath):\n",
        "    filepath = Path(filepath)\n",
        "    line_count = 0\n",
        "    with filepath.open(\"r\") as f:\n",
        "        for line in f:\n",
        "            line_count += 1\n",
        "    return line_count\n",
        "\n",
        "\n",
        "def load_dump(filepath):\n",
        "    return pickle.load(open(filepath, 'rb'))\n",
        "\n",
        "\n",
        "def dump(obj, filepath):\n",
        "    pickle.dump(obj, open(filepath, 'wb'))\n",
        "\n",
        "def save_preprocessor(preprocessor):\n",
        "    DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    PREPROCESSOR_DUMP_FILE = f'{DUMPS_DIR}/preprocessor.pickle'\n",
        "    dump(preprocessor, PREPROCESSOR_DUMP_FILE)\n",
        "\n",
        "\n",
        "def load_preprocessor():\n",
        "    PREPROCESSOR_DUMP_FILE = f'{DUMPS_DIR}/preprocessor.pickle'\n",
        "    if os.path.exists(PREPROCESSOR_DUMP_FILE):\n",
        "        return load_dump(PREPROCESSOR_DUMP_FILE)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def generate_hash(data):\n",
        "    h = hashlib.new('md5')\n",
        "    h.update(str(data).encode())\n",
        "    return h.hexdigest()\n",
        "\n",
        "def get_data_filepath(dataset, phase, type, i=None):\n",
        "    suffix = ''\n",
        "    if i is not None:\n",
        "        suffix = f'.{i}'\n",
        "    filename = f'{dataset}.{phase}.{type}{suffix}'\n",
        "    return f'/content/{dataset}/{filename}'\n",
        "\n",
        "#################################\n",
        "\n",
        "def round(val):\n",
        "    return '%.2f' % val\n",
        "\n",
        "\n",
        "def safe_division(a, b):\n",
        "    return a / b if b else 0\n",
        "\n",
        "\n",
        "# def tokenize(sentence):\n",
        "#     return sentence.split()\n",
        "\n",
        "def is_punctuation(word):\n",
        "    return ''.join([char for char in word if char not in punctuation]) == ''\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return ' '.join([word for word in tokenize(text) if not is_punctuation(word)])\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([w for w in tokenize(text) if w.lower() not in stopwords])\n",
        "\n",
        "\n",
        "def get_dependency_tree_depth(sentence):\n",
        "    def tree_height(node):\n",
        "        if len(list(node.children)) == 0:\n",
        "            return 0\n",
        "        return 1 + max(tree_height(child) for child in node.children)\n",
        "\n",
        "    tree_depths = [tree_height(spacy_sentence.root) for spacy_sentence in spacy_process(sentence).sents]\n",
        "    if len(tree_depths) == 0:\n",
        "        return 0\n",
        "    return max(tree_depths)\n",
        "\n",
        "def get_spacy_model():\n",
        "    model = 'en_core_web_sm'\n",
        "    if not spacy.util.is_package(model):\n",
        "        spacy.cli.download(model)\n",
        "        spacy.cli.link(model, model, force=True, model_path=spacy.util.get_package_path(model))\n",
        "    return spacy.load(model)\n",
        "\n",
        "\n",
        "def spacy_process(text):\n",
        "    return get_spacy_model()(str(text))\n",
        "\n",
        "\n",
        "def get_word2rank(vocab_size=np.inf):\n",
        "    model_filepath = f'{DUMPS_DIR}/{WORD_EMBEDDINGS_NAME}.pk'\n",
        "    if model_filepath.exists():\n",
        "        return load_dump(model_filepath)\n",
        "\n",
        "\n",
        "def get_normalized_rank(word):\n",
        "    max = len(get_word2rank())\n",
        "    rank = get_word2rank().get(word, max)\n",
        "    return np.log(1 + rank) / np.log(1 + max)\n",
        "\n",
        "\n",
        "\n",
        "def get_complexity_score2(sentence):\n",
        "    words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
        "    words = [word for word in words if word in get_word2rank()]  # remove unknown words\n",
        "    if len(words) == 0:\n",
        "        return 1.0\n",
        "    return np.array([get_normalized_rank(word) for word in words]).mean()\n",
        "\n",
        "def get_word_frequency():\n",
        "    model_filepath = f'{DUMPS_DIR}/{WORD_FREQUENCY_FILEPATH.stem}.pk'\n",
        "    if model_filepath.exists():\n",
        "        return load_dump(model_filepath)\n",
        "    else:\n",
        "        DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        word_freq = {}\n",
        "        for line in yield_lines(WORD_FREQUENCY_FILEPATH):\n",
        "            chunks = line.split(' ')\n",
        "            word = chunks[0]\n",
        "            freq = int(chunks[1])\n",
        "            word_freq[word] = freq\n",
        "        dump(word_freq, model_filepath)\n",
        "        return word_freq\n",
        "\n",
        "\n",
        "def get_normalized_inverse_frequency(word):\n",
        "    max = 153141437 # the 153141437, the max frequency\n",
        "    freq = get_word_frequency().get(word, 0)\n",
        "    return 1.0 - np.log(1 + freq) / np.log(1 + max)\n",
        "\n",
        "\n",
        "def get_complexity_score(sentence, operation_type = None):\n",
        "    words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
        "    #words = tokenize(remove_punctuation(sentence))\n",
        "    words = [word for word in words if word in get_word2rank()]  # remove unknown words\n",
        "    if len(words) == 0:\n",
        "        return 1.0\n",
        "    if operation_type == 'mean':\n",
        "        return np.array([get_normalized_inverse_frequency(word.lower()) for word in words]).mean()\n",
        "    else:\n",
        "        return np.array([get_normalized_inverse_frequency(word.lower()) for word in words]).max()\n",
        "\n",
        "class RatioFeature:\n",
        "    def __init__(self, feature_extractor, target_ratio=0.8):\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.target_ratio = target_ratio\n",
        "\n",
        "    def encode_sentence(self, sentence):\n",
        "        return f'{self.name}_{self.target_ratio}'\n",
        "\n",
        "    def encode_sentence_pair(self, complex_sentence, simple_sentence):\n",
        "        return f'{self.name}_{self.feature_extractor(complex_sentence, simple_sentence)}', simple_sentence\n",
        "\n",
        "    def decode_sentence(self, encoded_sentence):\n",
        "        return encoded_sentence\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        class_name = self.__class__.__name__.replace('RatioFeature', '')\n",
        "        name = \"\"\n",
        "        for word in re.findall('[A-Z][^A-Z]*', class_name):\n",
        "            if word: name += word[0]\n",
        "        if not name: name = class_name\n",
        "        return name\n",
        "\n",
        "### tokens features ###\n",
        "class WordRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_word_length_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_word_length_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(safe_division(len(tokenize(simple_sentence)), len(tokenize(complex_sentence))))\n",
        "\n",
        "\n",
        "class CharRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_char_length_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_char_length_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(safe_division(len(simple_sentence), len(complex_sentence)))\n",
        "\n",
        "\n",
        "class LevenshteinRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_levenshtein_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_levenshtein_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(Levenshtein.ratio(complex_sentence, simple_sentence))\n",
        "\n",
        "\n",
        "class WordRankRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_word_rank_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_word_rank_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(min(safe_division(self.get_lexical_complexity_score(simple_sentence),\n",
        "                                       self.get_lexical_complexity_score(complex_sentence)), 2))\n",
        "\n",
        "    def get_lexical_complexity_score(self, sentence):\n",
        "        words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
        "        words = [word for word in words if word in get_word2rank()]\n",
        "        if len(words) == 0:\n",
        "            return np.log(1 + len(get_word2rank()))\n",
        "        return np.quantile([self.get_rank(word) for word in words], 0.75)\n",
        "\n",
        "\n",
        "    def get_rank(self, word):\n",
        "        # return get_normalized_inverse_frequency(word)\n",
        "        rank = get_word2rank().get(word, len(get_word2rank()))\n",
        "        return np.log(1 + rank)\n",
        "\n",
        "\n",
        "class DependencyTreeDepthRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_dependency_tree_depth_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_dependency_tree_depth_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(\n",
        "            safe_division(self.get_dependency_tree_depth(simple_sentence),\n",
        "                          self.get_dependency_tree_depth(complex_sentence)))\n",
        "\n",
        "\n",
        "    def get_dependency_tree_depth(self, sentence):\n",
        "        def get_subtree_depth(node):\n",
        "            if len(list(node.children)) == 0:\n",
        "                return 0\n",
        "            return 1 + max([get_subtree_depth(child) for child in node.children])\n",
        "\n",
        "        tree_depths = [get_subtree_depth(spacy_sentence.root) for spacy_sentence in self.spacy_process(sentence).sents]\n",
        "        if len(tree_depths) == 0:\n",
        "            return 0\n",
        "        return max(tree_depths)\n",
        "\n",
        "    def spacy_process(self, text):\n",
        "        return get_spacy_model()(text)\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self, features_kwargs=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = self.get_features(features_kwargs)\n",
        "        if features_kwargs:\n",
        "            self.hash = generate_hash(str(features_kwargs).encode())\n",
        "        else:\n",
        "            self.hash = \"no_feature\"\n",
        "\n",
        "    def get_class(self, class_name, *args, **kwargs):\n",
        "        return globals()[class_name](*args, **kwargs)\n",
        "\n",
        "    def get_features(self, feature_kwargs):\n",
        "        features = []\n",
        "        for feature_name, kwargs in feature_kwargs.items():\n",
        "            features.append(self.get_class(feature_name, **kwargs))\n",
        "        return features\n",
        "\n",
        "    def encode_sentence(self, sentence):\n",
        "        if self.features:\n",
        "            line = ''\n",
        "            for feature in self.features:\n",
        "                line += feature.encode_sentence(sentence) + ' '\n",
        "            line += ' ' + sentence\n",
        "            return line.rstrip()\n",
        "        else:\n",
        "            return sentence\n",
        "\n",
        "    def encode_sentence_pair(self, complex_sentence, simple_sentence):\n",
        "        # print(complex_sentence)\n",
        "        if self.features:\n",
        "            line = ''\n",
        "            for feature in self.features:\n",
        "                # startTime = timeit.default_timer()\n",
        "                # print(feature)\n",
        "                processed_complex, _ = feature.encode_sentence_pair(complex_sentence, simple_sentence)\n",
        "                line += processed_complex + ' '\n",
        "                # print(feature, timeit.default_timer() - startTime)\n",
        "            line += ' ' + complex_sentence\n",
        "            return line.rstrip()\n",
        "\n",
        "        else:\n",
        "            return complex_sentence\n",
        "\n",
        "    def decode_sentence(self, encoded_sentence):\n",
        "        for feature in self.features:\n",
        "            decoded_sentence = feature.decode_sentence(encoded_sentence)\n",
        "        return decoded_sentence\n",
        "\n",
        "    def encode_file(self, input_filepath, output_filepath):\n",
        "        with open(output_filepath, 'w') as f:\n",
        "            for line in yield_lines(input_filepath):\n",
        "                f.write(self.encode_sentence(line) + '\\n')\n",
        "\n",
        "    def decode_file(self, input_filepath, output_filepath):\n",
        "        with open(output_filepath, 'w') as f:\n",
        "            for line in yield_lines(input_filepath):\n",
        "                f.write(self.decode_sentence(line) + '\\n')\n",
        "\n",
        "    def process_encode_sentence_pair(self, sentences):\n",
        "        print(f\"{sentences[2]}/{self.line_count}\", sentences[0])  # sentence[0] index\n",
        "        return (self.encode_sentence_pair(sentences[0], sentences[1]))\n",
        "\n",
        "    def pool_encode_sentence_pair(self, args):\n",
        "        # print(f\"{processed_line_count}/{self.line_count}\")\n",
        "        complex_sent, simple_sent, queue = args\n",
        "        queue.put(1)\n",
        "        return self.encode_sentence_pair(complex_sent, simple_sent)\n",
        "\n",
        "\n",
        "    def encode_file_pair(self, complex_filepath, simple_filepath):\n",
        "        processed_complex_sentences = []\n",
        "        self.line_count = count_line(simple_filepath)\n",
        "\n",
        "        i = 0\n",
        "        for complex_sentence, simple_sentence in yield_sentence_pair(complex_filepath, simple_filepath):\n",
        "        # print(complex_sentence)\n",
        "            processed_complex_sentence = self.encode_sentence_pair(complex_sentence, simple_sentence)\n",
        "            i +=1\n",
        "            print(f\"{i}/{self.line_count}\", processed_complex_sentence)\n",
        "            processed_complex_sentences.append(processed_complex_sentence)\n",
        "\n",
        "        return processed_complex_sentences\n",
        "\n",
        "    def get_preprocessed_filepath(self, dataset, phase, type):\n",
        "        filename = f'{dataset}.{phase}.{type}'\n",
        "        return f'{self.preprocessed_data_dir}/{filename}'\n",
        "\n",
        "    def preprocess_dataset(self, dataset):\n",
        "        # download_requirements()\n",
        "        self.preprocessed_data_dir = f'{PROCESSED_DATA_DIR}/{self.hash}/{dataset}'\n",
        "        #self.preprocessed_data_dir.mkdir(parents=True, exist_ok=True)\n",
        "        os.makedirs(self.preprocessed_data_dir, exist_ok=True)\n",
        "        save_preprocessor(self)\n",
        "        print(f'Preprocessing dataset: {dataset}')\n",
        "\n",
        "        for phase in PHASES:\n",
        "            # for phase in [\"valid\", \"test\"]:\n",
        "            complex_filepath = get_data_filepath(dataset, phase, 'complex')\n",
        "            simple_filepath = get_data_filepath(dataset, phase, 'simple')\n",
        "\n",
        "            complex_output_filepath = f'{self.preprocessed_data_dir}/{complex_filepath.name}'\n",
        "            simple_output_filepath = f'{self.preprocessed_data_dir}/{simple_filepath.name}'\n",
        "            if complex_output_filepath.exists() and simple_output_filepath.exists():\n",
        "                continue\n",
        "\n",
        "            print(f'Prepocessing files: {complex_filepath.name} {simple_filepath.name}')\n",
        "            processed_complex_sentences = self.encode_file_pair(complex_filepath, simple_filepath)\n",
        "\n",
        "            write_lines(processed_complex_sentences, complex_output_filepath)\n",
        "            shutil.copy(simple_filepath, simple_output_filepath)\n",
        "\n",
        "        print(f'Preprocessing dataset \"{dataset}\" is finished.')\n",
        "        return self.preprocessed_data_dir\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    features_kwargs = {\n",
        "        # 'WordRatioFeature': {'target_ratio': 0.8},\n",
        "        'CharRatioFeature': {'target_ratio': 0.8},\n",
        "        'LevenshteinRatioFeature': {'target_ratio': 0.8},\n",
        "        'WordRankRatioFeature': {'target_ratio': 0.8},\n",
        "        'DependencyTreeDepthRatioFeature': {'target_ratio': 0.8}\n",
        "    }\n",
        "\n",
        "    preprocessor = load_preprocessor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifsZllxTw_41",
        "outputId": "4eb9762d-21b3-42e5-e048-6b46852e5251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimSum BART Model"
      ],
      "metadata": {
        "id": "agAqxZaaWLR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import lru_cache\n",
        "from gc import callbacks\n",
        "from lib2to3.pgen2 import token\n",
        "from pathlib import Path\n",
        "from weakref import ref\n",
        "import math\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from easse.sari import corpus_sari\n",
        "from torch.nn import functional as F\n",
        "import Levenshtein\n",
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "import nltk\n",
        "from summarizer import Summarizer\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.trainer import seed_everything\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast,\n",
        "    BertTokenizer, BertForPreTraining,\n",
        "    BartForConditionalGeneration, BartTokenizer,pipeline,BartTokenizerFast, BartModel,\n",
        "    get_linear_schedule_with_warmup, AutoConfig, AutoModel,\n",
        "    get_cosine_schedule_with_warmup\n",
        ")\n",
        "\n",
        "#BERT_Sum = Summarizer(model='distilbert-base-uncased')\n",
        "\n",
        "class MetricsCallback(pl.Callback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.metrics = []\n",
        "\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "      self.metrics.append(trainer.callback_metrics)\n",
        "\n",
        "### Special tokens\n",
        "def char_ratio(complex_sentence, simple_sentence):\n",
        "    return round(safe_division(len(simple_sentence), len(complex_sentence)))\n",
        "\n",
        "\n",
        "def LevSim(complex_sentence, simple_sentence):\n",
        "    return round(Levenshtein.ratio(complex_sentence, simple_sentence))\n",
        "\n",
        "def word_rank_ratio(complex_sentence, simple_sentence):\n",
        "    def get_rank(word):\n",
        "        rank = get_word2rank().get(word, len(get_word2rank()))\n",
        "        return np.log(1+rank)\n",
        "\n",
        "    def get_lexical_complexity_score(sentence):\n",
        "        words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
        "        words = [word for word in words if word in get_word2rank()]\n",
        "        if len(words)==0:\n",
        "            return np.log(1+len(get_word2rank()))\n",
        "        return np.quantile([get_rank(word) for word in words], 0.75)\n",
        "\n",
        "    return round(min(safe_division(\n",
        "        get_lexical_complexity_score(simple_sentence),\n",
        "        get_lexical_complexity_score(complex_sentence)\n",
        "    ), 2))\n",
        "### Special tokens end\n",
        "\n",
        "class SumSim(pl.LightningModule):\n",
        "    def __init__(self,args):\n",
        "        super(SumSim, self).__init__()\n",
        "        self.args = args\n",
        "        self.save_hyperparameters()\n",
        "        # Load pre-trained model and tokenizer\n",
        "        self.summarizer = BartForConditionalGeneration.from_pretrained(self.args.sum_model)\n",
        "        self.summarizer_tokenizer = BartTokenizerFast.from_pretrained(self.args.sum_model)\n",
        "        self.summarizer = self.summarizer.to(self.args.device)\n",
        "        # print(self.summarizer)\n",
        "\n",
        "        self.simplifier = BartForConditionalGeneration.from_pretrained(self.args.sim_model)\n",
        "        self.simplifier_tokenizer = BartTokenizerFast.from_pretrained(self.args.sim_model)\n",
        "        self.simplifier = self.simplifier.to(self.args.device)\n",
        "        # print(self.simplifier)\n",
        "\n",
        "    def is_logger(self):\n",
        "        return self.trainer.global_rank <= 0\n",
        "\n",
        "    def forward(self, input_ids,\n",
        "    attention_mask = None,\n",
        "    decoder_input_ids = None,\n",
        "    decoder_attention_mask = None, labels = None):\n",
        "\n",
        "        outputs = self.simplifier(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_input_ids = decoder_input_ids,\n",
        "            decoder_attention_mask =  decoder_attention_mask,\n",
        "            labels = labels\n",
        "        )\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        source = batch[\"source\"]\n",
        "        labels = batch['target_ids']\n",
        "        labels[labels[:,:] == self.simplifier_tokenizer.pad_token_id] = -100\n",
        "        # zero the gradient buffers of all parameters\n",
        "        self.opt.zero_grad()\n",
        "        #print(source, len(source))\n",
        "        ## summarizer stage\n",
        "        inputs = self.summarizer_tokenizer(\n",
        "            source,\n",
        "            max_length = 512,\n",
        "            truncation = True,\n",
        "            padding = 'max_length',\n",
        "            return_tensors = 'pt'\n",
        "        ).to(self.args.device)\n",
        "\n",
        "\n",
        "        src_ids = inputs['input_ids'].to(self.args.device)\n",
        "        src_mask = inputs['attention_mask'].to(self.args.device)\n",
        "\n",
        "\n",
        "        # compute the loss between summarization and simplification target\n",
        "        # sum_outputs.loss\n",
        "\n",
        "        sum_outputs = self.summarizer(\n",
        "            input_ids = src_ids,\n",
        "            attention_mask  = src_mask,\n",
        "            labels = labels,\n",
        "            decoder_attention_mask = batch['target_mask']\n",
        "        )\n",
        "\n",
        "        #H1 = sum_outputs.encoder_last_hidden_state\n",
        "\n",
        "        # generate summary\n",
        "        summary_ids = self.summarizer.generate(\n",
        "            inputs['input_ids'].to(self.args.device),\n",
        "            num_beams = 5,\n",
        "            min_length = 10,\n",
        "            max_length = 256,\n",
        "            top_k=120,top_p=0.95,\n",
        "        ).to(self.args.device)\n",
        "\n",
        "        ### Original loss\n",
        "        summary_attention_mask = torch.ones(summary_ids.shape).to(self.args.device)\n",
        "        summary_attention_mask[summary_ids[:,:]==self.summarizer_tokenizer.pad_token_id]=0\n",
        "\n",
        "        sim_outputs  = self(\n",
        "            input_ids = summary_ids,\n",
        "            attention_mask = summary_attention_mask,\n",
        "            labels = labels,\n",
        "            decoder_attention_mask = batch['target_mask']\n",
        "        )\n",
        "\n",
        "        ### modified loss\n",
        "        # padded_summary_ids = torch.zeros((summary_ids.shape[0], 256), dtype=torch.long).fill_(self.simplifier_tokenizer.pad_token_id).to(self.args.device)\n",
        "\n",
        "        # for i, summary_id in enumerate(summary_ids):\n",
        "        #     padded_summary_ids[i, :summary_id.shape[0]] = summary_id\n",
        "\n",
        "        # summary_attention_mask = torch.ones(padded_summary_ids.shape).to(self.args.device)\n",
        "        # summary_attention_mask[padded_summary_ids[:,:]==self.summarizer_tokenizer.pad_token_id]=0\n",
        "\n",
        "\n",
        "\n",
        "        # # forward pass\n",
        "        # sim_outputs  = self(\n",
        "        #     input_ids = padded_summary_ids,\n",
        "        #     attention_mask = summary_attention_mask,\n",
        "        #     labels = labels,\n",
        "        #     decoder_attention_mask = batch['target_mask']\n",
        "        # )\n",
        "\n",
        "        #H2 = sim_outputs.encoder_last_hidden_state\n",
        "\n",
        "        ## CosSim\n",
        "        # Rep1 = torch.matmul(H1, self.W)\n",
        "        # Rep2 = torch.matmul(H2, self.W)\n",
        "        # Rep1 = self.relu(Rep1)\n",
        "        # Rep2 = self.relu(Rep2)\n",
        "        # CosSim = nn.CosineSimilarity(dim=2, eps=1e-6)\n",
        "        # sim_score = CosSim(Rep1, Rep2)\n",
        "\n",
        "        ## KL loss\n",
        "        # H1 = torch.transpose((torch.transpose(H1, 1,2)@self.Q), 1,2)\n",
        "        # H2 = torch.transpose((torch.transpose(H2, 1,2)@self.Q), 1,2)\n",
        "        # Rep1 = torch.matmul(H1, self.W)\n",
        "        # Rep2 = torch.matmul(H2, self.W)\n",
        "        # Rep1 = Rep1.squeeze(dim=2)\n",
        "        # Rep2 = Rep2.squeeze(dim=2)\n",
        "        # LogSoftMax = nn.LogSoftmax(dim=1)\n",
        "        # Rep1 = LogSoftMax(Rep1)\n",
        "        # Rep2 = LogSoftMax(Rep2)\n",
        "\n",
        "        if self.args.custom_loss:\n",
        "            '''\n",
        "            Custom Loss:\n",
        "            Loss = original_loss + lambda**2 * complexity_score\n",
        "\n",
        "            - ratio: control the ratio of sentences we want to compute complexity for training.\n",
        "            - lambda: control the weight of the complexity loss.\n",
        "            '''\n",
        "            loss = sim_outputs.loss * self.args.w1\n",
        "            #loss += sum_outputs.loss * self.args.w2\n",
        "            ### KL ###\n",
        "            #loss += (self.args.lambda_ * self.kl_loss(Rep1, Rep2))\n",
        "\n",
        "            ### CosSim ###\n",
        "            #loss += (-self.args.lambda_ * (sim_score.mean(dim=1).mean(dim=0)))\n",
        "\n",
        "\n",
        "            # self.manual_backward(loss)\n",
        "            # self.opt.step()\n",
        "\n",
        "            self.log('train_loss', sim_outputs.loss, on_step=True, prog_bar=True, logger=True)\n",
        "            # print(loss)\n",
        "            return loss\n",
        "        else:\n",
        "            loss = sim_outputs.loss\n",
        "            self.log('train_loss', loss, on_step=True, prog_bar=True, logger=True)\n",
        "            #print(loss)\n",
        "            return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.sari_validation_step(batch)\n",
        "        # loss = self._step(batch)\n",
        "        print(\"Val_loss\", loss)\n",
        "        logs = {\"val_loss\": loss}\n",
        "\n",
        "        self.log('val_loss', loss, batch_size = self.args.valid_batch_size)\n",
        "        return torch.tensor(loss, dtype=float)\n",
        "\n",
        "    def sari_validation_step(self, batch):\n",
        "        def generate(sentence):\n",
        "\n",
        "            text = sentence\n",
        "            # summarize the document\n",
        "            inputs = self.summarizer_tokenizer(\n",
        "            [text],\n",
        "            max_length = 512,\n",
        "            truncation = True,\n",
        "            padding = 'max_length',\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "            # generate summary\n",
        "            summary_ids = self.summarizer.generate(\n",
        "                inputs['input_ids'].to(self.args.device),\n",
        "                num_beams = 5,\n",
        "                min_length = 10,\n",
        "                max_length = 256,\n",
        "                top_k = 120, top_p = 0.95,\n",
        "            ).to(self.args.device)\n",
        "\n",
        "            summary_attention_mask = torch.ones(summary_ids.shape).to(self.args.device)\n",
        "            summary_attention_mask[summary_ids==self.summarizer_tokenizer.pad_token_id]=0\n",
        "\n",
        "\n",
        "            # set top_k = 130 and set top_p = 0.95 and num_return_sequences = 1\n",
        "            beam_outputs = self.simplifier.generate(\n",
        "                input_ids=summary_ids,\n",
        "                attention_mask=summary_attention_mask,\n",
        "                do_sample=True,\n",
        "                max_length=self.args.max_seq_length,\n",
        "                num_beams=5,\n",
        "                top_k=130,\n",
        "                top_p=0.95,\n",
        "                early_stopping=True,\n",
        "                num_return_sequences=1\n",
        "            ).to(self.device)\n",
        "            # final_outputs = []\n",
        "            # for beam_output in beam_outputs:\n",
        "\n",
        "            sent = self.simplifier_tokenizer.decode(beam_outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "            # if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "                # final_outputs.append(sent)\n",
        "\n",
        "            return sent\n",
        "\n",
        "        pred_sents = []\n",
        "        for source in batch[\"source\"]:\n",
        "            pred_sent = generate(source)\n",
        "            pred_sents.append(pred_sent)\n",
        "\n",
        "        ### WIKI-large ###\n",
        "        score = corpus_sari(batch[\"source\"], pred_sents, [batch[\"targets\"]])\n",
        "\n",
        "        ### turkcorpuse ###\n",
        "        #score = corpus_sari(batch[\"source\"], pred_sents, batch[\"targets\"])\n",
        "\n",
        "        print(\"Sari score: \", score)\n",
        "\n",
        "        return 1 - score / 100\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "        model1 = self.summarizer\n",
        "        model2 = self.simplifier\n",
        "        #no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n,p in model1.named_parameters()]\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n,p in model2.named_parameters()]\n",
        "            },\n",
        "            # {\n",
        "            #     \"params\": self.W\n",
        "            # },\n",
        "            # {\n",
        "            #     \"params\": self.Q\n",
        "            # },\n",
        "            # {\n",
        "            #     \"params\": self.W2\n",
        "            # }\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
        "        self.opt = optimizer\n",
        "        return [optimizer]\n",
        "\n",
        "    def optimizer_step(self, epoch=None, batch_idx=None, optimizer=None,optimizer_closure=None):\n",
        "        optimizer.step(closure=optimizer_closure)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        self.lr_scheduler.step()\n",
        "\n",
        "    def save_core_model(self):\n",
        "      tmp = self.args.model_name + 'core'\n",
        "      store_path = f'/content/experiments/{tmp}'\n",
        "      self.model.save_pretrained(store_path)\n",
        "      self.simplifier_tokenizer.save_pretrained(store_path)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_dataset = TrainDataset(dataset=self.args.dataset,\n",
        "                                     tokenizer=self.simplifier_tokenizer,\n",
        "                                     max_len=self.args.max_seq_length,\n",
        "                                     sample_size=self.args.train_sample_size)\n",
        "\n",
        "        dataloader = DataLoader(train_dataset,\n",
        "                                batch_size=self.args.train_batch_size,\n",
        "                                drop_last=True,\n",
        "                                shuffle=True,\n",
        "                                pin_memory=True,\n",
        "                                num_workers=2)\n",
        "        t_total = ((len(dataloader.dataset) // (self.args.train_batch_size * max(1, self.args.n_gpu)))\n",
        "                   // self.args.gradient_accumulation_steps\n",
        "                   * float(self.args.num_train_epochs)\n",
        "                   )\n",
        "        # scheduler = get_linear_schedule_with_warmup(\n",
        "        #     self.opt, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total\n",
        "        # )\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            self.opt, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total\n",
        "        )\n",
        "        self.lr_scheduler = scheduler\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        val_dataset = ValDataset(dataset=self.args.dataset,\n",
        "                                 tokenizer=self.simplifier_tokenizer,\n",
        "                                 max_len=self.args.max_seq_length,\n",
        "                                 sample_size=self.args.valid_sample_size)\n",
        "        return DataLoader(val_dataset,\n",
        "                          batch_size=self.args.valid_batch_size,\n",
        "                          num_workers=2)\n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parent_parser):\n",
        "      p = ArgumentParser(parents=[parent_parser],add_help = False)\n",
        "      p.add_argument('-HiddenSize','--hidden_size',type=int, default = 1)\n",
        "      p.add_argument('-SeqDim','--seq_dim', type=int, default = 512)\n",
        "      p.add_argument('-Weight1', '--w1', type = int, default = 1)\n",
        "      p.add_argument('-Weight2', '--w2', type = int, default = 1)\n",
        "      p.add_argument('-Lambda', '--lambda_', type = int, default = 11)\n",
        "      p.add_argument('-Summarizer','--sum_model', default='facebook/bart-base')\n",
        "      p.add_argument('-Simplifier','--sim_model', default='facebook/bart-base')\n",
        "      p.add_argument('-TrainBS','--train_batch_size',type=int, default=6)\n",
        "      p.add_argument('-ValidBS','--valid_batch_size',type=int, default=6)\n",
        "      p.add_argument('-lr','--learning_rate',type=float, default=5e-5)\n",
        "      p.add_argument('-MaxSeqLen','--max_seq_length',type=int, default=256)\n",
        "      p.add_argument('-AdamEps','--adam_epsilon', default=1e-8)\n",
        "      p.add_argument('-WeightDecay','--weight_decay', default = 0.0001)\n",
        "      p.add_argument('-WarmupSteps','--warmup_steps',default=5)\n",
        "      p.add_argument('-NumEpoch','--num_train_epochs',default=3)\n",
        "      p.add_argument('-CosLoss','--custom_loss', default=False)\n",
        "      p.add_argument('-GradAccuSteps','--gradient_accumulation_steps', default=1)\n",
        "      p.add_argument('-GPUs','--n_gpu',default=torch.cuda.device_count())\n",
        "      p.add_argument('-nbSVS','--nb_sanity_val_steps',default = -1)\n",
        "      p.add_argument('-TrainSampleSize','--train_sample_size', default=1)\n",
        "      p.add_argument('-ValidSampleSize','--valid_sample_size', default=1)\n",
        "      p.add_argument('-device','--device', default = 'cuda')\n",
        "      #p.add_argument('-NumBeams','--num_beams', default=8)\n",
        "      return p\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        logger.info(\"***** Validation results *****\")\n",
        "        print(\"***** Validation results *****\")\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "            # Log results\n",
        "            for key in sorted(metrics):\n",
        "                print(key, metrics[key])\n",
        "                if key not in [\"log\", \"progress_bar\"]:\n",
        "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                    print(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "    def on_test_end(self, trainer, pl_module):\n",
        "        logger.info(\"***** Test results *****\")\n",
        "        print(\"***** Test results *****\")\n",
        "\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "\n",
        "            # Log and save results to file\n",
        "            output_test_results_file = os.path.join(pl_module.args.output_dir, \"test_results.txt\")\n",
        "            with open(output_test_results_file, \"w\") as writer:\n",
        "                for key in sorted(metrics):\n",
        "                    if key not in [\"log\", \"progress_bar\"]:\n",
        "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                        print(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "\n",
        "##### build dataset Loader #####\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_len=256, sample_size=1):\n",
        "        self.sample_size = sample_size\n",
        "        print(\"init TrainDataset ...\")\n",
        "        self.source_filepath = get_data_filepath(dataset,'train','complex')\n",
        "        self.target_filepath = get_data_filepath(dataset,'train','simple')\n",
        "        print(\"Initialized dataset done.....\")\n",
        "        # preprocessor = load_preprocessor()\n",
        "        # self.source_filepath = preprocessor.get_preprocessed_filepath(dataset, 'train', 'complex')\n",
        "        # self.target_filepath = preprocessor.get_preprocessed_filepath(dataset, 'train', 'simple')\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        self.inputs = read_lines(self.source_filepath)\n",
        "        self.targets = read_lines(self.target_filepath)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.inputs) * self.sample_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source = self.inputs[index]\n",
        "        # source = \"summarize: \" + self.inputs[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        tokenized_inputs = self.tokenizer(\n",
        "            [source],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        tokenized_targets = self.tokenizer(\n",
        "            [target],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        source_ids = tokenized_inputs[\"input_ids\"].squeeze()\n",
        "        target_ids = tokenized_targets[\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = tokenized_inputs[\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "        target_mask = tokenized_targets[\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask,\n",
        "                'sources': self.inputs[index], 'targets': [self.targets[index]],\n",
        "                'source': source, 'target': target}\n",
        "\n",
        "\n",
        "class ValDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_len=256, sample_size=1):\n",
        "        self.sample_size = sample_size\n",
        "        ### WIKI-large dataset ###\n",
        "        self.source_filepath = get_data_filepath(dataset, 'valid', 'complex')\n",
        "        self.target_filepaths = get_data_filepath(dataset, 'valid', 'simple')\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.inputs) * self.sample_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\"source\": self.inputs[index], \"targets\": self.targets[index]}\n",
        "\n",
        "    def _build(self):\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        for source in yield_lines(self.source_filepath):\n",
        "            self.inputs.append(source)\n",
        "\n",
        "        for target in yield_lines(self.target_filepaths):\n",
        "            self.targets.append(target)\n",
        "\n",
        "def train(args):\n",
        "    seed_everything(args.seed)\n",
        "\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=args.output_dir,\n",
        "        filename=\"checkpoint-{epoch}\",\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=True,\n",
        "        mode=\"min\",\n",
        "        save_top_k=1\n",
        "    )\n",
        "    bar_callback = pl.callbacks.TQDMProgressBar(refresh_rate=1)\n",
        "    metrics_callback = MetricsCallback()\n",
        "    train_params = dict(\n",
        "        accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "        max_epochs=args.num_train_epochs,\n",
        "        callbacks=[\n",
        "            LoggingCallback(),\n",
        "            checkpoint_callback, bar_callback],\n",
        "        logger=CSVLogger(f'{args.output_dir}/logs'),\n",
        "        log_every_n_steps= 9,\n",
        "        num_sanity_val_steps=0,  # skip sanity check to save time for debugging purpose\n",
        "        # plugins='ddp_sharded',\n",
        "        #progress_bar_refresh_rate=1,\n",
        "\n",
        "    )\n",
        "\n",
        "    print(\"Initialize model\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f'Using {device}')\n",
        "    model = SumSim(args)\n",
        "    model.args.dataset = args.dataset\n",
        "    trainer = pl.Trainer(**train_params)\n",
        "\n",
        "    print(\"Training model\")\n",
        "    trainer.fit(model)\n",
        "\n",
        "    print(\"training finished\")\n",
        "\n",
        "    # print(\"Saving model\")\n",
        "    # model.model.save_pretrained(args.output_dir)\n",
        "\n",
        "    # print(\"Saved model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE6FXE5AWK9s",
        "outputId": "9f9e2e42-a40e-457e-e23b-2ba95a39b8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "YnrYRDYash9B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/PSAT'):\n",
        "  if os.path.exists('/content/PSAT.zip'):\n",
        "    !unzip PSAT.zip -d PSAT\n",
        "  else:\n",
        "    print('Please upload the dataset zip file.')"
      ],
      "metadata": {
        "id": "d2bRgN5NE-kN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c18258d8-a3d8-48ab-a81f-624f70508954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  PSAT.zip\n",
            " extracting: PSAT/PSAT.train.complex  \n",
            " extracting: PSAT/PSAT.test.complex  \n",
            " extracting: PSAT/PSAT.valid.complex  \n",
            " extracting: PSAT/PSAT.train.simple  \n",
            " extracting: PSAT/PSAT.test.simple   \n",
            " extracting: PSAT/PSAT.valid.simple  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Trainer"
      ],
      "metadata": {
        "id": "mlJacv9Z2QBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVaU8eZBrZP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220e2bf9-9720-41b5-f370-9dccc10d4908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(seed=42, hidden_size=1, seq_dim=512, w1=1, w2=1, lambda_=11, sum_model='facebook/bart-base', sim_model='facebook/bart-base', train_batch_size=6, valid_batch_size=6, learning_rate=5e-05, max_seq_length=256, adam_epsilon=1e-08, weight_decay=0.0001, warmup_steps=5, num_train_epochs=3, custom_loss=False, gradient_accumulation_steps=1, n_gpu=1, nb_sanity_val_steps=-1, train_sample_size=1, valid_sample_size=1, device='cuda')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "PSAT = 'PSAT'\n",
        "EXP_DIR = '/content/experiments'\n",
        "\n",
        "import time\n",
        "import json\n",
        "import argparse\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "\n",
        "def parse_arguments():\n",
        "    p = ArgumentParser()\n",
        "\n",
        "    p.add_argument('--seed', type=int, default=42, help='randomization seed')\n",
        "\n",
        "    p = SumSim.add_model_specific_args(p)\n",
        "    args,_ = p.parse_known_args()\n",
        "    return args\n",
        "\n",
        "# Create experiment directory\n",
        "\n",
        "def get_experiment_dir(create_dir=False):\n",
        "    path = os.path.join('/content/experiments')\n",
        "    if os.path.exists(path):\n",
        "      shutil.rmtree(path) # Delete the directory if it exists\n",
        "    if create_dir:\n",
        "        os.makedirs(path)\n",
        "    return path\n",
        "\n",
        "def log_params(filepath, kwargs):\n",
        "    filepath = Path(filepath)\n",
        "    kwargs_str = dict()\n",
        "    for key in kwargs:\n",
        "        kwargs_str[key] = str(kwargs[key])\n",
        "    json.dump(kwargs_str, filepath.open('w'), indent=4)\n",
        "\n",
        "\n",
        "def run_training(args, dataset):\n",
        "\n",
        "    args.output_dir = get_experiment_dir(create_dir=True)\n",
        "    # logging the args\n",
        "    log_params(f\"{args.output_dir}/params.json\", vars(args))\n",
        "\n",
        "    args.dataset = dataset\n",
        "    print(\"Dataset: \",args.dataset)\n",
        "    train(args)\n",
        "\n",
        "dataset = PSAT\n",
        "args = parse_arguments()\n",
        "print(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(args,dataset)"
      ],
      "metadata": {
        "id": "1VV2Ud8bAj8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b17de61be6664c0ba8cdb150b9667e35",
            "f0673c62c3f24561b8b7f1d704e85b88",
            "42655a53e2684b24a42f4bcf9807b2a1",
            "cd8f9e62b9e94e6db667ebaf6d3ced84",
            "cea7e4fa0d144c10acf406db9376a1ad",
            "a753e05b09d243fcab9028b634a33b86",
            "3fcb0e7b14cb4f9cb7b951420eed67d7",
            "905c8c6ae4884aba8fca1948eba3a433",
            "12a5807daafb41eebefa9f1ab3f4284e",
            "6e0f701df9a6448db95be60ddd4e1eb9",
            "a98e5fb3019d4a6f91fcf5b89deb4a28",
            "21b00fc5b3024bd4a723a8402a7551c6",
            "2c13613114ce4efa85a9749c50c1ebe8",
            "c7c7be7247d24b9fbbdddea5c264e370",
            "76d0084cf8e84126b6b82f73059c16c2",
            "40002a967c1d43c9bf4e751bce3cc248",
            "4fd11f7b872c4ccabe4e03730a43fbad",
            "dbb29dd55d8441f7936371fb813155a8",
            "9b6286e701b84854b2e78b62139c48cf",
            "8ac1390d43f14d9ca2005507d9321c67",
            "14c2c3cd7c3d4b659ade0ac671ba0bc1",
            "8d64c55289fb48948dbb37feec487e58",
            "3f2cf487ae5c438a9338faccff9c95ae",
            "166e7731084145b09a0857cf7620caac",
            "66401a5ca63543bab4c7da732a695333",
            "b56dd0149ce74b0590fc95ec8b521452",
            "b0b40ee0c6b54b10971a669c3b904065",
            "4832dad227954dc3a0951be99a8c333e",
            "b4dbeff46ba642bf88f7905ef3d61898",
            "67e7f227cbfd42eb98c7850b1a898bac",
            "e8a24b2acefa4318881a8cc9b8cd2e29",
            "1551571d98b0417aade431438d9b640f",
            "e943167079e74db28bbb9609f0d0b019",
            "693f34ca28294a70bfa78ce9802ac431",
            "8ac87d14e8f84042ad0757141399f593",
            "00068aea2e9542b189e0f40d7a19363b",
            "366c94b6468a46979000de332f13a081",
            "80c7df802779476fb0919973812c1d82",
            "9d2f8b72f61f4d3c8a939084fbd27586",
            "bb71f37909144044826713d68b947f8a",
            "5db16686ff534e248ca19e20ccd45568",
            "355ba714cc7348e08dd005c39100f4e0",
            "c3e00108b5674d06b9ae61e384b3183e",
            "f77c0806b5344d048211a6cb84777ea9",
            "f3e65a4f2a7048e4ab8f40e826af2627",
            "1eeb41ee272544e6afc511e9287f2b04",
            "1effb916d06440cd9f62b1b78b0ae400",
            "1579c089dcd544baa3e8f155b521c1b2",
            "04ec73cfa0b14eaf9632a954fea1dc27",
            "de700e303dd4462d98bd721e065ef383",
            "26aa729ff5ba4a98a5cb287c83ebb921",
            "5737cbff42c04e01bd5edd2ef6a057ee",
            "ab157b193db445939fe986b8119b927d",
            "2a37f04148ed48f9905c0b271a394c37",
            "c1381aec2a0a40498b44dfeb1f033336",
            "b09958f8937f447eb39e4e6de0f1ef68",
            "8f88c8b9c5ac4d2ca429bde418befd7e",
            "e96bfa4a29a44dcca4a68678ce963445",
            "83dc353b8714437bb4d8e986df87df2a",
            "778719b331f946f0b396afef9acb2cbb",
            "3f631ee8a31945599eba06b95d7dc4c6",
            "76389a9a64fc4c78bd8375267b1b57b8",
            "89d0ad51e66840a98d6856b171f1d0f9",
            "c126948088d148ffb89d66f2f50d4ab6",
            "c7d44d2f37a74ee8ae101096c9a30cf3",
            "f8fd6c9eae6b42b095cdee2992bee2c4",
            "37b4f1f834db451d95d8dae6c3188845",
            "896b6ee30aa4459b9c93e83b3da7d797",
            "cb2f321f848f495dbee41368bbc122d2",
            "c0605bce7fe34c77a61b41fd9811ba62",
            "3033681c75eb46ff8a2259ed714ec043",
            "d57ac4186e694ff392d3eeb265e95250",
            "4d162d7e5c7441769a878cad78812865",
            "5f4beb955875488d9ad923e1e018f182",
            "3c09aaa4c4b344d395c835c60ddf9fbb",
            "78fb99caa71248aba864d5bdac801005",
            "d69277f1f9af432487fd6b6a45d2e54f",
            "0c7b9d3bd67643cba62d37661b636f8f",
            "588a8a13606b4821bdf5f8b2211bcdbc",
            "b8841d131da24372bfbce33321305d26",
            "118829ee509047ac9cd328a36a34c2ad",
            "e27d4aaf0fbf4ee58dc0502297cbaaf9",
            "74f9b98b98864440b63672c82fc39f97",
            "d7aa374777884b3b9739daad7c55a858",
            "88b984a92e714065865000060675e515",
            "f5518d6842df4b5686dbdda5ba0df7c7",
            "f3be97405278423686f2c1270c8daf94",
            "17ba60fa441947b899bcbd7d5c388f82",
            "019f59fd6a3c41e8a790fd0af102ee98",
            "bb6885d3a8624c2281ffbfa854afb3b3",
            "efdd9718a4e54aa68422d33cfba2dbe7",
            "561742723c8641b7b01118bb81bcdac4",
            "7b477f76ee2346a18e0b494649532ee0",
            "23ca8ba19fe44397a611cfcdb617bd28",
            "070fd6b935504509bbb730efead75078",
            "b0bc5c15fea2437daf75a6801793355d",
            "eee20a77ccc641c3836217376ba27145",
            "3db3ad7c039745419bcab45fbaff8e15",
            "2eb24e4bf4564c3fbc931939c2da5b13"
          ]
        },
        "outputId": "020ba0fb-b6f5-4007-865b-3878eea67f95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:  PSAT\n",
            "Initialize model\n",
            "Using cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b17de61be6664c0ba8cdb150b9667e35"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/558M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21b00fc5b3024bd4a723a8402a7551c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f2cf487ae5c438a9338faccff9c95ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "693f34ca28294a70bfa78ce9802ac431"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3e65a4f2a7048e4ab8f40e826af2627"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lightning_fabric.loggers.csv_logs:Missing logger folder: /content/experiments/logs/lightning_logs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /content/experiments exists and is not empty.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name       | Type                         | Params\n",
            "------------------------------------------------------------\n",
            "0 | summarizer | BartForConditionalGeneration | 139 M \n",
            "1 | simplifier | BartForConditionalGeneration | 139 M \n",
            "------------------------------------------------------------\n",
            "278 M     Trainable params\n",
            "0         Non-trainable params\n",
            "278 M     Total params\n",
            "1,115.363 Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init TrainDataset ...\n",
            "Initialized dataset done.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b09958f8937f447eb39e4e6de0f1ef68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `120` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37b4f1f834db451d95d8dae6c3188845"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  43.477185214147255\n",
            "Val_loss 0.5652281478585275\n",
            "Sari score:  44.16723756340329\n",
            "Val_loss 0.5583276243659672\n",
            "Sari score:  43.678964933069345\n",
            "Val_loss 0.5632103506693065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 9: 'val_loss' reached 0.57395 (best 0.57395), saving model to '/content/experiments/checkpoint-epoch=0.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  39.095495551971204\n",
            "Val_loss 0.609045044480288\n",
            "***** Validation results *****\n",
            "train_loss tensor(2.5888, device='cuda:0')\n",
            "train_loss = tensor(2.5888, device='cuda:0')\n",
            "\n",
            "val_loss tensor(0.5740, device='cuda:0')\n",
            "val_loss = tensor(0.5740, device='cuda:0')\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c7b9d3bd67643cba62d37661b636f8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  49.9422520451271\n",
            "Val_loss 0.500577479548729\n",
            "Sari score:  51.367270309314755\n",
            "Val_loss 0.4863272969068525\n",
            "Sari score:  50.59609150614951\n",
            "Val_loss 0.4940390849385049\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 18: 'val_loss' reached 0.51429 (best 0.51429), saving model to '/content/experiments/checkpoint-epoch=1.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  42.37879810182371\n",
            "Val_loss 0.5762120189817629\n",
            "***** Validation results *****\n",
            "train_loss tensor(1.6786, device='cuda:0')\n",
            "train_loss = tensor(1.6786, device='cuda:0')\n",
            "\n",
            "val_loss tensor(0.5143, device='cuda:0')\n",
            "val_loss = tensor(0.5143, device='cuda:0')\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "019f59fd6a3c41e8a790fd0af102ee98"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  51.1899812582356\n",
            "Val_loss 0.48810018741764405\n",
            "Sari score:  52.147791877234475\n",
            "Val_loss 0.47852208122765527\n",
            "Sari score:  50.025579887200195\n",
            "Val_loss 0.499744201127998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 27: 'val_loss' reached 0.50533 (best 0.50533), saving model to '/content/experiments/checkpoint-epoch=2.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  44.50446150617389\n",
            "Val_loss 0.5549553849382611\n",
            "***** Validation results *****\n",
            "train_loss tensor(1.5809, device='cuda:0')\n",
            "train_loss = tensor(1.5809, device='cuda:0')\n",
            "\n",
            "val_loss tensor(0.5053, device='cuda:0')\n",
            "val_loss = tensor(0.5053, device='cuda:0')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D-Sari"
      ],
      "metadata": {
        "id": "dBwyNQunrGvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import sys\n",
        "import nltk\n",
        "import math\n",
        "\n",
        "def ReadInFile(filename):\n",
        "    with open(filename) as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "        lines = [x.strip() for x in lines]\n",
        "\n",
        "    return lines\n",
        "\n",
        "def D_SARIngram(sgrams, cgrams, rgramslist, numref):\n",
        "    rgramsall = [rgram for rgrams in rgramslist for rgram in rgrams]\n",
        "\n",
        "    rgramcounter = Counter(rgramsall)\n",
        "\n",
        "    sgramcounter = Counter(sgrams)\n",
        "\n",
        "    sgramcounter_rep = Counter()\n",
        "\n",
        "    for sgram, scount in sgramcounter.items():\n",
        "        sgramcounter_rep[sgram] = scount * numref\n",
        "\n",
        "    cgramcounter = Counter(cgrams)\n",
        "\n",
        "    cgramcounter_rep = Counter()\n",
        "\n",
        "    for cgram, ccount in cgramcounter.items():\n",
        "        cgramcounter_rep[cgram] = ccount * numref\n",
        "\n",
        "    # KEEP\n",
        "\n",
        "    keepgramcounter_rep = sgramcounter_rep & cgramcounter_rep\n",
        "\n",
        "    keepgramcountergood_rep = keepgramcounter_rep & rgramcounter\n",
        "\n",
        "    keepgramcounterall_rep = sgramcounter_rep & rgramcounter\n",
        "\n",
        "    keeptmpscore1 = 0\n",
        "\n",
        "    keeptmpscore2 = 0\n",
        "\n",
        "    for keepgram in keepgramcountergood_rep:\n",
        "        keeptmpscore1 += keepgramcountergood_rep[keepgram] / keepgramcounter_rep[keepgram]\n",
        "\n",
        "        keeptmpscore2 += keepgramcountergood_rep[keepgram] / keepgramcounterall_rep[keepgram]\n",
        "\n",
        "        # print \"KEEP\", keepgram, keepscore, cgramcounter[keepgram], sgramcounter[keepgram], rgramcounter[keepgram]\n",
        "\n",
        "    keepscore_precision = 0\n",
        "\n",
        "    if len(keepgramcounter_rep) > 0:\n",
        "        keepscore_precision = keeptmpscore1 / len(keepgramcounter_rep)\n",
        "\n",
        "    keepscore_recall = 0\n",
        "\n",
        "    if len(keepgramcounterall_rep) > 0:\n",
        "        keepscore_recall = keeptmpscore2 / len(keepgramcounterall_rep)\n",
        "\n",
        "    keepscore = 0\n",
        "\n",
        "    if keepscore_precision > 0 or keepscore_recall > 0:\n",
        "        keepscore = 2 * keepscore_precision * keepscore_recall / (keepscore_precision + keepscore_recall)\n",
        "\n",
        "    # DELETION\n",
        "\n",
        "    delgramcounter_rep = sgramcounter_rep - cgramcounter_rep\n",
        "\n",
        "    delgramcountergood_rep = delgramcounter_rep - rgramcounter\n",
        "\n",
        "    delgramcounterall_rep = sgramcounter_rep - rgramcounter\n",
        "\n",
        "    deltmpscore1 = 0\n",
        "\n",
        "    deltmpscore2 = 0\n",
        "\n",
        "    for delgram in delgramcountergood_rep:\n",
        "        deltmpscore1 += delgramcountergood_rep[delgram] / delgramcounter_rep[delgram]\n",
        "\n",
        "        deltmpscore2 += delgramcountergood_rep[delgram] / delgramcounterall_rep[delgram]\n",
        "\n",
        "    delscore_precision = 0\n",
        "\n",
        "    if len(delgramcounter_rep) > 0:\n",
        "        delscore_precision = deltmpscore1 / len(delgramcounter_rep)\n",
        "\n",
        "    delscore_recall = 0\n",
        "\n",
        "    if len(delgramcounterall_rep) > 0:\n",
        "        delscore_recall = deltmpscore1 / len(delgramcounterall_rep)\n",
        "\n",
        "    delscore = 0\n",
        "\n",
        "    if delscore_precision > 0 or delscore_recall > 0:\n",
        "        delscore = 2 * delscore_precision * delscore_recall / (delscore_precision + delscore_recall)\n",
        "\n",
        "    # ADDITION\n",
        "\n",
        "    addgramcounter = set(cgramcounter) - set(sgramcounter)\n",
        "\n",
        "    addgramcountergood = set(addgramcounter) & set(rgramcounter)\n",
        "\n",
        "    addgramcounterall = set(rgramcounter) - set(sgramcounter)\n",
        "\n",
        "    addtmpscore = 0\n",
        "\n",
        "    for addgram in addgramcountergood:\n",
        "        addtmpscore += 1\n",
        "\n",
        "    addscore_precision = 0\n",
        "\n",
        "    addscore_recall = 0\n",
        "\n",
        "    if len(addgramcounter) > 0:\n",
        "        addscore_precision = addtmpscore / len(addgramcounter)\n",
        "\n",
        "    if len(addgramcounterall) > 0:\n",
        "        addscore_recall = addtmpscore / len(addgramcounterall)\n",
        "\n",
        "    addscore = 0\n",
        "\n",
        "    if addscore_precision > 0 or addscore_recall > 0:\n",
        "        addscore = 2 * addscore_precision * addscore_recall / (addscore_precision + addscore_recall)\n",
        "\n",
        "    return (keepscore, delscore_precision, addscore)\n",
        "\n",
        "def count_length(ssent, csent, rsents):\n",
        "\n",
        "    input_length = len(ssent.split(\" \"))\n",
        "\n",
        "    output_length = len(csent.split(\" \"))\n",
        "\n",
        "    reference_length = 0\n",
        "\n",
        "    for rsent in rsents:\n",
        "\n",
        "        reference_length += len(rsent.split(\" \"))\n",
        "\n",
        "    reference_length = int(reference_length / len(rsents))\n",
        "\n",
        "    return input_length, reference_length, output_length\n",
        "\n",
        "def sentence_number(csent, rsents):\n",
        "\n",
        "    output_sentence_number = len(nltk.sent_tokenize(csent))\n",
        "\n",
        "    reference_sentence_number = 0\n",
        "\n",
        "    for rsent in rsents:\n",
        "\n",
        "        reference_sentence_number += len(nltk.sent_tokenize(rsent))\n",
        "\n",
        "    reference_sentence_number = int(reference_sentence_number / len(rsents))\n",
        "\n",
        "    return reference_sentence_number, output_sentence_number\n",
        "\n",
        "def D_SARIsent(ssent, csent, rsents):\n",
        "    numref = len(rsents)\n",
        "\n",
        "    s1grams = ssent.lower().split(\" \")\n",
        "\n",
        "    c1grams = csent.lower().split(\" \")\n",
        "\n",
        "    s2grams = []\n",
        "\n",
        "    c2grams = []\n",
        "\n",
        "    s3grams = []\n",
        "\n",
        "    c3grams = []\n",
        "\n",
        "    s4grams = []\n",
        "\n",
        "    c4grams = []\n",
        "\n",
        "    r1gramslist = []\n",
        "\n",
        "    r2gramslist = []\n",
        "\n",
        "    r3gramslist = []\n",
        "\n",
        "    r4gramslist = []\n",
        "\n",
        "    for rsent in rsents:\n",
        "\n",
        "        r1grams = rsent.lower().split(\" \")\n",
        "\n",
        "        r2grams = []\n",
        "\n",
        "        r3grams = []\n",
        "\n",
        "        r4grams = []\n",
        "\n",
        "        r1gramslist.append(r1grams)\n",
        "\n",
        "        for i in range(0, len(r1grams) - 1):\n",
        "\n",
        "            if i < len(r1grams) - 1:\n",
        "                r2gram = r1grams[i] + \" \" + r1grams[i + 1]\n",
        "\n",
        "                r2grams.append(r2gram)\n",
        "\n",
        "            if i < len(r1grams) - 2:\n",
        "                r3gram = r1grams[i] + \" \" + r1grams[i + 1] + \" \" + r1grams[i + 2]\n",
        "\n",
        "                r3grams.append(r3gram)\n",
        "\n",
        "            if i < len(r1grams) - 3:\n",
        "                r4gram = r1grams[i] + \" \" + r1grams[i + 1] + \" \" + r1grams[i + 2] + \" \" + r1grams[i + 3]\n",
        "\n",
        "                r4grams.append(r4gram)\n",
        "\n",
        "        r2gramslist.append(r2grams)\n",
        "\n",
        "        r3gramslist.append(r3grams)\n",
        "\n",
        "        r4gramslist.append(r4grams)\n",
        "\n",
        "    for i in range(0, len(s1grams) - 1):\n",
        "\n",
        "        if i < len(s1grams) - 1:\n",
        "            s2gram = s1grams[i] + \" \" + s1grams[i + 1]\n",
        "\n",
        "            s2grams.append(s2gram)\n",
        "\n",
        "        if i < len(s1grams) - 2:\n",
        "            s3gram = s1grams[i] + \" \" + s1grams[i + 1] + \" \" + s1grams[i + 2]\n",
        "\n",
        "            s3grams.append(s3gram)\n",
        "\n",
        "        if i < len(s1grams) - 3:\n",
        "            s4gram = s1grams[i] + \" \" + s1grams[i + 1] + \" \" + s1grams[i + 2] + \" \" + s1grams[i + 3]\n",
        "\n",
        "            s4grams.append(s4gram)\n",
        "\n",
        "    for i in range(0, len(c1grams) - 1):\n",
        "\n",
        "        if i < len(c1grams) - 1:\n",
        "            c2gram = c1grams[i] + \" \" + c1grams[i + 1]\n",
        "\n",
        "            c2grams.append(c2gram)\n",
        "\n",
        "        if i < len(c1grams) - 2:\n",
        "            c3gram = c1grams[i] + \" \" + c1grams[i + 1] + \" \" + c1grams[i + 2]\n",
        "\n",
        "            c3grams.append(c3gram)\n",
        "\n",
        "        if i < len(c1grams) - 3:\n",
        "            c4gram = c1grams[i] + \" \" + c1grams[i + 1] + \" \" + c1grams[i + 2] + \" \" + c1grams[i + 3]\n",
        "\n",
        "            c4grams.append(c4gram)\n",
        "\n",
        "    (keep1score, del1score, add1score) = D_SARIngram(s1grams, c1grams, r1gramslist, numref)\n",
        "\n",
        "    (keep2score, del2score, add2score) = D_SARIngram(s2grams, c2grams, r2gramslist, numref)\n",
        "\n",
        "    (keep3score, del3score, add3score) = D_SARIngram(s3grams, c3grams, r3gramslist, numref)\n",
        "\n",
        "    (keep4score, del4score, add4score) = D_SARIngram(s4grams, c4grams, r4gramslist, numref)\n",
        "\n",
        "    avgkeepscore = sum([keep1score, keep2score, keep3score, keep4score]) / 4\n",
        "\n",
        "    avgdelscore = sum([del1score, del2score, del3score, del4score]) / 4\n",
        "\n",
        "    avgaddscore = sum([add1score, add2score, add3score, add4score]) / 4\n",
        "\n",
        "    input_length, reference_length, output_length = count_length(ssent, csent, rsents)\n",
        "\n",
        "    reference_sentence_number, output_sentence_number = sentence_number(csent, rsents)\n",
        "\n",
        "    if output_length >= reference_length:\n",
        "\n",
        "        LP_1 = 1\n",
        "\n",
        "    else:\n",
        "\n",
        "        LP_1 = math.exp((output_length - reference_length) / output_length)\n",
        "\n",
        "    if output_length > reference_length:\n",
        "\n",
        "        LP_2 = math.exp((reference_length - output_length) / max(input_length - reference_length, 1))\n",
        "\n",
        "    else:\n",
        "\n",
        "        LP_2 = 1\n",
        "\n",
        "    SLP = math.exp(-abs(reference_sentence_number - output_sentence_number) / max(reference_sentence_number,\n",
        "                                                                                  output_sentence_number))\n",
        "\n",
        "    avgkeepscore = avgkeepscore * LP_2 * SLP\n",
        "\n",
        "    avgaddscore = avgaddscore * LP_1\n",
        "\n",
        "    avgdelscore = avgdelscore * LP_2\n",
        "\n",
        "    finalscore = (avgkeepscore + avgdelscore + avgaddscore) / 3\n",
        "\n",
        "    return finalscore, avgkeepscore, avgdelscore, avgaddscore\n",
        "\n",
        "def D_SARI_file(ssent, csent, rsents):\n",
        "    D_SARI = 0\n",
        "    for st, ct, rt in zip(ssent, csent, rsents):\n",
        "        D_SARI += D_SARIsent(st, ct, [rt])[0]\n",
        "    return 100 * D_SARI / len(ssent)"
      ],
      "metadata": {
        "id": "iRIF-deZrCKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "from easse.utils.resources import get_orig_sents, get_refs_sents\n",
        "\n",
        "def get_sys_sents(test_set, sys_sents_path=None):\n",
        "    # Get system sentences to be evaluated\n",
        "    if sys_sents_path is not None:\n",
        "        return read_lines(sys_sents_path)\n",
        "    else:\n",
        "        # read the system output\n",
        "        with click.get_text_stream(\"stdin\", encoding=\"utf-8\") as system_output_file:\n",
        "            return system_output_file.read().splitlines()\n",
        "\n",
        "\n",
        "def get_orig_and_refs_sents(test_set, orig_sents_path=None, refs_sents_paths=None):\n",
        "  # Get original and reference sentences\n",
        "    if test_set == \"custom\":\n",
        "        assert orig_sents_path is not None\n",
        "        assert refs_sents_paths is not None\n",
        "\n",
        "        orig_sents = read_lines(orig_sents_path)\n",
        "        refs_sents = [read_lines(refs_sents_paths)]\n",
        "    else:\n",
        "        orig_sents = get_orig_sents(test_set)\n",
        "        refs_sents = get_refs_sents(test_set)\n",
        "    return orig_sents, refs_sents"
      ],
      "metadata": {
        "id": "LTl-6BEwBVaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "clnjIc4VCdb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from easse.cli import evaluate_system_output\n",
        "from easse.report import get_all_scores\n",
        "from contextlib import contextmanager\n",
        "import json\n",
        "import torch\n",
        "from easse.sari import corpus_sari\n",
        "import time\n",
        "#from googletrans import Translator\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def log_stdout(filepath, mute_stdout=False):\n",
        "    '''Context manager to write both to stdout and to a file'''\n",
        "\n",
        "    class MultipleStreamsWriter:\n",
        "        def __init__(self, streams):\n",
        "            self.streams = streams\n",
        "\n",
        "        def write(self, message):\n",
        "            for stream in self.streams:\n",
        "                stream.write(message)\n",
        "\n",
        "        def flush(self):\n",
        "            for stream in self.streams:\n",
        "                stream.flush()\n",
        "\n",
        "    save_stdout = sys.stdout\n",
        "    log_file = open(filepath, 'w')\n",
        "    if mute_stdout:\n",
        "        sys.stdout = MultipleStreamsWriter([log_file])  # Write to file only\n",
        "    else:\n",
        "        sys.stdout = MultipleStreamsWriter([save_stdout, log_file])  # Write to both stdout and file\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        sys.stdout = save_stdout\n",
        "        log_file.close()\n",
        "\n",
        "# set random seed universal\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "model_dir = None\n",
        "_model_dirname = None\n",
        "max_len = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device}')\n",
        "\n",
        "#### Joint model ####\n",
        "Model = SumSim.load_from_checkpoint('/content/experiments/checkpoint-epoch=2.ckpt').to(device)\n",
        "summarizer = Model.summarizer.to(device)\n",
        "simplifier = Model.simplifier.to(device)\n",
        "summarizer_tokenizer = Model.summarizer_tokenizer\n",
        "simplifier_tokenizer = Model.simplifier_tokenizer\n",
        "#### Joint model ####\n",
        "\n",
        "def generate(sentence, preprocessor=None):\n",
        "    '''\n",
        "    This function is for Joint model to generate/predict\n",
        "    '''\n",
        "\n",
        "    encoding = summarizer_tokenizer(\n",
        "        [sentence],\n",
        "        max_length = 512,\n",
        "        truncation = True,\n",
        "        padding = 'max_length',\n",
        "        return_tensors = 'pt',\n",
        "    )\n",
        "\n",
        "    summary_ids = summarizer.generate(\n",
        "        encoding['input_ids'].to(device),\n",
        "        num_beams = 15,\n",
        "        min_length = 30,\n",
        "        max_length = 512,\n",
        "        top_k = 80, top_p = 0.97\n",
        "    ).to(device)\n",
        "\n",
        "    summary_atten_mask = torch.ones(summary_ids.shape).to(device)\n",
        "    summary_atten_mask[summary_ids[:,:] == summarizer_tokenizer.pad_token_id] = 0\n",
        "\n",
        "    beam_outputs = simplifier.generate(\n",
        "        input_ids = summary_ids,\n",
        "        attention_mask = summary_atten_mask,\n",
        "        do_sample = True,\n",
        "        max_length = 256,\n",
        "        num_beams = 5, #16\n",
        "        top_k = 80,  #120\n",
        "        top_p = 0.95, #0.95\n",
        "        early_stopping = True,\n",
        "        num_return_sequences = 1,\n",
        "    )\n",
        "\n",
        "    sent = simplifier_tokenizer.decode(beam_outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    return sent\n",
        "\n",
        "\n",
        "def evaluate(orig_filepath, sys_filepath, ref_filepaths):\n",
        "    orig_sents = read_lines(orig_filepath)\n",
        "    refs_sents = [read_lines(ref_filepaths)]\n",
        "\n",
        "    return corpus_sari(orig_sents, read_lines(sys_filepath), refs_sents)\n",
        "\n",
        "def back_translation(text):\n",
        "    X = translator.translate(text, dest = 'de')\n",
        "    return translator.translate(X.text, dest = 'en').text\n",
        "\n",
        "\n",
        "def simplify_file(complex_filepath, output_filepath, features_kwargs=None, model_dirname=None, post_processing=True):\n",
        "    '''\n",
        "    Obtain the simplified sentences (predictions) from the original complex sentences.\n",
        "    '''\n",
        "\n",
        "    total_lines = count_line(complex_filepath)\n",
        "    print(complex_filepath)\n",
        "    print(complex_filepath.stem)\n",
        "\n",
        "    output_file = Path(output_filepath).open(\"w\")\n",
        "\n",
        "    for n_line, complex_sent in enumerate(yield_lines(complex_filepath), start=1):\n",
        "        output_sents = generate(complex_sent, preprocessor=None)\n",
        "\n",
        "\n",
        "        print(f\"{n_line}/{total_lines}\", \" : \", output_sents)\n",
        "        if output_sents:\n",
        "            output_file.write(output_sents + \"\\n\")\n",
        "        else:\n",
        "            output_file.write(\"\\n\")\n",
        "    output_file.close()\n",
        "\n",
        "    if post_processing: post_process(output_filepath)\n",
        "\n",
        "def post_process(filepath):\n",
        "    lines = []\n",
        "    for line in yield_lines(filepath):\n",
        "        lines.append(line.replace(\"''\", '\"'))\n",
        "    write_lines(lines, filepath)\n",
        "\n",
        "def evaluate_on_PSAT(phase, features_kwargs=None,  model_dirname = None):\n",
        "    dataset = PSAT\n",
        "    output_dir = '/content/outputs'\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "    output_score_filepath = f'{output_dir}/score_{dataset}_{phase}.log.txt'\n",
        "    complex_filepath = get_data_filepath(dataset, phase, 'complex')\n",
        "\n",
        "    if not os.path.exists(output_score_filepath) or count_line(output_score_filepath)==0:\n",
        "        start_time = time.time()\n",
        "        complex_filepath =get_data_filepath(dataset, phase, 'complex')\n",
        "        complex_filepath = Path(complex_filepath)\n",
        "\n",
        "        pred_filepath = f'{output_dir}/{complex_filepath.stem}.txt'\n",
        "        ref_filepaths = get_data_filepath(dataset, phase, 'simple')\n",
        "\n",
        "        if os.path.exists(pred_filepath) and count_line(pred_filepath)==count_line(complex_filepath):\n",
        "            print(\"File is already processed.\")\n",
        "        else:\n",
        "            simplify_file(complex_filepath, pred_filepath, features_kwargs, model_dirname)\n",
        "\n",
        "        print(\"Evaluate: \", pred_filepath)\n",
        "\n",
        "        with log_stdout(output_score_filepath):\n",
        "\n",
        "            scores  = evaluate_system_output(test_set='custom',\n",
        "                                             sys_sents_path=str(pred_filepath),\n",
        "                                             orig_sents_path=str(complex_filepath),\n",
        "                                             refs_sents_paths=str(ref_filepaths),metrics = ['bleu', 'sari', 'fkgl'] )\n",
        "\n",
        "            sys_sents = get_sys_sents(test_set = 'custom', sys_sents_path=str(pred_filepath))\n",
        "            orig_sents, refs_sents = get_orig_and_refs_sents(test_set = 'custom',\n",
        "                                                             orig_sents_path = str(complex_filepath),\n",
        "                                                             refs_sents_paths = str(ref_filepaths))\n",
        "\n",
        "\n",
        "            print(\"SARI: {:.2f}\\t D-SARI: {:.2f} \\t BLEU: {:.2f} \\t FKGL: {:.2f} \".format(scores['sari'],\n",
        "                                                                                          D_SARI_file(orig_sents,sys_sents,refs_sents[0],),\n",
        "                                                                                          scores['bleu'],\n",
        "                                                                                          scores['fkgl']))\n",
        "\n",
        "            print(\"Execution time: --- %s seconds ---\" % (time.time() - start_time))\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Already exists: \", output_score_filepath)\n",
        "        print(\"\".join(read_lines(output_score_filepath)))\n",
        "\n",
        "evaluate_on_PSAT(phase='test', features_kwargs=None, model_dirname=None)"
      ],
      "metadata": {
        "id": "9Wrv8iUJqsH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c51c3d-909c-412b-f0e8-54785677aa8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n",
            "/content/PSAT/PSAT.test.complex\n",
            "PSAT.test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:415: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.97` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:427: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `80` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/33  :  How to Apply: You must submit an online application with an application using the Broward College Registrar's Office 4205 Bonaventure Blvd, Weston, FL 33332. Official High School transcript(s) must be sent directly from the School, but for non-US students who attended high school diplomas, you must submit a Home School Completion Affidavit. If you are signed by parent and notarized, you can submit an application with a \"A Guide to Florida Res Residency\" (a guide to Florida residency). Required Materials: Official high school transcripts. Official GED passing transcripts.\n",
            "2/33  :  How to Apply: You must submit an application using the Missouri S&T Application. Required Materials: Official high school and/or college transcript(s). If you have questions, you can contact us at: Missouri University of Science and Technology 106 Parker Hall, 300 W 13th Street Rolla, Missouri USA 65409\n",
            "3/33  :  How to Apply: You must submit an application using the Radford High School Office of Admissions Box 6903 Radford, VA 24142. Required Materials: Official transcript(s) of high school work completed. If materials are submitted electronically we do not require that you submit a paper copy. If you would prefer to mail application materials to Radford University, you can mail them to:\n",
            "4/33  :  How to Apply: You must submit an application with a $50 application fee. Required Materials: Official U.S. High School transcript(s) and high school equivalency certificate(s). If you have questions, you can contact us at: www.applytexas.org. Official SAT and/or ACT scores from the U.TRGV school code is ACT 6991, SAT 6568. If you are a high school student, you must submit your high school transcript or high school equivalent (ESL) to the UTRV Language Institute. You can also submit your ACT or SAT scores directly from the testing agency.\n",
            "5/33  :  How to Apply: You must submit an application using the AACOM AS application fee. Required Materials: Official MCAT scores (MCAT must be within 3 calendar years from the desired date of matriculation). We will not accept letters of recommendation. You should only submit them to the Office of the Admissions Officer (WVSOM) with an original signature. If you have questions, you can contact us through the AACOAS website. We will contact you directly to ask you to submit an interview. You can also contact us directly through our website at: AACOMAS.\n",
            "6/33  :  How to Apply: You must submit an application with a $115 application fee. Required Materials: Official SAT and/or ACT scores. If you are applying to the Albany Medical College, you should contact the Admissions Office at [email protected]   Chi Chi, Inc. (212) 6208-479 (1-212-521 (\n",
            "7/33  :  How to Apply: You must submit an application with a nonrefundable $50 application fee. You can pay using a credit card (Visa or Mastercard) or eCheck at the time you submit your application. Or you can log in to My ASU, or you can mail a check or money order to Admission Services (payable to Arizona State University) at the email below. Admission Services Applicant Processing Phoenix State University PO Box 87100 4 Tempe. AZ 85287-1004\n",
            "8/33  :  How to Apply: You must submit an application using the BYU-Hawaii Admissions website. If you have questions about your application, you can contact us at admissions@byuh.edu or (808) 675-3738. You can also submit an online application through the BYU Admissions Office. You should only submit one application with a $50 application fee. Required Materials: Official BYU Official Official Official Statement.\n",
            "9/33  :  How to Apply: You must submit an application with a $10 application fee. Required Materials:\n",
            "10/33  :  How to Apply: You must submit an application using the Common Application. Required Materials: Official high school transcript(s) G.P.A. and/or equivalent ACT composite scores. If English is not your first language, you can submit a letter of recommendation Nursing Personal Statement (250 word count minimum). You can submit your application through the chaminade website or through Common Application, as early as September 1. If you are interested in pursuing a degree in Nursing, you should contact us at: chaminades@chaminade.edu. You can also submit an online application with a nonrefundable $10 application fee. You should only submit one letter. If this is not the case, we will contact you to request more information. If we can’t reach you, we’ll contact you directly. If it is not, we can contact you through the website. If the application is not for you, you must submit a recommendation letter through the school’s Common Application with a minimum of 250 word count. If your application does not have an application fee, it must be paid in full. Optional Materials: Optional Materials (e.g. ACT or Baccalaureate test scores). You should also submit\n",
            "11/33  :  How to Apply: You must submit an application using the Student Accounts College of Biblical Studies website. If you are applying for an academic program, you must submit a $40 application fee. Required Materials: Official SAT and/or ACT scores. You must have a high school diploma or equivalent. Official ACT scores must be at least 18 years old. You can also submit an online or mail application. If your ACT scores are below, you can submit them to:\n",
            "12/33  :  How to Apply: You must submit an application using the Official high school transcript(s). Official ACT and/or SAT scores (1-2 pages) Required essay(s) Two letters of recommendation. If you have questions, you can contact the Office of Admission at (800) 210-7900 to arrange to meet with an Admission Counselor and to tour the campus.\n",
            "13/33  :  How to Apply: You must submit an online application with a $50 nonrefundable application fee. Required Materials: Official High School transcript SAT or ACT scores. If you are 21 years of age or older, you must submit a high school transcript or ACT score. You can also submit a hard copy application. Transfer students should visit, www.coppin.edu/transfer. Application Deadline: December 15th Fall Semester: May 1st\n",
            "14/33  :  How to Apply: You must submit an application with a Common Application or De Pauw Application. Required Materials: Official High school transcript(s). Official high school transcript. Official SAT and/or ACT scores. Official ACT scores(s) (if any) from any of our 45 majors and 53 minors. You can apply to the School of Music or DePauw University Office of Admission 204 East Seminary Street Greencastle, IN 46135 admission@depauw.edu\n",
            "15/33  :  How to Apply: You must submit an application with a $85.00 student fee and $35.00 cashier's check.\n",
            "16/33  :  How to Apply: You must submit an application with a high school transcript to Illinois College. Required Materials: School Report (a reference form completed by your high school counselor). Optional Materials: High school transcript(s) (optional for some students) Recommendation letter from a counselor.\n",
            "17/33  :  How to Apply: You must submit an application with a Common Application. We use the Common Application to collect application materials. There is no fee for applying to Marlboro. If you have an alternative transcript, read more about our requirements. Required Materials: Official transcript(s) and/or essay(s). If you’re a homeschooling student, you must submit a home-schooled transcript with 250-500 word responses. You can also submit a letter of recommendation. We’d like to hear from your admissions counselor to talk about your options. We recommend an interview for all applicants. You should see the requirements for a transcript (if any). Recommendation letters. We are asking you to submit one letter with 250 words. We may have to skim your novel for the sake of time, but if you haven’t been out of school or you finished it, you can submit a transcript here. We strongly recommend you submit an interview with our admissions counselor. Recommendation letter. You are required to submit two letters of recommendation (if you have one). We can only recommend one letter if you are in school for a while, with at least one letter from a teacher of yours in the past two years. We can recommend\n",
            "18/33  :  How to Apply: You must submit an application using the Common Application with a $50 nonrefundable application fee (or fee waiver). Required Materials: Official high school (secondary school) transcript(s) (if English is not your first language) SAT and/or ACT scores (optional for homeschooled applicants only). If you have already graduated high school but have not yet attended a college or university, you can apply for an application fee waiver from the College Board, a similar agency, or by obtaining a form from your guidance counselor. You can also submit a fee waiver through our online application form. Application Fee waiver is available through our Common Application form. If you cannot pay the fee, you should contact our guidance counselor at Montserrat College of Art at the Admissions Office at the address at the base of this page. Application Form (or Common Application) is here: www.montserrat.edu/applications/\n",
            "19/33  :  How to Apply: You must submit an application with nonrefundable $30 fee. Required Materials: Official high school and/or college transcript(s). Official GED transcripts. If you have questions, you can contact the Office of Undergraduate and Graduate Admissions, Mount Alumni College, Cresson, PA 16630, (814) 886-6383. If your high school or GED teacher is a GED student, you must submit a copy of the high school transcript to the Vice President for Enrollment Management.\n",
            "20/33  :  How to Apply: You must submit an online application with a minimum of two references (a maximum of two) and an essay. If you have questions, you can contact us at [email protected]. Required Materials: Official U.S. college transcript(s) (if any). College of Pharmacy applicants should submit an essay with a reference letter(s).\n",
            "21/33  :  How to Apply: You must submit an application using the Common Application. Required Materials: Official high school transcript Official SAT and/or ACT scores. Official High School transcript Official highschool transcript Official ACT scores(s). Official SAT or/or/\n",
            "22/33  :  How to Apply: You must submit an application using the Saint Meinrad Seminary and School of Theology website. Required Materials: Official Official Certificate of Baptism Official (S.M.A.C.\n",
            "23/33  :  How to Apply: You must submit an application using the Common Application or Common Application. Required Materials: SAT and/or SAT scores. If you’ve taken the ACT and SAT scores more than once, we encourage you to submit all sets of scores. All information not submitted online should be submitted to the following address: St. Norbert College Office of Admission 100 Grant St. De Pere, WI 54115-2099\n",
            "24/33  :  How to Apply: You must submit an application with a $50 application fee or acceptable fee waiver form. Required Materials: Official high school transcript(s) showing grades 9-11. Official SAT and/or ACT scores. Richmond’s codes are 4410 for the ACT and 5569 for the SAT. Required Recommendations: Required recommendation from school counselor or official (principal or teacher). Required Recommendation from a school counselor. If you are an incoming freshman, you must submit official reports directly from a high school principal or official, as soon as they become available. Optional Materials: You can submit an essay with a self-report. You can also submit a questionnaire using the code: SAT = 4410 ACT = 5569 SAT.\n",
            "25/33  :  How to Apply: You must submit an application with a Common Application or University of Maine System application. Required Materials: Official SAT and/or ACT scores. If homeschooled, transcript must show date of graduation, or annual assessment of courses completed, and should be signed by the person responsible for homeschooling the student. Official high school transcript(s). Official SAT or ACT scores are optional for all undergraduate applicants except those applying for a BS in Nursing.\n",
            "26/33  :  How to Apply: You must submit an application using the High School Request Form (DC) or VA/Online (VHS/Online/Digital/Web/Email). Required Materials: Official transcripts from all colleges/universities previously attended to be submitted to the Office of Records and Registration, University of the Potomac. Official transcript(s) from any college or university in the United States. Equivalents include a GED Certificate.\n",
            "27/33  :  How to Apply: You must submit an application using the Common Application. You can submit an online application with a $10 application fee. Required Materials: Official SAT and/or ACT scores. If you have questions, you can contact us at [email protected] or you can email us directly. If this sounds like you, then you should contact us. We’ll work with you to find out how to apply. If we can’t find you, we can contact you through our website at: http://www.wellesley.edu/apply.\n",
            "28/33  :  How to Apply: You must submit an application using the Common Application Early Decision agreement (if you apply Early Decision I or II, available through the Common App). You must ask your school or counselor to submit the following materials: Official SAT and/or ACT scores (more testing policy information here) Interview with Admission Officer (recommended). If you are an international applicant, you can apply to Whitman as an international student. Required Materials: Official transcript(s). Official SAT or ACT scores(s) (if any).\n",
            "29/33  :  How to Apply: You must submit an application using the WMU Online Application. Required Materials: Official high school and/or college transcript(s). You must have a high school GPA of 3.4 or a 23 ACT or 1090 SAT. If you have questions, you can contact WMU Admissions Office in Seibert Administration Building at (269) 387-4200 with a Gold Gateway account. You can also contact us at:\n",
            "30/33  :  How to Apply: You must submit an application using the “Academy of Art University” website. Required Materials: Official high school transcript(s) or GED High school diploma with graduation date. Official, signed copy of a completed Bachelor’s degree transcript. If you have questions, you can contact us at: [email protected]. If you are an international student, you should contact us through our International Student Resources page. You can also contact our Transfer Students page to apply. We also accept Visa, MasterCard, and Discover credit cards. Our application fee is nonrefundable and non-transferrable. Your application fee should not exceed $50. You should only submit one application. We’ll only accept one application with a $50 application fee. If your application is not in writing, we’d like to hear from you directly. We can only accept letters from you. If we can’t, we can contact you directly through our website.\n",
            "31/33  :  How to Apply: You must submit an application using the University of Saint Mary Online Application. Required Materials: Official school transcript(s). Official school transcripts (if any). Essay or personal statement (see the Admissions pages for specific requirements for the program) Documentation of teaching or nursing licensure, if required TOEFL or TSE scores, if necessary. If you have questions, you can contact us at 877-307-4915 or request more information and we will contact you shortly. Official high school and/or nursing school transcripts. Official college transcripts.\n",
            "32/33  :  How to Apply: You must submit an application with a $25 application fee. Required Materials: Official SAT and/or ACT scores. If you have achieved the General Equivalency Diploma, an official score report will be submitted. Dual credit transcript(s). Dual credit transcripts (if any). Optional Items: Your transcript must reflect grades for all college-level work completed since you last attended UIW. You can request your score be sent to UIW by listing our code when you register for the exam. Our code for the SAT is 6303, and ACT is 4106. If applicable, you can request our code for G.E.D. scores (if applicable).\n",
            "33/33  :  How to Apply: You must submit an application using either the Common Application, the Coalition Application or online application. Official transcripts of all academic work completed to date. Official scores must be submitted directly to the College. Official SAT and/or ACT scores are 5634, and the ABC code is 4406. If you are 21 years of age or older, you must submit a transcript with proof of high school graduation prior to your first academic year. Optional: You can submit an essay. Essay or video, essay, or portfolio. If applicable, a list of current (senior year) grades.\n",
            "Evaluate:  /content/outputs/PSAT.test.txt\n",
            "SARI: 47.56\t D-SARI: 36.45 \t BLEU: 18.94 \t FKGL: 5.80 \n",
            "Execution time: --- 268.9647488594055 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Outputs"
      ],
      "metadata": {
        "id": "BhnCT_ALs_je"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the zip file\n",
        "zip_file_path = '/content/outputs.zip'\n",
        "\n",
        "if os.path.exists(zip_file_path):\n",
        "    os.remove(zip_file_path)\n",
        "\n",
        "# Compress the folder into a zip file\n",
        "!zip -r {zip_file_path} {os.path.basename('/content/outputs')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0eSICdf4UhF",
        "outputId": "5be86cce-d11e-4579-a1b5-2d8bb60dfa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: outputs/ (stored 0%)\n",
            "  adding: outputs/PSAT.test.txt (deflated 72%)\n",
            "  adding: outputs/score_PSAT_test.log.txt (deflated 6%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(f'/content/outputs.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "5CBSoj334r5J",
        "outputId": "4a93d6e3-b8b4-4b81-be94-b9e2c7b2f27e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_717b9cd8-26fc-4a46-9b57-e0eae14bc6ed\", \"outputs.zip\", 5292)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "nZoHhHLbKGog"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  [SimSum GitHub Code](https://github.com/epfml/easy-summary/tree/main)"
      ],
      "metadata": {
        "id": "Mh5kN3bdKIKT"
      }
    }
  ]
}