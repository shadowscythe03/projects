{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09f1ee6aa9a5435c84caaead0b6727a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e2826f4ea5141c08d475b9fb2bec58b",
              "IPY_MODEL_365afd5bc84c4f1fb78686ca5e39bc0e",
              "IPY_MODEL_83aefa0a92524f40ad70da3a6bfdb9af"
            ],
            "layout": "IPY_MODEL_bd4fb2a8db3d4e4faf654ebc5a387f04"
          }
        },
        "0e2826f4ea5141c08d475b9fb2bec58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76e1c7a3f44a4590b6451e32dd3a31c9",
            "placeholder": "​",
            "style": "IPY_MODEL_89daba12fdde46688b12a4e03f4cec6f",
            "value": "config.json: 100%"
          }
        },
        "365afd5bc84c4f1fb78686ca5e39bc0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47996cfad12f4986bf7678e3bc078a55",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55a5a756d93845b881962c073af4bdeb",
            "value": 1208
          }
        },
        "83aefa0a92524f40ad70da3a6bfdb9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6099f81e5dd946f1bbc632df7918bf85",
            "placeholder": "​",
            "style": "IPY_MODEL_3c10febd1355451d9000edc7856f566c",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 87.5kB/s]"
          }
        },
        "bd4fb2a8db3d4e4faf654ebc5a387f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76e1c7a3f44a4590b6451e32dd3a31c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89daba12fdde46688b12a4e03f4cec6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "47996cfad12f4986bf7678e3bc078a55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55a5a756d93845b881962c073af4bdeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6099f81e5dd946f1bbc632df7918bf85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c10febd1355451d9000edc7856f566c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce44e4f125074972a923253f66fd81dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75e7efc4da744721830ec2f07423c9d2",
              "IPY_MODEL_75bd6ea48fcd41da9c2aac58940e60dc",
              "IPY_MODEL_4d6f104c91084db9890dcdc732a7129c"
            ],
            "layout": "IPY_MODEL_3c4ae50c66eb47b48774f63ed515b5b6"
          }
        },
        "75e7efc4da744721830ec2f07423c9d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13e530676183454694a3f1759d5e156a",
            "placeholder": "​",
            "style": "IPY_MODEL_0eddfea23ca6488899fa26f506e36de7",
            "value": "model.safetensors: 100%"
          }
        },
        "75bd6ea48fcd41da9c2aac58940e60dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5411d708dd2443b6a2da6618abd55bb3",
            "max": 891646390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5aac075b67b4ca99c0258c007fe8312",
            "value": 891646390
          }
        },
        "4d6f104c91084db9890dcdc732a7129c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_10d829a4400449f0803553111843c0b0",
            "placeholder": "​",
            "style": "IPY_MODEL_009b22f8a5994be6b07c3ed535d32369",
            "value": " 892M/892M [00:07&lt;00:00, 207MB/s]"
          }
        },
        "3c4ae50c66eb47b48774f63ed515b5b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13e530676183454694a3f1759d5e156a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eddfea23ca6488899fa26f506e36de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5411d708dd2443b6a2da6618abd55bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5aac075b67b4ca99c0258c007fe8312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "10d829a4400449f0803553111843c0b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "009b22f8a5994be6b07c3ed535d32369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2a945fadaee4d5483fb89b8589bcda3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_06387ceba4784faab1c08ff0a06a9c88",
              "IPY_MODEL_c2efbf3949cb427486fcef9898b20332",
              "IPY_MODEL_542c425a0cc6457e9d53c8b823053b46"
            ],
            "layout": "IPY_MODEL_e4b3e7ad15a44757a31ee61bdd30eba8"
          }
        },
        "06387ceba4784faab1c08ff0a06a9c88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13a509b0c1dd4c05ba5a18c890882f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_4c77f112c58344e59f31679271820811",
            "value": "generation_config.json: 100%"
          }
        },
        "c2efbf3949cb427486fcef9898b20332": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dda6da273c948bbbf7c07002d99ff7f",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d4f43ba3f0a4555a95b71b7930c38e1",
            "value": 147
          }
        },
        "542c425a0cc6457e9d53c8b823053b46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8764658158f14d8b8f60db9421288b44",
            "placeholder": "​",
            "style": "IPY_MODEL_a33c5306ba5146c0ae56e534e680ebe6",
            "value": " 147/147 [00:00&lt;00:00, 10.2kB/s]"
          }
        },
        "e4b3e7ad15a44757a31ee61bdd30eba8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13a509b0c1dd4c05ba5a18c890882f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c77f112c58344e59f31679271820811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dda6da273c948bbbf7c07002d99ff7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4f43ba3f0a4555a95b71b7930c38e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8764658158f14d8b8f60db9421288b44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a33c5306ba5146c0ae56e534e680ebe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee9c10b848114ec594ffe1f43f4e464d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0611a2934d25494596b4453f280bc10f",
              "IPY_MODEL_403ee659325942099ffcb713a7d74fec",
              "IPY_MODEL_e869117731654d4387db14231e17a97b"
            ],
            "layout": "IPY_MODEL_99f6cecb8de141539f9aba1b755f5a07"
          }
        },
        "0611a2934d25494596b4453f280bc10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37d77ff757f64b78948c861f59048a23",
            "placeholder": "​",
            "style": "IPY_MODEL_a2814996f8894c53b1101d02a785b4ad",
            "value": "spiece.model: 100%"
          }
        },
        "403ee659325942099ffcb713a7d74fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f23b650d844e35a99f3acec2deb0da",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c1564849a8245738c8f363dfb312b03",
            "value": 791656
          }
        },
        "e869117731654d4387db14231e17a97b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f037d407444549ed88afd99514ea7300",
            "placeholder": "​",
            "style": "IPY_MODEL_321685d1cada480c9afcf9a084d56e87",
            "value": " 792k/792k [00:00&lt;00:00, 32.1MB/s]"
          }
        },
        "99f6cecb8de141539f9aba1b755f5a07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37d77ff757f64b78948c861f59048a23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2814996f8894c53b1101d02a785b4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f23b650d844e35a99f3acec2deb0da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c1564849a8245738c8f363dfb312b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f037d407444549ed88afd99514ea7300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "321685d1cada480c9afcf9a084d56e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b763dc013451472b8779d71f89cfe511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1a993a9dfd5d4893afd7828a3973eb4b",
              "IPY_MODEL_83da4d4ed98448cfaba79cf3dbb97b64",
              "IPY_MODEL_a901710c58db4d988077db16a68f7d17"
            ],
            "layout": "IPY_MODEL_98a74d0e854d448796907223f4d4c067"
          }
        },
        "1a993a9dfd5d4893afd7828a3973eb4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cfa0e173ef4a409b676c72b2fb38be",
            "placeholder": "​",
            "style": "IPY_MODEL_8b4a90c54bd3401ba1b3c63bf2e60624",
            "value": "tokenizer.json: 100%"
          }
        },
        "83da4d4ed98448cfaba79cf3dbb97b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7336f93ff05b4b1d9499cb724c984327",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97c0ce3a607344929593f531444608d9",
            "value": 1389353
          }
        },
        "a901710c58db4d988077db16a68f7d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b731c0f3c5fb486eae08b7bda36b45f1",
            "placeholder": "​",
            "style": "IPY_MODEL_7e2a8f5338294cbaa2c4b94a683428c3",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 5.81MB/s]"
          }
        },
        "98a74d0e854d448796907223f4d4c067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cfa0e173ef4a409b676c72b2fb38be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b4a90c54bd3401ba1b3c63bf2e60624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7336f93ff05b4b1d9499cb724c984327": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c0ce3a607344929593f531444608d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b731c0f3c5fb486eae08b7bda36b45f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e2a8f5338294cbaa2c4b94a683428c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50b7ee1c335f4e6bb997cf23b82b94d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_786d7adc1b0f48c3954f2434024da598",
              "IPY_MODEL_71360675a3ce4c21adc2cafb3987e266",
              "IPY_MODEL_f30e01d3594e4ea5a2c2bbce34019a85"
            ],
            "layout": "IPY_MODEL_6f5fa9d79a1244e69a1db6237ff48cb7"
          }
        },
        "786d7adc1b0f48c3954f2434024da598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29397120f48d4fdfa86d5cc94ce7ed0f",
            "placeholder": "​",
            "style": "IPY_MODEL_674b91683da44ad38b730288d8f6004d",
            "value": "Epoch 2: 100%"
          }
        },
        "71360675a3ce4c21adc2cafb3987e266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf91a11034bc42428b1aa82e19b7fdfd",
            "max": 9,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86e422c743f941dfb0ceed20bc499b2f",
            "value": 9
          }
        },
        "f30e01d3594e4ea5a2c2bbce34019a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc7d718b9ee413884a00212382f2f19",
            "placeholder": "​",
            "style": "IPY_MODEL_24f3aecc3a684f02a4ada46e27a05435",
            "value": " 9/9 [03:50&lt;00:00,  0.04it/s, v_num=0, train_loss=2.810]"
          }
        },
        "6f5fa9d79a1244e69a1db6237ff48cb7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "29397120f48d4fdfa86d5cc94ce7ed0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "674b91683da44ad38b730288d8f6004d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf91a11034bc42428b1aa82e19b7fdfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86e422c743f941dfb0ceed20bc499b2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbc7d718b9ee413884a00212382f2f19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24f3aecc3a684f02a4ada46e27a05435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aab7ef64f3654243b2c278b5582f1b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9dcd9195cb53483a9adb9634d11a7fff",
              "IPY_MODEL_f9962f232769452ca3b36d25f487f078",
              "IPY_MODEL_a230afc1087045e787df0eeff8789f46"
            ],
            "layout": "IPY_MODEL_ecc7cdba46df4e4caa07621c8f278957"
          }
        },
        "9dcd9195cb53483a9adb9634d11a7fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1fa305ebd3249c4be6fac76474ba6fc",
            "placeholder": "​",
            "style": "IPY_MODEL_700eef54f3494104b2d3b85e2db3d7be",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "f9962f232769452ca3b36d25f487f078": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87ac2d941d9c43029883b5e661a8e4a8",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c6a5ff4ab2645e5bebdc1e41aacbbf0",
            "value": 4
          }
        },
        "a230afc1087045e787df0eeff8789f46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdad0d82d952430486ff9caba4ccaef6",
            "placeholder": "​",
            "style": "IPY_MODEL_824d5623223b4235a5f4d92ac4c5e37a",
            "value": " 4/4 [02:00&lt;00:00,  0.03it/s]"
          }
        },
        "ecc7cdba46df4e4caa07621c8f278957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "a1fa305ebd3249c4be6fac76474ba6fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "700eef54f3494104b2d3b85e2db3d7be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87ac2d941d9c43029883b5e661a8e4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c6a5ff4ab2645e5bebdc1e41aacbbf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdad0d82d952430486ff9caba4ccaef6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "824d5623223b4235a5f4d92ac4c5e37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7594b5c124734348815c86c0a0a9778d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05d290ebbc5f413bbd49b2e454a3df28",
              "IPY_MODEL_ad02de50ebc6436db2fe05761e004077",
              "IPY_MODEL_8116217cb11545c3af929f303bd7f89b"
            ],
            "layout": "IPY_MODEL_fa2ed9617cbd4ed7938f8cb8650f6184"
          }
        },
        "05d290ebbc5f413bbd49b2e454a3df28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6404f8cbad54336a77be002bd766f07",
            "placeholder": "​",
            "style": "IPY_MODEL_3947a524905940118dbf6652257de300",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "ad02de50ebc6436db2fe05761e004077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_089e14b78f2b41febbc20d7b7c05cdcb",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68259be876cd47b9abf621f740381ed0",
            "value": 4
          }
        },
        "8116217cb11545c3af929f303bd7f89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39a44caa213f4afe9e8f3b5317bd74cd",
            "placeholder": "​",
            "style": "IPY_MODEL_b0fec4f7689c4acdbd47bb52dfac1962",
            "value": " 4/4 [02:48&lt;00:00,  0.02it/s]"
          }
        },
        "fa2ed9617cbd4ed7938f8cb8650f6184": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "c6404f8cbad54336a77be002bd766f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3947a524905940118dbf6652257de300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "089e14b78f2b41febbc20d7b7c05cdcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68259be876cd47b9abf621f740381ed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39a44caa213f4afe9e8f3b5317bd74cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0fec4f7689c4acdbd47bb52dfac1962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4466af3c876c43858bb30a51ee50df6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d2daa64d0d8496aba78e882f2f5350f",
              "IPY_MODEL_1b1f27d5a82a4da0a1234b42001b1cae",
              "IPY_MODEL_8635f661b3ca4904954c6f2e1c8cb1ec"
            ],
            "layout": "IPY_MODEL_7197c89977374941935a3fd2d510f896"
          }
        },
        "9d2daa64d0d8496aba78e882f2f5350f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a890a8b2fcf44e12a77ac6a0f9b2f4b6",
            "placeholder": "​",
            "style": "IPY_MODEL_6f8ac38e5c8440d197c14a946a39b30a",
            "value": "Validation DataLoader 0: 100%"
          }
        },
        "1b1f27d5a82a4da0a1234b42001b1cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff7ed055de414f819f0fbb9765fa575c",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed64cfbac38e443fbad18896c0b4269e",
            "value": 4
          }
        },
        "8635f661b3ca4904954c6f2e1c8cb1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94916c1d14c54595a79bd3b503eef464",
            "placeholder": "​",
            "style": "IPY_MODEL_8fe2aa79fc1840239e807c439c4ea2f2",
            "value": " 4/4 [02:41&lt;00:00,  0.02it/s]"
          }
        },
        "7197c89977374941935a3fd2d510f896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "a890a8b2fcf44e12a77ac6a0f9b2f4b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8ac38e5c8440d197c14a946a39b30a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff7ed055de414f819f0fbb9765fa575c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed64cfbac38e443fbad18896c0b4269e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94916c1d14c54595a79bd3b503eef464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe2aa79fc1840239e807c439c4ea2f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install Requirements"
      ],
      "metadata": {
        "id": "JQJcWGe_AqHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bert_score click keybert matplotlib nltk numpy optuna-integration pandas plotly python_Levenshtein pytorch_lightning rouge sacrebleu sacremoses spacy scikit_learn simalign stanfordnlp summarizer torch torchfile tqdm transformers yattag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAPdN-qWveJ1",
        "outputId": "2dbb5502-c097-4d5a-b5f2-03b4b051561c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bert_score\n",
            "  Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (8.1.7)\n",
            "Collecting keybert\n",
            "  Downloading keybert-0.8.4.tar.gz (29 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Collecting optuna-integration\n",
            "  Downloading optuna_integration-3.6.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.4/93.4 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Collecting python_Levenshtein\n",
            "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.2.3-py3-none-any.whl (802 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m802.2/802.2 kB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting simalign\n",
            "  Downloading simalign-0.4-py3-none-any.whl (8.1 kB)\n",
            "Collecting stanfordnlp\n",
            "  Downloading stanfordnlp-0.2.0-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting summarizer\n",
            "  Downloading summarizer-0.0.7.tar.gz (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.1/280.1 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n",
            "Collecting yattag\n",
            "  Downloading yattag-1.15.2.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.31.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.0)\n",
            "Collecting sentence-transformers>=0.3.8 (from keybert)\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rich>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from keybert) (13.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Collecting optuna (from optuna-integration)\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly) (8.2.3)\n",
            "Collecting Levenshtein==0.25.1 (from python_Levenshtein)\n",
            "  Downloading Levenshtein-0.25.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0 (from Levenshtein==0.25.1->python_Levenshtein)\n",
            "  Downloading rapidfuzz-3.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.3.2-py3-none-any.whl (841 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m841.5/841.5 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.11.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.11.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn) (3.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from simalign) (3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanfordnlp) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning) (3.9.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.4.0->keybert) (2.16.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting alembic>=1.5.0 (from optuna->optuna-integration)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna->optuna-integration)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna->optuna-integration) (2.0.29)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning) (4.0.3)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna->optuna-integration)\n",
            "  Downloading Mako-1.3.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna->optuna-integration) (3.0.3)\n",
            "Building wheels for collected packages: keybert, summarizer, torchfile, yattag\n",
            "  Building wheel for keybert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keybert: filename=keybert-0.8.4-py3-none-any.whl size=39200 sha256=cd2c85764e43c5f04fad41536080b91fe9da0681ddf80acb309d3d09307d1f6c\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/ef/4c/6588bd7072b0cc04225b40e639b991e49ebd4e21fb81f0acee\n",
            "  Building wheel for summarizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summarizer: filename=summarizer-0.0.7-py2.py3-none-any.whl size=284209 sha256=6bc57bee0d54c1eca822d4563ffafeb835e2b6f63ca8caea4638670cfc295dff\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/bb/2d/1fe057c2f729818a5f28c312c3667e8b9d5cfd4af4a39895e7\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5693 sha256=9424acdecd188430871d3bcf5abc9f2654aa968e86e7840bf5f535cecb81b1ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/c7/e9/87/1c51daf8e468d5c14931f8ac3344880f903ba96b063675cac2\n",
            "  Building wheel for yattag (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for yattag: filename=yattag-1.15.2-py3-none-any.whl size=15668 sha256=1319e12a997f28fe509ddb89762ae8ea9cbc897902f649ed0597cedbd49ee686\n",
            "  Stored in directory: /root/.cache/pip/wheels/3f/6e/e5/d526243c27041915f63eacc0804babeb86b6973b0bc1991f06\n",
            "Successfully built keybert summarizer torchfile yattag\n",
            "Installing collected packages: yattag, torchfile, sacremoses, rouge, rapidfuzz, portalocker, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, lightning-utilities, colorlog, colorama, summarizer, sacrebleu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, Levenshtein, alembic, python_Levenshtein, optuna, nvidia-cusolver-cu12, optuna-integration, torchmetrics, stanfordnlp, simalign, sentence-transformers, bert_score, pytorch_lightning, keybert\n",
            "Successfully installed Levenshtein-0.25.1 Mako-1.3.3 alembic-1.13.1 bert_score-0.3.13 colorama-0.4.6 colorlog-6.8.2 keybert-0.8.4 lightning-utilities-0.11.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 optuna-integration-3.6.0 portalocker-2.8.2 python_Levenshtein-0.25.1 pytorch_lightning-2.2.3 rapidfuzz-3.8.1 rouge-1.0.1 sacrebleu-2.4.2 sacremoses-0.1.1 sentence-transformers-2.7.0 simalign-0.4 stanfordnlp-0.2.0 summarizer-0.0.7 torchfile-0.1.0 torchmetrics-1.3.2 yattag-1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EASSE Library"
      ],
      "metadata": {
        "id": "XiYHNd_ZtQYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/feralvam/easse.git"
      ],
      "metadata": {
        "id": "d5zVHpYL2ftc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f77dea83-f584-4bfa-fcb7-8e44fc64ffb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'easse'...\n",
            "remote: Enumerating objects: 1964, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
            "remote: Total 1964 (delta 109), reused 96 (delta 96), pack-reused 1827\u001b[K\n",
            "Receiving objects: 100% (1964/1964), 33.15 MiB | 13.91 MiB/s, done.\n",
            "Resolving deltas: 100% (1231/1231), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/easse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGU2bo1e3N3-",
        "outputId": "6f3c2270-bf24-4ebe-d4cf-d25885cd0cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/easse\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYG6R4d53hCN",
        "outputId": "50e71798-50df-47af-aa78-d09db2a347b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/easse\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main (from easse==0.2.4)\n",
            "  Cloning https://github.com/facebookresearch/text-simplification-evaluation.git (to revision main) to /tmp/pip-install-gk0ri4v_/tseval_3f1c74c984624274bb8442dff03b251e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/text-simplification-evaluation.git /tmp/pip-install-gk0ri4v_/tseval_3f1c74c984624274bb8442dff03b251e\n",
            "  Resolved https://github.com/facebookresearch/text-simplification-evaluation.git to commit dea8863683ea5946fd50184883c9be7a7339e821\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (8.1.7)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (3.7.1)\n",
            "Requirement already satisfied: nltk>=3.6.5 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (2.31.0)\n",
            "Requirement already satisfied: sacrebleu>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (2.4.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.1.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (1.2.2)\n",
            "Requirement already satisfied: stanfordnlp in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.2.0)\n",
            "Requirement already satisfied: tqdm>=4.32.2 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (4.66.2)\n",
            "Requirement already satisfied: yattag in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (1.15.2)\n",
            "Requirement already satisfied: plotly>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (5.15.0)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.3.13)\n",
            "Requirement already satisfied: simalign in /usr/local/lib/python3.10/dist-packages (from easse==0.2.4) (0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->easse==0.2.4) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.6.5->easse==0.2.4) (2023.12.25)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->easse==0.2.4) (8.2.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from plotly>=4.0.0->easse==0.2.4) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->easse==0.2.4) (2024.2.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (2.8.2)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (0.9.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=2.0.0->easse==0.2.4) (4.9.4)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score->easse==0.2.4) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score->easse==0.2.4) (4.40.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->easse==0.2.4) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easse==0.2.4) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->easse==0.2.4) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->easse==0.2.4) (3.1.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->easse==0.2.4) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->easse==0.2.4) (3.4.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from simalign->easse==0.2.4) (3.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from stanfordnlp->easse==0.2.4) (3.20.3)\n",
            "Requirement already satisfied: python-Levenshtein in /usr/local/lib/python3.10/dist-packages (from tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4) (0.25.1)\n",
            "Collecting gitpython (from tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->easse==0.2.4) (1.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score->easse==0.2.4) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0.0->bert_score->easse==0.2.4) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (6.0.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score->easse==0.2.4) (0.4.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Levenshtein==0.25.1 in /usr/local/lib/python3.10/dist-packages (from python-Levenshtein->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4) (0.25.1)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from Levenshtein==0.25.1->python-Levenshtein->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4) (3.8.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython->tseval@ git+https://github.com/facebookresearch/text-simplification-evaluation.git@main->easse==0.2.4)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score->easse==0.2.4) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.0.0->bert_score->easse==0.2.4) (1.3.0)\n",
            "Building wheels for collected packages: tseval\n",
            "  Building wheel for tseval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tseval: filename=tseval-1.0-py3-none-any.whl size=8522217 sha256=27fcaeae30ef70ac315bfbde79e9935c5c2a04693fe2ae598f61a92c560ccf64\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-v7elcrfw/wheels/89/be/e9/c9b30865c44c542db11cefa3afb9fb31d1f7136f5093d2e0b4\n",
            "Successfully built tseval\n",
            "Installing collected packages: smmap, gitdb, gitpython, tseval, easse\n",
            "  Running setup.py develop for easse\n",
            "Successfully installed easse-0.2.4 gitdb-4.0.11 gitpython-3.1.43 smmap-5.0.1 tseval-1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqkHgWfp3qs9",
        "outputId": "fc220478-afd5-4100-b6b4-3709a5121415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "root_dir = '/content/'\n",
        "out_dir = os.path.join(root_dir, 'easse')\n",
        "inner_easse_dir = os.path.join(root_dir, 'easse', 'easse')\n",
        "\n",
        "if os.path.exists(out_dir):\n",
        "\n",
        "    # Move the contents of the inner easse folder back to 'easse'\n",
        "    if os.path.exists(inner_easse_dir):\n",
        "        inner_easse_files = os.listdir(inner_easse_dir)\n",
        "        for file in inner_easse_files:\n",
        "            src = os.path.join(inner_easse_dir, file)\n",
        "            dst = os.path.join(root_dir, 'easse', file)\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "        os.rmdir(inner_easse_dir)"
      ],
      "metadata": {
        "id": "N_9vBu1-_mX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessor"
      ],
      "metadata": {
        "id": "j8c9Pdrpzdoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optparse\n",
        "import os\n",
        "from pathlib import Path\n",
        "import sys\n",
        "from functools import lru_cache\n",
        "from multiprocessing import Pool, Lock\n",
        "from string import punctuation\n",
        "import multiprocessing\n",
        "import Levenshtein\n",
        "import numpy as np\n",
        "import spacy\n",
        "import nltk\n",
        "import shutil\n",
        "import time\n",
        "import pickle\n",
        "import hashlib\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import re\n",
        "from sacremoses import MosesDetokenizer, MosesTokenizer\n",
        "\n",
        "EXP_DIR = '/content/experiments'\n",
        "DUMPS_DIR = '/content/dumps'\n",
        "\n",
        "PSAT = 'PSAT'\n",
        "\n",
        "LANGUAGES = ['complex', 'simple']\n",
        "PHASES = ['train','valid']\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "\n",
        "#######################\n",
        "def get_tokenizer():\n",
        "    return MosesTokenizer(lang='en')\n",
        "\n",
        "def get_detokenizer():\n",
        "    return MosesDetokenizer(lang='en')\n",
        "\n",
        "def tokenize(sentence):\n",
        "    return get_tokenizer().tokenize(sentence)\n",
        "\n",
        "def write_lines(lines, filepath):\n",
        "    filepath = Path(filepath)\n",
        "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
        "    with filepath.open(\"w\") as fout:\n",
        "        for line in lines:\n",
        "            fout.write(line + '\\n')\n",
        "\n",
        "\n",
        "def read_lines(filepath):\n",
        "    return [line.rstrip() for line in yield_lines(filepath)]\n",
        "\n",
        "\n",
        "def yield_lines(filepath):\n",
        "    filepath = Path(filepath)\n",
        "    with filepath.open('r') as f:\n",
        "        for line in f:\n",
        "            yield line.rstrip()\n",
        "\n",
        "\n",
        "def yield_sentence_pair_with_index(filepath1, filepath2):\n",
        "    index = 0\n",
        "    with Path(filepath1).open('r') as f1, Path(filepath2).open('r') as f2:\n",
        "        for line1, line2 in zip(f1, f2):\n",
        "            index += 1\n",
        "            yield (line1.rstrip(), line2.rstrip(), index)\n",
        "\n",
        "\n",
        "def yield_sentence_pair(filepath1, filepath2):\n",
        "    with Path(filepath1).open('r') as f1, Path(filepath2).open('r') as f2:\n",
        "        for line1, line2 in zip(f1, f2):\n",
        "            yield line1.rstrip(), line2.rstrip()\n",
        "\n",
        "\n",
        "def count_line(filepath):\n",
        "    filepath = Path(filepath)\n",
        "    line_count = 0\n",
        "    with filepath.open(\"r\") as f:\n",
        "        for line in f:\n",
        "            line_count += 1\n",
        "    return line_count\n",
        "\n",
        "\n",
        "def load_dump(filepath):\n",
        "    return pickle.load(open(filepath, 'rb'))\n",
        "\n",
        "\n",
        "def dump(obj, filepath):\n",
        "    pickle.dump(obj, open(filepath, 'wb'))\n",
        "\n",
        "def save_preprocessor(preprocessor):\n",
        "    DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "    PREPROCESSOR_DUMP_FILE = f'{DUMPS_DIR}/preprocessor.pickle'\n",
        "    dump(preprocessor, PREPROCESSOR_DUMP_FILE)\n",
        "\n",
        "\n",
        "def load_preprocessor():\n",
        "    PREPROCESSOR_DUMP_FILE = f'{DUMPS_DIR}/preprocessor.pickle'\n",
        "    if os.path.exists(PREPROCESSOR_DUMP_FILE):\n",
        "        return load_dump(PREPROCESSOR_DUMP_FILE)\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def generate_hash(data):\n",
        "    h = hashlib.new('md5')\n",
        "    h.update(str(data).encode())\n",
        "    return h.hexdigest()\n",
        "\n",
        "def get_data_filepath(dataset, phase, type, i=None):\n",
        "    suffix = ''\n",
        "    if i is not None:\n",
        "        suffix = f'.{i}'\n",
        "    filename = f'{dataset}.{phase}.{type}{suffix}'\n",
        "    return f'/content/{dataset}/{filename}'\n",
        "\n",
        "#################################\n",
        "\n",
        "def round(val):\n",
        "    return '%.2f' % val\n",
        "\n",
        "\n",
        "def safe_division(a, b):\n",
        "    return a / b if b else 0\n",
        "\n",
        "\n",
        "# def tokenize(sentence):\n",
        "#     return sentence.split()\n",
        "\n",
        "def is_punctuation(word):\n",
        "    return ''.join([char for char in word if char not in punctuation]) == ''\n",
        "\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    return ' '.join([word for word in tokenize(text) if not is_punctuation(word)])\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    return ' '.join([w for w in tokenize(text) if w.lower() not in stopwords])\n",
        "\n",
        "\n",
        "def get_dependency_tree_depth(sentence):\n",
        "    def tree_height(node):\n",
        "        if len(list(node.children)) == 0:\n",
        "            return 0\n",
        "        return 1 + max(tree_height(child) for child in node.children)\n",
        "\n",
        "    tree_depths = [tree_height(spacy_sentence.root) for spacy_sentence in spacy_process(sentence).sents]\n",
        "    if len(tree_depths) == 0:\n",
        "        return 0\n",
        "    return max(tree_depths)\n",
        "\n",
        "def get_spacy_model():\n",
        "    model = 'en_core_web_sm'\n",
        "    if not spacy.util.is_package(model):\n",
        "        spacy.cli.download(model)\n",
        "        spacy.cli.link(model, model, force=True, model_path=spacy.util.get_package_path(model))\n",
        "    return spacy.load(model)\n",
        "\n",
        "\n",
        "def spacy_process(text):\n",
        "    return get_spacy_model()(str(text))\n",
        "\n",
        "\n",
        "def get_word2rank(vocab_size=np.inf):\n",
        "    model_filepath = f'{DUMPS_DIR}/{WORD_EMBEDDINGS_NAME}.pk'\n",
        "    if model_filepath.exists():\n",
        "        return load_dump(model_filepath)\n",
        "\n",
        "\n",
        "def get_normalized_rank(word):\n",
        "    max = len(get_word2rank())\n",
        "    rank = get_word2rank().get(word, max)\n",
        "    return np.log(1 + rank) / np.log(1 + max)\n",
        "\n",
        "\n",
        "\n",
        "def get_complexity_score2(sentence):\n",
        "    words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
        "    words = [word for word in words if word in get_word2rank()]  # remove unknown words\n",
        "    if len(words) == 0:\n",
        "        return 1.0\n",
        "    return np.array([get_normalized_rank(word) for word in words]).mean()\n",
        "\n",
        "def get_word_frequency():\n",
        "    model_filepath = f'{DUMPS_DIR}/{WORD_FREQUENCY_FILEPATH.stem}.pk'\n",
        "    if model_filepath.exists():\n",
        "        return load_dump(model_filepath)\n",
        "    else:\n",
        "        DUMPS_DIR.mkdir(parents=True, exist_ok=True)\n",
        "        word_freq = {}\n",
        "        for line in yield_lines(WORD_FREQUENCY_FILEPATH):\n",
        "            chunks = line.split(' ')\n",
        "            word = chunks[0]\n",
        "            freq = int(chunks[1])\n",
        "            word_freq[word] = freq\n",
        "        dump(word_freq, model_filepath)\n",
        "        return word_freq\n",
        "\n",
        "\n",
        "def get_normalized_inverse_frequency(word):\n",
        "    max = 153141437 # the 153141437, the max frequency\n",
        "    freq = get_word_frequency().get(word, 0)\n",
        "    return 1.0 - np.log(1 + freq) / np.log(1 + max)\n",
        "\n",
        "\n",
        "def get_complexity_score(sentence, operation_type = None):\n",
        "    words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
        "    #words = tokenize(remove_punctuation(sentence))\n",
        "    words = [word for word in words if word in get_word2rank()]  # remove unknown words\n",
        "    if len(words) == 0:\n",
        "        return 1.0\n",
        "    if operation_type == 'mean':\n",
        "        return np.array([get_normalized_inverse_frequency(word.lower()) for word in words]).mean()\n",
        "    else:\n",
        "        return np.array([get_normalized_inverse_frequency(word.lower()) for word in words]).max()\n",
        "\n",
        "class RatioFeature:\n",
        "    def __init__(self, feature_extractor, target_ratio=0.8):\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.target_ratio = target_ratio\n",
        "\n",
        "    def encode_sentence(self, sentence):\n",
        "        return f'{self.name}_{self.target_ratio}'\n",
        "\n",
        "    def encode_sentence_pair(self, complex_sentence, simple_sentence):\n",
        "        return f'{self.name}_{self.feature_extractor(complex_sentence, simple_sentence)}', simple_sentence\n",
        "\n",
        "    def decode_sentence(self, encoded_sentence):\n",
        "        return encoded_sentence\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        class_name = self.__class__.__name__.replace('RatioFeature', '')\n",
        "        name = \"\"\n",
        "        for word in re.findall('[A-Z][^A-Z]*', class_name):\n",
        "            if word: name += word[0]\n",
        "        if not name: name = class_name\n",
        "        return name\n",
        "\n",
        "### tokens features ###\n",
        "class WordRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_word_length_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_word_length_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(safe_division(len(tokenize(simple_sentence)), len(tokenize(complex_sentence))))\n",
        "\n",
        "\n",
        "class CharRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_char_length_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_char_length_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(safe_division(len(simple_sentence), len(complex_sentence)))\n",
        "\n",
        "\n",
        "class LevenshteinRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_levenshtein_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_levenshtein_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(Levenshtein.ratio(complex_sentence, simple_sentence))\n",
        "\n",
        "\n",
        "class WordRankRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_word_rank_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_word_rank_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(min(safe_division(self.get_lexical_complexity_score(simple_sentence),\n",
        "                                       self.get_lexical_complexity_score(complex_sentence)), 2))\n",
        "\n",
        "    def get_lexical_complexity_score(self, sentence):\n",
        "        words = tokenize(remove_stopwords(remove_punctuation(sentence)))\n",
        "        words = [word for word in words if word in get_word2rank()]\n",
        "        if len(words) == 0:\n",
        "            return np.log(1 + len(get_word2rank()))\n",
        "        return np.quantile([self.get_rank(word) for word in words], 0.75)\n",
        "\n",
        "\n",
        "    def get_rank(self, word):\n",
        "        # return get_normalized_inverse_frequency(word)\n",
        "        rank = get_word2rank().get(word, len(get_word2rank()))\n",
        "        return np.log(1 + rank)\n",
        "\n",
        "\n",
        "class DependencyTreeDepthRatioFeature(RatioFeature):\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__(self.get_dependency_tree_depth_ratio, *args, **kwargs)\n",
        "\n",
        "    def get_dependency_tree_depth_ratio(self, complex_sentence, simple_sentence):\n",
        "        return round(\n",
        "            safe_division(self.get_dependency_tree_depth(simple_sentence),\n",
        "                          self.get_dependency_tree_depth(complex_sentence)))\n",
        "\n",
        "\n",
        "    def get_dependency_tree_depth(self, sentence):\n",
        "        def get_subtree_depth(node):\n",
        "            if len(list(node.children)) == 0:\n",
        "                return 0\n",
        "            return 1 + max([get_subtree_depth(child) for child in node.children])\n",
        "\n",
        "        tree_depths = [get_subtree_depth(spacy_sentence.root) for spacy_sentence in self.spacy_process(sentence).sents]\n",
        "        if len(tree_depths) == 0:\n",
        "            return 0\n",
        "        return max(tree_depths)\n",
        "\n",
        "    def spacy_process(self, text):\n",
        "        return get_spacy_model()(text)\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self, features_kwargs=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.features = self.get_features(features_kwargs)\n",
        "        if features_kwargs:\n",
        "            self.hash = generate_hash(str(features_kwargs).encode())\n",
        "        else:\n",
        "            self.hash = \"no_feature\"\n",
        "\n",
        "    def get_class(self, class_name, *args, **kwargs):\n",
        "        return globals()[class_name](*args, **kwargs)\n",
        "\n",
        "    def get_features(self, feature_kwargs):\n",
        "        features = []\n",
        "        for feature_name, kwargs in feature_kwargs.items():\n",
        "            features.append(self.get_class(feature_name, **kwargs))\n",
        "        return features\n",
        "\n",
        "    def encode_sentence(self, sentence):\n",
        "        if self.features:\n",
        "            line = ''\n",
        "            for feature in self.features:\n",
        "                line += feature.encode_sentence(sentence) + ' '\n",
        "            line += ' ' + sentence\n",
        "            return line.rstrip()\n",
        "        else:\n",
        "            return sentence\n",
        "\n",
        "    def encode_sentence_pair(self, complex_sentence, simple_sentence):\n",
        "        # print(complex_sentence)\n",
        "        if self.features:\n",
        "            line = ''\n",
        "            for feature in self.features:\n",
        "                # startTime = timeit.default_timer()\n",
        "                # print(feature)\n",
        "                processed_complex, _ = feature.encode_sentence_pair(complex_sentence, simple_sentence)\n",
        "                line += processed_complex + ' '\n",
        "                # print(feature, timeit.default_timer() - startTime)\n",
        "            line += ' ' + complex_sentence\n",
        "            return line.rstrip()\n",
        "\n",
        "        else:\n",
        "            return complex_sentence\n",
        "\n",
        "    def decode_sentence(self, encoded_sentence):\n",
        "        for feature in self.features:\n",
        "            decoded_sentence = feature.decode_sentence(encoded_sentence)\n",
        "        return decoded_sentence\n",
        "\n",
        "    def encode_file(self, input_filepath, output_filepath):\n",
        "        with open(output_filepath, 'w') as f:\n",
        "            for line in yield_lines(input_filepath):\n",
        "                f.write(self.encode_sentence(line) + '\\n')\n",
        "\n",
        "    def decode_file(self, input_filepath, output_filepath):\n",
        "        with open(output_filepath, 'w') as f:\n",
        "            for line in yield_lines(input_filepath):\n",
        "                f.write(self.decode_sentence(line) + '\\n')\n",
        "\n",
        "    def process_encode_sentence_pair(self, sentences):\n",
        "        print(f\"{sentences[2]}/{self.line_count}\", sentences[0])  # sentence[0] index\n",
        "        return (self.encode_sentence_pair(sentences[0], sentences[1]))\n",
        "\n",
        "    def pool_encode_sentence_pair(self, args):\n",
        "        # print(f\"{processed_line_count}/{self.line_count}\")\n",
        "        complex_sent, simple_sent, queue = args\n",
        "        queue.put(1)\n",
        "        return self.encode_sentence_pair(complex_sent, simple_sent)\n",
        "\n",
        "\n",
        "    def encode_file_pair(self, complex_filepath, simple_filepath):\n",
        "        processed_complex_sentences = []\n",
        "        self.line_count = count_line(simple_filepath)\n",
        "\n",
        "        i = 0\n",
        "        for complex_sentence, simple_sentence in yield_sentence_pair(complex_filepath, simple_filepath):\n",
        "        # print(complex_sentence)\n",
        "            processed_complex_sentence = self.encode_sentence_pair(complex_sentence, simple_sentence)\n",
        "            i +=1\n",
        "            print(f\"{i}/{self.line_count}\", processed_complex_sentence)\n",
        "            processed_complex_sentences.append(processed_complex_sentence)\n",
        "\n",
        "        return processed_complex_sentences\n",
        "\n",
        "    def get_preprocessed_filepath(self, dataset, phase, type):\n",
        "        filename = f'{dataset}.{phase}.{type}'\n",
        "        return f'{self.preprocessed_data_dir}/{filename}'\n",
        "\n",
        "    def preprocess_dataset(self, dataset):\n",
        "        # download_requirements()\n",
        "        self.preprocessed_data_dir = f'{PROCESSED_DATA_DIR}/{self.hash}/{dataset}'\n",
        "        #self.preprocessed_data_dir.mkdir(parents=True, exist_ok=True)\n",
        "        os.makedirs(self.preprocessed_data_dir, exist_ok=True)\n",
        "        save_preprocessor(self)\n",
        "        print(f'Preprocessing dataset: {dataset}')\n",
        "\n",
        "        for phase in PHASES:\n",
        "            # for phase in [\"valid\", \"test\"]:\n",
        "            complex_filepath = get_data_filepath(dataset, phase, 'complex')\n",
        "            simple_filepath = get_data_filepath(dataset, phase, 'simple')\n",
        "\n",
        "            complex_output_filepath = f'{self.preprocessed_data_dir}/{complex_filepath.name}'\n",
        "            simple_output_filepath = f'{self.preprocessed_data_dir}/{simple_filepath.name}'\n",
        "            if complex_output_filepath.exists() and simple_output_filepath.exists():\n",
        "                continue\n",
        "\n",
        "            print(f'Prepocessing files: {complex_filepath.name} {simple_filepath.name}')\n",
        "            processed_complex_sentences = self.encode_file_pair(complex_filepath, simple_filepath)\n",
        "\n",
        "            write_lines(processed_complex_sentences, complex_output_filepath)\n",
        "            shutil.copy(simple_filepath, simple_output_filepath)\n",
        "\n",
        "        print(f'Preprocessing dataset \"{dataset}\" is finished.')\n",
        "        return self.preprocessed_data_dir\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    features_kwargs = {\n",
        "        # 'WordRatioFeature': {'target_ratio': 0.8},\n",
        "        'CharRatioFeature': {'target_ratio': 0.8},\n",
        "        'LevenshteinRatioFeature': {'target_ratio': 0.8},\n",
        "        'WordRankRatioFeature': {'target_ratio': 0.8},\n",
        "        'DependencyTreeDepthRatioFeature': {'target_ratio': 0.8}\n",
        "    }\n",
        "\n",
        "    preprocessor = load_preprocessor()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifsZllxTw_41",
        "outputId": "a2c8af72-8cdb-4bb9-bb8a-a8e01fa72044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SimSum T5 Model"
      ],
      "metadata": {
        "id": "agAqxZaaWLR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import lru_cache\n",
        "from gc import callbacks\n",
        "from lib2to3.pgen2 import token\n",
        "from pathlib import Path\n",
        "from weakref import ref\n",
        "import math\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "from easse.sari import corpus_sari\n",
        "from torch.nn import functional as F\n",
        "# import Levenshtein\n",
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "import os\n",
        "import logging\n",
        "import random\n",
        "import nltk\n",
        "# from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.trainer import seed_everything\n",
        "from transformers import (\n",
        "    T5ForConditionalGeneration,\n",
        "    T5TokenizerFast,\n",
        "    BertTokenizer, BertForPreTraining,\n",
        "    BartForConditionalGeneration, BartTokenizer,pipeline,BartTokenizerFast, BartModel,\n",
        "    get_linear_schedule_with_warmup, AutoConfig, AutoModel,\n",
        "    get_cosine_schedule_with_warmup,\n",
        ")\n",
        "#from sentence_transformers import SentenceTransformer\n",
        "# from keybert import KeyBERT\n",
        "#kw_model = KeyBERT()\n",
        "#BERT_Sum = Summarizer(model='distilbert-base-uncased')\n",
        "\n",
        "class MetricsCallback(pl.Callback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.metrics = []\n",
        "\n",
        "  def on_validation_end(self, trainer, pl_module):\n",
        "      self.metrics.append(trainer.callback_metrics)\n",
        "\n",
        "class SumSim(pl.LightningModule):\n",
        "    def __init__(self,args):\n",
        "        super(SumSim, self).__init__()\n",
        "        self.args = args\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        self.summarizer = T5ForConditionalGeneration.from_pretrained(self.args.sum_model)\n",
        "        self.summarizer = self.summarizer.to(self.args.device)\n",
        "        self.summarizer_tokenizer = T5TokenizerFast.from_pretrained(self.args.sum_model)\n",
        "\n",
        "        self.simplifier = T5ForConditionalGeneration.from_pretrained(self.args.sim_model)\n",
        "        self.simplifier = self.simplifier.to(self.args.device)\n",
        "        self.simplifier_tokenizer = T5TokenizerFast.from_pretrained(self.args.sim_model)\n",
        "\n",
        "        self.W = torch.randn((768, int(self.args.hidden_size)), requires_grad=True, device = self.args.device)\n",
        "\n",
        "        self.CosSim = nn.CosineSimilarity(dim = 2, eps = 1e-6)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "\n",
        "    def is_logger(self):\n",
        "        return self.trainer.global_rank <= 0\n",
        "\n",
        "    def forward(self, input_ids,\n",
        "    attention_mask = None,\n",
        "    decoder_input_ids = None,\n",
        "    decoder_attention_mask = None, labels = None):\n",
        "\n",
        "        outputs = self.simplifier(\n",
        "            input_ids = input_ids,\n",
        "            attention_mask = attention_mask,\n",
        "            decoder_input_ids = decoder_input_ids,\n",
        "            decoder_attention_mask =  decoder_attention_mask,\n",
        "            labels = labels\n",
        "        )\n",
        "\n",
        "        return outputs\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        source = batch[\"source\"]\n",
        "        labels = batch['target_ids']\n",
        "        targets = batch['target']\n",
        "        labels[labels[:,:] == self.simplifier_tokenizer.pad_token_id] = -100\n",
        "        # zero the gradient buffers of all parameters\n",
        "        self.opt.zero_grad()\n",
        "        #print(source, len(source))\n",
        "\n",
        "        #### tokenize targets\n",
        "        targets_encoding = self.simplifier_tokenizer(\n",
        "            targets,\n",
        "            max_length = 256,\n",
        "            truncation = True,\n",
        "            padding = 'max_length',\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "        tgt_ids = targets_encoding['input_ids'].to(self.args.device)\n",
        "        tgt_mask = targets_encoding['attention_mask'].to(self.args.device)\n",
        "\n",
        "        tgt_output = self.simplifier(\n",
        "            input_ids =  tgt_ids,\n",
        "            attention_mask = tgt_mask,\n",
        "            labels = labels,\n",
        "            decoder_attention_mask = batch['target_mask']\n",
        "        )\n",
        "        H_sim = tgt_output.encoder_last_hidden_state\n",
        "\n",
        "\n",
        "        ## summarizer stage\n",
        "        inputs = self.summarizer_tokenizer(\n",
        "            source,\n",
        "            max_length = 512, # 1024\n",
        "            truncation = True,\n",
        "            padding = 'max_length',\n",
        "            return_tensors = 'pt'\n",
        "        )#.to(self.args.device)\n",
        "\n",
        "\n",
        "        src_ids = inputs['input_ids'].to(self.args.device)\n",
        "        src_mask = inputs['attention_mask'].to(self.args.device)\n",
        "\n",
        "\n",
        "        # compute the loss between summarization and simplification target\n",
        "        # sum_outputs.loss\n",
        "\n",
        "        sum_outputs = self.summarizer(\n",
        "            input_ids = src_ids,\n",
        "            attention_mask  = src_mask,\n",
        "            labels = labels,\n",
        "            decoder_attention_mask = batch['target_mask']\n",
        "        )\n",
        "\n",
        "        H1 = sum_outputs.encoder_last_hidden_state\n",
        "\n",
        "        # generate summary\n",
        "        summary_ids = self.summarizer.generate(\n",
        "            inputs['input_ids'].to(self.args.device),\n",
        "            do_sample = True,\n",
        "            num_beams = 5,\n",
        "            min_length = 10,\n",
        "            max_length = 256, # 512\n",
        "        ).to(self.args.device)\n",
        "\n",
        "\n",
        "        # add 'simplify: ' ids\n",
        "        # 18356, 10\n",
        "        for i, summary_id in enumerate(summary_ids):\n",
        "            added_tokens = torch.tensor([18356, 10]).to(self.args.device)\n",
        "            summary_ids[i] = torch.cat((added_tokens, summary_id), dim=0)[:-2]\n",
        "\n",
        "        ### Original loss\n",
        "        # summary_attention_mask = torch.ones(summary_ids.shape).to(self.args.device)\n",
        "        # summary_attention_mask[summary_ids[:,:]==self.summarizer_tokenizer.pad_token_id]=0\n",
        "\n",
        "        ### modified loss\n",
        "        padded_summary_ids = torch.zeros((summary_ids.shape[0], 256), dtype = torch.long).fill_(self.simplifier_tokenizer.pad_token_id).to(self.args.device)\n",
        "        for i, summary_id in enumerate(summary_ids):\n",
        "            padded_summary_ids[i,:summary_id.shape[0]]=summary_id\n",
        "\n",
        "        summary_attention_mask = torch.ones(padded_summary_ids.shape).to(self.args.device)\n",
        "        summary_attention_mask[padded_summary_ids[:,:]==self.summarizer_tokenizer.pad_token_id]=0\n",
        "\n",
        "        # forward pass\n",
        "        sim_outputs  = self(\n",
        "            # summary_ids -> padded\n",
        "            input_ids = padded_summary_ids, #padded_summary_ids for padded, summary_ids otherwise\n",
        "            attention_mask = summary_attention_mask,\n",
        "            labels = labels,\n",
        "            decoder_attention_mask = batch['target_mask']\n",
        "        )\n",
        "\n",
        "        H2 = sim_outputs.encoder_last_hidden_state\n",
        "\n",
        "        Rep1 = torch.matmul(H_sim, self.W)\n",
        "        Rep2 = torch.matmul(H2, self.W)\n",
        "        Rep1 = self.relu(Rep1)\n",
        "        Rep2 = self.relu(Rep2)\n",
        "        Rep1 = H_sim\n",
        "        Rep2 = H2\n",
        "\n",
        "        sim_score = self.CosSim(Rep1, Rep2)\n",
        "\n",
        "        ###################\n",
        "\n",
        "\n",
        "        if self.args.custom_loss:\n",
        "\n",
        "\n",
        "            loss = sim_outputs.loss * self.args.w1\n",
        "            #loss += sum_outputs.loss * self.args.w2\n",
        "\n",
        "            ### CosSim ###\n",
        "            loss += (-self.args.lambda_ * (sim_score.mean(dim=1).mean(dim=0)))\n",
        "\n",
        "\n",
        "            self.log('train_loss', sim_outputs.loss, on_step=True, prog_bar=True, logger=True)\n",
        "            # print(loss)\n",
        "            return loss\n",
        "        else:\n",
        "            loss = sim_outputs.loss\n",
        "            self.log('train_loss', loss, on_step=True, prog_bar=True, logger=True)\n",
        "            #print(loss)\n",
        "            return loss\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss = self.sari_validation_step(batch)\n",
        "        # loss = self._step(batch)\n",
        "        print(\"Val_loss\", loss)\n",
        "        logs = {\"val_loss\": loss}\n",
        "\n",
        "        self.log('val_loss', loss, batch_size = self.args.valid_batch_size)\n",
        "        return torch.tensor(loss, dtype=float)\n",
        "\n",
        "    def sari_validation_step(self, batch):\n",
        "        def generate(sentence):\n",
        "            #sentence = self.preprocessor.encode_sentence(sentence)\n",
        "\n",
        "            text = \"summarize: \" + sentence\n",
        "            # summarize the document\n",
        "            inputs = self.summarizer_tokenizer(\n",
        "            [text],\n",
        "            max_length = 512, #1024\n",
        "            truncation = True,\n",
        "            padding = 'max_length',\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "            # generate summary\n",
        "            summary_ids = self.summarizer.generate(\n",
        "                inputs['input_ids'].to(self.args.device),\n",
        "                num_beams = 15,\n",
        "                #min_length = 30,\n",
        "                max_length = 256, # 512\n",
        "                top_k = 130, top_p = 0.95\n",
        "            ).to(self.args.device)\n",
        "\n",
        "            for i, summary_id in enumerate(summary_ids):\n",
        "                add_tokens = torch.tensor([18356, 10]).to(self.args.device)\n",
        "                summary_ids[i,:] = torch.cat((summary_id, add_tokens), dim=0)[:-2]\n",
        "\n",
        "            summary_attention_mask = torch.ones(summary_ids.shape).to(self.args.device)\n",
        "            summary_attention_mask[summary_ids[:,:]==self.summarizer_tokenizer.pad_token_id]=0\n",
        "\n",
        "\n",
        "            # set top_k = 130 and set top_p = 0.95 and num_return_sequences = 1\n",
        "            beam_outputs = self.simplifier.generate(\n",
        "                input_ids=summary_ids,\n",
        "                attention_mask=summary_attention_mask,\n",
        "                do_sample=True,\n",
        "                max_length=256,#512\n",
        "                num_beams=2,\n",
        "                top_k=80,\n",
        "                top_p=0.90,\n",
        "                early_stopping=True,\n",
        "                num_return_sequences=1\n",
        "            ).to(self.device)\n",
        "            # final_outputs = []\n",
        "            # for beam_output in beam_outputs:\n",
        "\n",
        "            sent  = self.simplifier_tokenizer.decode(beam_outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "            # if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
        "                # final_outputs.append(sent)\n",
        "\n",
        "            return sent\n",
        "\n",
        "        pred_sents = []\n",
        "        for source in batch[\"source\"]:\n",
        "            pred_sent = generate(source)\n",
        "            pred_sents.append(pred_sent)\n",
        "\n",
        "        score = corpus_sari(batch[\"source\"], pred_sents, [batch[\"targets\"]])\n",
        "\n",
        "\n",
        "        print(\"Sari score: \", score)\n",
        "\n",
        "        return 1 - score / 100\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
        "\n",
        "        model1 = self.summarizer\n",
        "        model2 = self.simplifier\n",
        "        no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "        optimizer_grouped_parameters = [\n",
        "            {\n",
        "                \"params\": [p for n, p in model2.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                                \"weight_decay\": self.args.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model2.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model1.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "                                \"weight_decay\": self.args.weight_decay,\n",
        "            },\n",
        "            {\n",
        "                \"params\": [p for n, p in model1.named_parameters() if any(nd in n for nd in no_decay)],\n",
        "                \"weight_decay\": 0.0,\n",
        "            },\n",
        "            {\n",
        "                \"params\": self.W\n",
        "            },\n",
        "        ]\n",
        "        optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=self.args.learning_rate, eps=self.args.adam_epsilon)\n",
        "        self.opt = optimizer\n",
        "        return [optimizer]\n",
        "\n",
        "    def optimizer_step(self, epoch=None, batch_idx=None, optimizer=None,optimizer_closure=None):\n",
        "        optimizer.step(closure=optimizer_closure)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        self.lr_scheduler.step()\n",
        "\n",
        "    def save_core_model(self):\n",
        "      tmp = self.args.model_name + 'core'\n",
        "      store_path = f'/content/experiments/{tmp}'\n",
        "      self.model.save_pretrained(store_path)\n",
        "      self.simplifier_tokenizer.save_pretrained(store_path)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        train_dataset = TrainDataset(dataset=self.args.dataset,\n",
        "                                     tokenizer=self.simplifier_tokenizer,\n",
        "                                     max_len=self.args.max_seq_length,\n",
        "                                     sample_size=self.args.train_sample_size)\n",
        "\n",
        "        dataloader = DataLoader(train_dataset,\n",
        "                                batch_size=self.args.train_batch_size,\n",
        "                                drop_last=True,\n",
        "                                shuffle=True,\n",
        "                                pin_memory=True,\n",
        "                                num_workers=2)\n",
        "        t_total = ((len(dataloader.dataset) // (self.args.train_batch_size * max(1, self.args.n_gpu)))\n",
        "                   // self.args.gradient_accumulation_steps\n",
        "                   * float(self.args.num_train_epochs)\n",
        "                   )\n",
        "        # scheduler = get_linear_schedule_with_warmup(\n",
        "        #     self.opt, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total\n",
        "        # )\n",
        "        scheduler = get_cosine_schedule_with_warmup(\n",
        "            self.opt, num_warmup_steps=self.args.warmup_steps, num_training_steps=t_total\n",
        "        )\n",
        "        self.lr_scheduler = scheduler\n",
        "        return dataloader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        val_dataset = ValDataset(dataset=self.args.dataset,\n",
        "                                 tokenizer=self.simplifier_tokenizer,\n",
        "                                 max_len=self.args.max_seq_length,\n",
        "                                 sample_size=self.args.valid_sample_size)\n",
        "        return DataLoader(val_dataset,\n",
        "                          batch_size=self.args.valid_batch_size,\n",
        "                          num_workers=2)\n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parent_parser):\n",
        "      p = ArgumentParser(parents=[parent_parser],add_help = False)\n",
        "      p.add_argument('-HiddenSize','--hidden_size',type=int, default = 768)\n",
        "      p.add_argument('-SeqDim','--seq_dim', type=int, default = 1024)\n",
        "      p.add_argument('-Weight1', '--w1', type = int, default = 1)\n",
        "      p.add_argument('-Weight2', '--w2', type = int, default = 0.001)\n",
        "      p.add_argument('-Lambda', '--lambda_', type = int, default = 0.5)\n",
        "      p.add_argument('-Simplifier','--sim_model', default='t5-base')\n",
        "      p.add_argument('-Summarizer','--sum_model', default='t5-base')\n",
        "      p.add_argument('-TrainBS','--train_batch_size',type=int, default=6)\n",
        "      p.add_argument('-ValidBS','--valid_batch_size',type=int, default=6)\n",
        "      p.add_argument('-lr','--learning_rate',type=float, default=0.0003)\n",
        "      p.add_argument('-MaxSeqLen','--max_seq_length',type=int, default=256)\n",
        "      p.add_argument('-AdamEps','--adam_epsilon', default=1e-8)\n",
        "      p.add_argument('-WeightDecay','--weight_decay', default = 0.0001)\n",
        "      p.add_argument('-WarmupSteps','--warmup_steps',default=5)\n",
        "      p.add_argument('-NumEpoch','--num_train_epochs',default=3)\n",
        "      p.add_argument('-CosLoss','--custom_loss', default=True)\n",
        "      p.add_argument('-GradAccuSteps','--gradient_accumulation_steps', default=1)\n",
        "      p.add_argument('-GPUs','--n_gpu',default=1) #torch.cuda.device_count()\n",
        "      p.add_argument('-nbSVS','--nb_sanity_val_steps',default = -1)\n",
        "      p.add_argument('-TrainSampleSize','--train_sample_size', default=1)\n",
        "      p.add_argument('-ValidSampleSize','--valid_sample_size', default=1)\n",
        "      p.add_argument('-device','--device', default = 'cuda')\n",
        "      #p.add_argument('-NumBeams','--num_beams', default=8)\n",
        "      return p\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class LoggingCallback(pl.Callback):\n",
        "    def on_validation_end(self, trainer, pl_module):\n",
        "        logger.info(\"***** Validation results *****\")\n",
        "        print(\"***** Validation results *****\")\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "            # Log results\n",
        "            for key in sorted(metrics):\n",
        "                print(key, metrics[key])\n",
        "                if key not in [\"log\", \"progress_bar\"]:\n",
        "                    logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                    print(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "    def on_test_end(self, trainer, pl_module):\n",
        "        logger.info(\"***** Test results *****\")\n",
        "        print(\"***** Test results *****\")\n",
        "\n",
        "        if pl_module.is_logger():\n",
        "            metrics = trainer.callback_metrics\n",
        "\n",
        "            # Log and save results to file\n",
        "            output_test_results_file = os.path.join(pl_module.args.output_dir, \"test_results.txt\")\n",
        "            with open(output_test_results_file, \"w\") as writer:\n",
        "                for key in sorted(metrics):\n",
        "                    if key not in [\"log\", \"progress_bar\"]:\n",
        "                        logger.info(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                        writer.write(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "                        print(\"{} = {}\\n\".format(key, str(metrics[key])))\n",
        "\n",
        "\n",
        "##### build dataset Loader #####\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_len=512, sample_size=1):\n",
        "        self.sample_size = sample_size\n",
        "        print(\"init TrainDataset ...\")\n",
        "        self.source_filepath = get_data_filepath(dataset,'train','complex')\n",
        "        self.target_filepath = get_data_filepath(dataset,'train','simple')\n",
        "        print(\"source_filepath: \", self.source_filepath)\n",
        "        print(\"Initialized dataset done.....\")\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self._load_data()\n",
        "\n",
        "    def _load_data(self):\n",
        "        self.inputs = read_lines(self.source_filepath)\n",
        "        self.targets = read_lines(self.target_filepath)\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.inputs) * self.sample_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        source = self.inputs[index]\n",
        "\n",
        "\n",
        "        source = \"summarize: \" + self.inputs[index]\n",
        "        target = self.targets[index]\n",
        "\n",
        "        tokenized_inputs = self.tokenizer(\n",
        "            [source],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        tokenized_targets = self.tokenizer(\n",
        "            [target],\n",
        "            truncation=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        source_ids = tokenized_inputs[\"input_ids\"].squeeze()\n",
        "        target_ids = tokenized_targets[\"input_ids\"].squeeze()\n",
        "\n",
        "        src_mask = tokenized_inputs[\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "        target_mask = tokenized_targets[\"attention_mask\"].squeeze()  # might need to squeeze\n",
        "\n",
        "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask,\n",
        "                'sources': self.inputs[index], 'targets': [self.targets[index]],\n",
        "                'source': source, 'target': target}\n",
        "\n",
        "\n",
        "class ValDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_len=512, sample_size=1):\n",
        "        self.sample_size = sample_size\n",
        "\n",
        "        self.source_filepath = get_data_filepath(dataset, 'valid', 'complex')\n",
        "        self.target_filepaths = get_data_filepath(dataset, 'valid', 'simple')\n",
        "\n",
        "\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        self._build()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.inputs) * self.sample_size)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return {\"source\": self.inputs[index], \"targets\": self.targets[index]}\n",
        "\n",
        "    def _build(self):\n",
        "        self.inputs = []\n",
        "        self.targets = []\n",
        "\n",
        "        for source in yield_lines(self.source_filepath):\n",
        "            self.inputs.append(source)\n",
        "\n",
        "        for target in yield_lines(self.target_filepaths):\n",
        "            self.targets.append(target)\n",
        "\n",
        "def train(args):\n",
        "    seed_everything(args.seed)\n",
        "\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=args.output_dir,\n",
        "        filename=\"checkpoint-{epoch}\",\n",
        "        monitor=\"val_loss\",\n",
        "        verbose=True,\n",
        "        mode=\"min\",\n",
        "        save_top_k=1\n",
        "    )\n",
        "    bar_callback = pl.callbacks.TQDMProgressBar(refresh_rate=1)\n",
        "    metrics_callback = MetricsCallback()\n",
        "    train_params = dict(\n",
        "        accumulate_grad_batches=args.gradient_accumulation_steps,\n",
        "        max_epochs=args.num_train_epochs,\n",
        "        callbacks=[\n",
        "            LoggingCallback(),\n",
        "            checkpoint_callback, bar_callback],\n",
        "        logger=CSVLogger(f'{args.output_dir}/logs'),\n",
        "        log_every_n_steps= 9,\n",
        "        num_sanity_val_steps=0,  # skip sanity check to save time for debugging purpose\n",
        "        # plugins='ddp_sharded',\n",
        "        #progress_bar_refresh_rate=1,\n",
        "\n",
        "    )\n",
        "\n",
        "    print(\"Initialize model\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = SumSim(args)\n",
        "    model.args.dataset = args.dataset\n",
        "    trainer = pl.Trainer(**train_params)\n",
        "\n",
        "    print(\"Training model\")\n",
        "    trainer.fit(model)\n",
        "\n",
        "    print(\"training finished\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q5ZuzrCWM1t",
        "outputId": "ec224a7a-b945-4817-84e7-12cd3cd8528b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Dataset"
      ],
      "metadata": {
        "id": "5YXTTi8ct0UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists('/content/PSAT'):\n",
        "  if os.path.exists('/content/PSAT.zip'):\n",
        "    !unzip PSAT.zip -d PSAT\n",
        "  else:\n",
        "    print('Please upload the dataset zip file.')"
      ],
      "metadata": {
        "id": "d2bRgN5NE-kN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b575f6-af7e-4176-da07-ba30f8b416e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  PSAT.zip\n",
            " extracting: PSAT/PSAT.train.complex  \n",
            " extracting: PSAT/PSAT.test.complex  \n",
            " extracting: PSAT/PSAT.valid.complex  \n",
            " extracting: PSAT/PSAT.train.simple  \n",
            " extracting: PSAT/PSAT.test.simple   \n",
            " extracting: PSAT/PSAT.valid.simple  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Trainer"
      ],
      "metadata": {
        "id": "mlJacv9Z2QBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVNe4PljPFVd",
        "outputId": "d1bd04ce-ba30-4f5d-a092-2478e584ed16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVaU8eZBrZP_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d72a67b-fd86-42a7-a0b9-747426a39f72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(seed=42, hidden_size=768, seq_dim=1024, w1=1, w2=0.001, lambda_=0.5, sim_model='t5-base', sum_model='t5-base', train_batch_size=6, valid_batch_size=6, learning_rate=0.0003, max_seq_length=256, adam_epsilon=1e-08, weight_decay=0.0001, warmup_steps=5, num_train_epochs=3, custom_loss=True, gradient_accumulation_steps=1, n_gpu=1, nb_sanity_val_steps=-1, train_sample_size=1, valid_sample_size=1, device='cuda')\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "import sys\n",
        "\n",
        "PSAT = 'PSAT'\n",
        "EXP_DIR = '/content/experiments'\n",
        "\n",
        "import time\n",
        "import json\n",
        "import argparse\n",
        "\n",
        "from argparse import ArgumentParser\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "from optuna.integration import PyTorchLightningPruningCallback\n",
        "\n",
        "\n",
        "def parse_arguments():\n",
        "    p = ArgumentParser()\n",
        "\n",
        "    p.add_argument('--seed', type=int, default=42, help='randomization seed')\n",
        "\n",
        "    p = SumSim.add_model_specific_args(p)\n",
        "    args,_ = p.parse_known_args()\n",
        "    return args\n",
        "\n",
        "# Create experiment directory\n",
        "\n",
        "def get_experiment_dir(create_dir=False):\n",
        "    path = os.path.join('/content/experiments')\n",
        "    if os.path.exists(path):\n",
        "      shutil.rmtree(path) # Delete the directory if it exists\n",
        "    if create_dir:\n",
        "        os.makedirs(path)\n",
        "    return path\n",
        "\n",
        "def log_params(filepath, kwargs):\n",
        "    filepath = Path(filepath)\n",
        "    kwargs_str = dict()\n",
        "    for key in kwargs:\n",
        "        kwargs_str[key] = str(kwargs[key])\n",
        "    json.dump(kwargs_str, filepath.open('w'), indent=4)\n",
        "\n",
        "\n",
        "def run_training(args, dataset):\n",
        "\n",
        "    args.output_dir = get_experiment_dir(create_dir=True)\n",
        "    # logging the args\n",
        "    log_params(f\"{args.output_dir}/params.json\", vars(args))\n",
        "\n",
        "    args.dataset = dataset\n",
        "    print(\"Dataset: \",args.dataset)\n",
        "    train(args)\n",
        "\n",
        "dataset = PSAT\n",
        "args = parse_arguments()\n",
        "print(args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run_training(args,dataset)"
      ],
      "metadata": {
        "id": "1VV2Ud8bAj8K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "09f1ee6aa9a5435c84caaead0b6727a0",
            "0e2826f4ea5141c08d475b9fb2bec58b",
            "365afd5bc84c4f1fb78686ca5e39bc0e",
            "83aefa0a92524f40ad70da3a6bfdb9af",
            "bd4fb2a8db3d4e4faf654ebc5a387f04",
            "76e1c7a3f44a4590b6451e32dd3a31c9",
            "89daba12fdde46688b12a4e03f4cec6f",
            "47996cfad12f4986bf7678e3bc078a55",
            "55a5a756d93845b881962c073af4bdeb",
            "6099f81e5dd946f1bbc632df7918bf85",
            "3c10febd1355451d9000edc7856f566c",
            "ce44e4f125074972a923253f66fd81dd",
            "75e7efc4da744721830ec2f07423c9d2",
            "75bd6ea48fcd41da9c2aac58940e60dc",
            "4d6f104c91084db9890dcdc732a7129c",
            "3c4ae50c66eb47b48774f63ed515b5b6",
            "13e530676183454694a3f1759d5e156a",
            "0eddfea23ca6488899fa26f506e36de7",
            "5411d708dd2443b6a2da6618abd55bb3",
            "c5aac075b67b4ca99c0258c007fe8312",
            "10d829a4400449f0803553111843c0b0",
            "009b22f8a5994be6b07c3ed535d32369",
            "b2a945fadaee4d5483fb89b8589bcda3",
            "06387ceba4784faab1c08ff0a06a9c88",
            "c2efbf3949cb427486fcef9898b20332",
            "542c425a0cc6457e9d53c8b823053b46",
            "e4b3e7ad15a44757a31ee61bdd30eba8",
            "13a509b0c1dd4c05ba5a18c890882f1b",
            "4c77f112c58344e59f31679271820811",
            "1dda6da273c948bbbf7c07002d99ff7f",
            "9d4f43ba3f0a4555a95b71b7930c38e1",
            "8764658158f14d8b8f60db9421288b44",
            "a33c5306ba5146c0ae56e534e680ebe6",
            "ee9c10b848114ec594ffe1f43f4e464d",
            "0611a2934d25494596b4453f280bc10f",
            "403ee659325942099ffcb713a7d74fec",
            "e869117731654d4387db14231e17a97b",
            "99f6cecb8de141539f9aba1b755f5a07",
            "37d77ff757f64b78948c861f59048a23",
            "a2814996f8894c53b1101d02a785b4ad",
            "f9f23b650d844e35a99f3acec2deb0da",
            "3c1564849a8245738c8f363dfb312b03",
            "f037d407444549ed88afd99514ea7300",
            "321685d1cada480c9afcf9a084d56e87",
            "b763dc013451472b8779d71f89cfe511",
            "1a993a9dfd5d4893afd7828a3973eb4b",
            "83da4d4ed98448cfaba79cf3dbb97b64",
            "a901710c58db4d988077db16a68f7d17",
            "98a74d0e854d448796907223f4d4c067",
            "06cfa0e173ef4a409b676c72b2fb38be",
            "8b4a90c54bd3401ba1b3c63bf2e60624",
            "7336f93ff05b4b1d9499cb724c984327",
            "97c0ce3a607344929593f531444608d9",
            "b731c0f3c5fb486eae08b7bda36b45f1",
            "7e2a8f5338294cbaa2c4b94a683428c3",
            "50b7ee1c335f4e6bb997cf23b82b94d7",
            "786d7adc1b0f48c3954f2434024da598",
            "71360675a3ce4c21adc2cafb3987e266",
            "f30e01d3594e4ea5a2c2bbce34019a85",
            "6f5fa9d79a1244e69a1db6237ff48cb7",
            "29397120f48d4fdfa86d5cc94ce7ed0f",
            "674b91683da44ad38b730288d8f6004d",
            "cf91a11034bc42428b1aa82e19b7fdfd",
            "86e422c743f941dfb0ceed20bc499b2f",
            "dbc7d718b9ee413884a00212382f2f19",
            "24f3aecc3a684f02a4ada46e27a05435",
            "aab7ef64f3654243b2c278b5582f1b5e",
            "9dcd9195cb53483a9adb9634d11a7fff",
            "f9962f232769452ca3b36d25f487f078",
            "a230afc1087045e787df0eeff8789f46",
            "ecc7cdba46df4e4caa07621c8f278957",
            "a1fa305ebd3249c4be6fac76474ba6fc",
            "700eef54f3494104b2d3b85e2db3d7be",
            "87ac2d941d9c43029883b5e661a8e4a8",
            "3c6a5ff4ab2645e5bebdc1e41aacbbf0",
            "bdad0d82d952430486ff9caba4ccaef6",
            "824d5623223b4235a5f4d92ac4c5e37a",
            "7594b5c124734348815c86c0a0a9778d",
            "05d290ebbc5f413bbd49b2e454a3df28",
            "ad02de50ebc6436db2fe05761e004077",
            "8116217cb11545c3af929f303bd7f89b",
            "fa2ed9617cbd4ed7938f8cb8650f6184",
            "c6404f8cbad54336a77be002bd766f07",
            "3947a524905940118dbf6652257de300",
            "089e14b78f2b41febbc20d7b7c05cdcb",
            "68259be876cd47b9abf621f740381ed0",
            "39a44caa213f4afe9e8f3b5317bd74cd",
            "b0fec4f7689c4acdbd47bb52dfac1962",
            "4466af3c876c43858bb30a51ee50df6d",
            "9d2daa64d0d8496aba78e882f2f5350f",
            "1b1f27d5a82a4da0a1234b42001b1cae",
            "8635f661b3ca4904954c6f2e1c8cb1ec",
            "7197c89977374941935a3fd2d510f896",
            "a890a8b2fcf44e12a77ac6a0f9b2f4b6",
            "6f8ac38e5c8440d197c14a946a39b30a",
            "ff7ed055de414f819f0fbb9765fa575c",
            "ed64cfbac38e443fbad18896c0b4269e",
            "94916c1d14c54595a79bd3b503eef464",
            "8fe2aa79fc1840239e807c439c4ea2f2"
          ]
        },
        "outputId": "13125be2-3812-40c6-ae26-c0a1bea00c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:  PSAT\n",
            "Initialize model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09f1ee6aa9a5435c84caaead0b6727a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce44e4f125074972a923253f66fd81dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b2a945fadaee4d5483fb89b8589bcda3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee9c10b848114ec594ffe1f43f4e464d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b763dc013451472b8779d71f89cfe511"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:lightning_fabric.loggers.csv_logs:Missing logger folder: /content/experiments/logs/lightning_logs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /content/experiments exists and is not empty.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name       | Type                       | Params\n",
            "----------------------------------------------------------\n",
            "0 | summarizer | T5ForConditionalGeneration | 222 M \n",
            "1 | simplifier | T5ForConditionalGeneration | 222 M \n",
            "2 | CosSim     | CosineSimilarity           | 0     \n",
            "3 | relu       | ReLU                       | 0     \n",
            "----------------------------------------------------------\n",
            "445 M     Trainable params\n",
            "0         Non-trainable params\n",
            "445 M     Total params\n",
            "1,783.228 Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "init TrainDataset ...\n",
            "source_filepath:  /content/PSAT/PSAT.train.complex\n",
            "Initialized dataset done.....\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50b7ee1c335f4e6bb997cf23b82b94d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aab7ef64f3654243b2c278b5582f1b5e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:509: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `130` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  33.39281926806589\n",
            "Val_loss 0.666071807319341\n",
            "Sari score:  37.047113128080184\n",
            "Val_loss 0.6295288687191982\n",
            "Sari score:  33.75266384917519\n",
            "Val_loss 0.6624733615082481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 9: 'val_loss' reached 0.66693 (best 0.66693), saving model to '/content/experiments/checkpoint-epoch=0.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  29.03693680204672\n",
            "Val_loss 0.7096306319795328\n",
            "***** Validation results *****\n",
            "train_loss tensor(3.3839, device='cuda:0')\n",
            "train_loss = tensor(3.3839, device='cuda:0')\n",
            "\n",
            "val_loss tensor(0.6669, device='cuda:0')\n",
            "val_loss = tensor(0.6669, device='cuda:0')\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7594b5c124734348815c86c0a0a9778d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  32.40276523300525\n",
            "Val_loss 0.6759723476699475\n",
            "Sari score:  37.31479176845665\n",
            "Val_loss 0.6268520823154335\n",
            "Sari score:  35.38977410166783\n",
            "Val_loss 0.6461022589833216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 18: 'val_loss' reached 0.65891 (best 0.65891), saving model to '/content/experiments/checkpoint-epoch=1.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  31.330277659643674\n",
            "Val_loss 0.6866972234035633\n",
            "***** Validation results *****\n",
            "train_loss tensor(2.7721, device='cuda:0')\n",
            "train_loss = tensor(2.7721, device='cuda:0')\n",
            "\n",
            "val_loss tensor(0.6589, device='cuda:0')\n",
            "val_loss = tensor(0.6589, device='cuda:0')\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4466af3c876c43858bb30a51ee50df6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  35.20336998402194\n",
            "Val_loss 0.6479663001597806\n",
            "Sari score:  40.79872059502531\n",
            "Val_loss 0.5920127940497469\n",
            "Sari score:  37.649617828238355\n",
            "Val_loss 0.6235038217176164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 27: 'val_loss' reached 0.63463 (best 0.63463), saving model to '/content/experiments/checkpoint-epoch=2.ckpt' as top 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sari score:  32.496898325845486\n",
            "Val_loss 0.6750310167415452\n",
            "***** Validation results *****\n",
            "train_loss tensor(2.8091, device='cuda:0')\n",
            "train_loss = tensor(2.8091, device='cuda:0')\n",
            "\n",
            "val_loss tensor(0.6346, device='cuda:0')\n",
            "val_loss = tensor(0.6346, device='cuda:0')\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=3` reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## D-Sari"
      ],
      "metadata": {
        "id": "dBwyNQunrGvx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import sys\n",
        "import nltk\n",
        "import math\n",
        "\n",
        "def ReadInFile(filename):\n",
        "    with open(filename) as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "        lines = [x.strip() for x in lines]\n",
        "\n",
        "    return lines\n",
        "\n",
        "def D_SARIngram(sgrams, cgrams, rgramslist, numref):\n",
        "    rgramsall = [rgram for rgrams in rgramslist for rgram in rgrams]\n",
        "\n",
        "    rgramcounter = Counter(rgramsall)\n",
        "\n",
        "    sgramcounter = Counter(sgrams)\n",
        "\n",
        "    sgramcounter_rep = Counter()\n",
        "\n",
        "    for sgram, scount in sgramcounter.items():\n",
        "        sgramcounter_rep[sgram] = scount * numref\n",
        "\n",
        "    cgramcounter = Counter(cgrams)\n",
        "\n",
        "    cgramcounter_rep = Counter()\n",
        "\n",
        "    for cgram, ccount in cgramcounter.items():\n",
        "        cgramcounter_rep[cgram] = ccount * numref\n",
        "\n",
        "    # KEEP\n",
        "\n",
        "    keepgramcounter_rep = sgramcounter_rep & cgramcounter_rep\n",
        "\n",
        "    keepgramcountergood_rep = keepgramcounter_rep & rgramcounter\n",
        "\n",
        "    keepgramcounterall_rep = sgramcounter_rep & rgramcounter\n",
        "\n",
        "    keeptmpscore1 = 0\n",
        "\n",
        "    keeptmpscore2 = 0\n",
        "\n",
        "    for keepgram in keepgramcountergood_rep:\n",
        "        keeptmpscore1 += keepgramcountergood_rep[keepgram] / keepgramcounter_rep[keepgram]\n",
        "\n",
        "        keeptmpscore2 += keepgramcountergood_rep[keepgram] / keepgramcounterall_rep[keepgram]\n",
        "\n",
        "        # print \"KEEP\", keepgram, keepscore, cgramcounter[keepgram], sgramcounter[keepgram], rgramcounter[keepgram]\n",
        "\n",
        "    keepscore_precision = 0\n",
        "\n",
        "    if len(keepgramcounter_rep) > 0:\n",
        "        keepscore_precision = keeptmpscore1 / len(keepgramcounter_rep)\n",
        "\n",
        "    keepscore_recall = 0\n",
        "\n",
        "    if len(keepgramcounterall_rep) > 0:\n",
        "        keepscore_recall = keeptmpscore2 / len(keepgramcounterall_rep)\n",
        "\n",
        "    keepscore = 0\n",
        "\n",
        "    if keepscore_precision > 0 or keepscore_recall > 0:\n",
        "        keepscore = 2 * keepscore_precision * keepscore_recall / (keepscore_precision + keepscore_recall)\n",
        "\n",
        "    # DELETION\n",
        "\n",
        "    delgramcounter_rep = sgramcounter_rep - cgramcounter_rep\n",
        "\n",
        "    delgramcountergood_rep = delgramcounter_rep - rgramcounter\n",
        "\n",
        "    delgramcounterall_rep = sgramcounter_rep - rgramcounter\n",
        "\n",
        "    deltmpscore1 = 0\n",
        "\n",
        "    deltmpscore2 = 0\n",
        "\n",
        "    for delgram in delgramcountergood_rep:\n",
        "        deltmpscore1 += delgramcountergood_rep[delgram] / delgramcounter_rep[delgram]\n",
        "\n",
        "        deltmpscore2 += delgramcountergood_rep[delgram] / delgramcounterall_rep[delgram]\n",
        "\n",
        "    delscore_precision = 0\n",
        "\n",
        "    if len(delgramcounter_rep) > 0:\n",
        "        delscore_precision = deltmpscore1 / len(delgramcounter_rep)\n",
        "\n",
        "    delscore_recall = 0\n",
        "\n",
        "    if len(delgramcounterall_rep) > 0:\n",
        "        delscore_recall = deltmpscore1 / len(delgramcounterall_rep)\n",
        "\n",
        "    delscore = 0\n",
        "\n",
        "    if delscore_precision > 0 or delscore_recall > 0:\n",
        "        delscore = 2 * delscore_precision * delscore_recall / (delscore_precision + delscore_recall)\n",
        "\n",
        "    # ADDITION\n",
        "\n",
        "    addgramcounter = set(cgramcounter) - set(sgramcounter)\n",
        "\n",
        "    addgramcountergood = set(addgramcounter) & set(rgramcounter)\n",
        "\n",
        "    addgramcounterall = set(rgramcounter) - set(sgramcounter)\n",
        "\n",
        "    addtmpscore = 0\n",
        "\n",
        "    for addgram in addgramcountergood:\n",
        "        addtmpscore += 1\n",
        "\n",
        "    addscore_precision = 0\n",
        "\n",
        "    addscore_recall = 0\n",
        "\n",
        "    if len(addgramcounter) > 0:\n",
        "        addscore_precision = addtmpscore / len(addgramcounter)\n",
        "\n",
        "    if len(addgramcounterall) > 0:\n",
        "        addscore_recall = addtmpscore / len(addgramcounterall)\n",
        "\n",
        "    addscore = 0\n",
        "\n",
        "    if addscore_precision > 0 or addscore_recall > 0:\n",
        "        addscore = 2 * addscore_precision * addscore_recall / (addscore_precision + addscore_recall)\n",
        "\n",
        "    return (keepscore, delscore_precision, addscore)\n",
        "\n",
        "def count_length(ssent, csent, rsents):\n",
        "\n",
        "    input_length = len(ssent.split(\" \"))\n",
        "\n",
        "    output_length = len(csent.split(\" \"))\n",
        "\n",
        "    reference_length = 0\n",
        "\n",
        "    for rsent in rsents:\n",
        "\n",
        "        reference_length += len(rsent.split(\" \"))\n",
        "\n",
        "    reference_length = int(reference_length / len(rsents))\n",
        "\n",
        "    return input_length, reference_length, output_length\n",
        "\n",
        "def sentence_number(csent, rsents):\n",
        "\n",
        "    output_sentence_number = len(nltk.sent_tokenize(csent))\n",
        "\n",
        "    reference_sentence_number = 0\n",
        "\n",
        "    for rsent in rsents:\n",
        "\n",
        "        reference_sentence_number += len(nltk.sent_tokenize(rsent))\n",
        "\n",
        "    reference_sentence_number = int(reference_sentence_number / len(rsents))\n",
        "\n",
        "    return reference_sentence_number, output_sentence_number\n",
        "\n",
        "def D_SARIsent(ssent, csent, rsents):\n",
        "    numref = len(rsents)\n",
        "\n",
        "    s1grams = ssent.lower().split(\" \")\n",
        "\n",
        "    c1grams = csent.lower().split(\" \")\n",
        "\n",
        "    s2grams = []\n",
        "\n",
        "    c2grams = []\n",
        "\n",
        "    s3grams = []\n",
        "\n",
        "    c3grams = []\n",
        "\n",
        "    s4grams = []\n",
        "\n",
        "    c4grams = []\n",
        "\n",
        "    r1gramslist = []\n",
        "\n",
        "    r2gramslist = []\n",
        "\n",
        "    r3gramslist = []\n",
        "\n",
        "    r4gramslist = []\n",
        "\n",
        "    for rsent in rsents:\n",
        "\n",
        "        r1grams = rsent.lower().split(\" \")\n",
        "\n",
        "        r2grams = []\n",
        "\n",
        "        r3grams = []\n",
        "\n",
        "        r4grams = []\n",
        "\n",
        "        r1gramslist.append(r1grams)\n",
        "\n",
        "        for i in range(0, len(r1grams) - 1):\n",
        "\n",
        "            if i < len(r1grams) - 1:\n",
        "                r2gram = r1grams[i] + \" \" + r1grams[i + 1]\n",
        "\n",
        "                r2grams.append(r2gram)\n",
        "\n",
        "            if i < len(r1grams) - 2:\n",
        "                r3gram = r1grams[i] + \" \" + r1grams[i + 1] + \" \" + r1grams[i + 2]\n",
        "\n",
        "                r3grams.append(r3gram)\n",
        "\n",
        "            if i < len(r1grams) - 3:\n",
        "                r4gram = r1grams[i] + \" \" + r1grams[i + 1] + \" \" + r1grams[i + 2] + \" \" + r1grams[i + 3]\n",
        "\n",
        "                r4grams.append(r4gram)\n",
        "\n",
        "        r2gramslist.append(r2grams)\n",
        "\n",
        "        r3gramslist.append(r3grams)\n",
        "\n",
        "        r4gramslist.append(r4grams)\n",
        "\n",
        "    for i in range(0, len(s1grams) - 1):\n",
        "\n",
        "        if i < len(s1grams) - 1:\n",
        "            s2gram = s1grams[i] + \" \" + s1grams[i + 1]\n",
        "\n",
        "            s2grams.append(s2gram)\n",
        "\n",
        "        if i < len(s1grams) - 2:\n",
        "            s3gram = s1grams[i] + \" \" + s1grams[i + 1] + \" \" + s1grams[i + 2]\n",
        "\n",
        "            s3grams.append(s3gram)\n",
        "\n",
        "        if i < len(s1grams) - 3:\n",
        "            s4gram = s1grams[i] + \" \" + s1grams[i + 1] + \" \" + s1grams[i + 2] + \" \" + s1grams[i + 3]\n",
        "\n",
        "            s4grams.append(s4gram)\n",
        "\n",
        "    for i in range(0, len(c1grams) - 1):\n",
        "\n",
        "        if i < len(c1grams) - 1:\n",
        "            c2gram = c1grams[i] + \" \" + c1grams[i + 1]\n",
        "\n",
        "            c2grams.append(c2gram)\n",
        "\n",
        "        if i < len(c1grams) - 2:\n",
        "            c3gram = c1grams[i] + \" \" + c1grams[i + 1] + \" \" + c1grams[i + 2]\n",
        "\n",
        "            c3grams.append(c3gram)\n",
        "\n",
        "        if i < len(c1grams) - 3:\n",
        "            c4gram = c1grams[i] + \" \" + c1grams[i + 1] + \" \" + c1grams[i + 2] + \" \" + c1grams[i + 3]\n",
        "\n",
        "            c4grams.append(c4gram)\n",
        "\n",
        "    (keep1score, del1score, add1score) = D_SARIngram(s1grams, c1grams, r1gramslist, numref)\n",
        "\n",
        "    (keep2score, del2score, add2score) = D_SARIngram(s2grams, c2grams, r2gramslist, numref)\n",
        "\n",
        "    (keep3score, del3score, add3score) = D_SARIngram(s3grams, c3grams, r3gramslist, numref)\n",
        "\n",
        "    (keep4score, del4score, add4score) = D_SARIngram(s4grams, c4grams, r4gramslist, numref)\n",
        "\n",
        "    avgkeepscore = sum([keep1score, keep2score, keep3score, keep4score]) / 4\n",
        "\n",
        "    avgdelscore = sum([del1score, del2score, del3score, del4score]) / 4\n",
        "\n",
        "    avgaddscore = sum([add1score, add2score, add3score, add4score]) / 4\n",
        "\n",
        "    input_length, reference_length, output_length = count_length(ssent, csent, rsents)\n",
        "\n",
        "    reference_sentence_number, output_sentence_number = sentence_number(csent, rsents)\n",
        "\n",
        "    if output_length >= reference_length:\n",
        "\n",
        "        LP_1 = 1\n",
        "\n",
        "    else:\n",
        "\n",
        "        LP_1 = math.exp((output_length - reference_length) / output_length)\n",
        "\n",
        "    if output_length > reference_length:\n",
        "\n",
        "        LP_2 = math.exp((reference_length - output_length) / max(input_length - reference_length, 1))\n",
        "\n",
        "    else:\n",
        "\n",
        "        LP_2 = 1\n",
        "\n",
        "    SLP = math.exp(-abs(reference_sentence_number - output_sentence_number) / max(reference_sentence_number,\n",
        "                                                                                  output_sentence_number))\n",
        "\n",
        "    avgkeepscore = avgkeepscore * LP_2 * SLP\n",
        "\n",
        "    avgaddscore = avgaddscore * LP_1\n",
        "\n",
        "    avgdelscore = avgdelscore * LP_2\n",
        "\n",
        "    finalscore = (avgkeepscore + avgdelscore + avgaddscore) / 3\n",
        "\n",
        "    return finalscore, avgkeepscore, avgdelscore, avgaddscore\n",
        "\n",
        "def D_SARI_file(ssent, csent, rsents):\n",
        "    D_SARI = 0\n",
        "    for st, ct, rt in zip(ssent, csent, rsents):\n",
        "        D_SARI += D_SARIsent(st, ct, [rt])[0]\n",
        "    return 100 * D_SARI / len(ssent)"
      ],
      "metadata": {
        "id": "iRIF-deZrCKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import click\n",
        "from easse.utils.resources import get_orig_sents, get_refs_sents\n",
        "\n",
        "def get_sys_sents(test_set, sys_sents_path=None):\n",
        "    # Get system sentences to be evaluated\n",
        "    if sys_sents_path is not None:\n",
        "        return read_lines(sys_sents_path)\n",
        "    else:\n",
        "        # read the system output\n",
        "        with click.get_text_stream(\"stdin\", encoding=\"utf-8\") as system_output_file:\n",
        "            return system_output_file.read().splitlines()\n",
        "\n",
        "\n",
        "def get_orig_and_refs_sents(test_set, orig_sents_path=None, refs_sents_paths=None):\n",
        "    # Get original and reference sentences\n",
        "    if test_set == \"custom\":\n",
        "        assert orig_sents_path is not None\n",
        "        assert refs_sents_paths is not None\n",
        "\n",
        "        orig_sents = read_lines(orig_sents_path)\n",
        "        refs_sents = [read_lines(refs_sents_paths)]\n",
        "    else:\n",
        "        orig_sents = get_orig_sents(test_set)\n",
        "        refs_sents = get_refs_sents(test_set)\n",
        "    return orig_sents, refs_sents"
      ],
      "metadata": {
        "id": "LTl-6BEwBVaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "clnjIc4VCdb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import sys\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from easse.cli import evaluate_system_output\n",
        "from easse.report import get_all_scores\n",
        "from contextlib import contextmanager\n",
        "import json\n",
        "import torch\n",
        "from easse.sari import corpus_sari\n",
        "import time\n",
        "#from googletrans import Translator\n",
        "\n",
        "\n",
        "@contextmanager\n",
        "def log_stdout(filepath, mute_stdout=False):\n",
        "    '''Context manager to write both to stdout and to a file'''\n",
        "\n",
        "    class MultipleStreamsWriter:\n",
        "        def __init__(self, streams):\n",
        "            self.streams = streams\n",
        "\n",
        "        def write(self, message):\n",
        "            for stream in self.streams:\n",
        "                stream.write(message)\n",
        "\n",
        "        def flush(self):\n",
        "            for stream in self.streams:\n",
        "                stream.flush()\n",
        "\n",
        "    save_stdout = sys.stdout\n",
        "    log_file = open(filepath, 'w')\n",
        "    if mute_stdout:\n",
        "        sys.stdout = MultipleStreamsWriter([log_file])  # Write to file only\n",
        "    else:\n",
        "        sys.stdout = MultipleStreamsWriter([save_stdout, log_file])  # Write to both stdout and file\n",
        "    try:\n",
        "        yield\n",
        "    finally:\n",
        "        sys.stdout = save_stdout\n",
        "        log_file.close()\n",
        "\n",
        "# set random seed universal\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "set_seed(42)\n",
        "model_dir = None\n",
        "_model_dirname = None\n",
        "max_len = 256\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using {device}')\n",
        "\n",
        "#### Joint model ####\n",
        "Model = SumSim.load_from_checkpoint('/content/experiments/checkpoint-epoch=2.ckpt').to(device)\n",
        "summarizer = Model.summarizer.to(device)\n",
        "simplifier = Model.simplifier.to(device)\n",
        "summarizer_tokenizer = Model.summarizer_tokenizer\n",
        "simplifier_tokenizer = Model.simplifier_tokenizer\n",
        "#### Joint model ####\n",
        "\n",
        "\n",
        "def generate(sentence, preprocessor=None):\n",
        "    '''\n",
        "    This function is for Joint model to generate/predict\n",
        "    '''\n",
        "\n",
        "    sentence = 'summarize: ' + sentence\n",
        "\n",
        "    encoding = summarizer_tokenizer(\n",
        "        [sentence],\n",
        "        max_length = 512,\n",
        "        truncation = True,\n",
        "        padding = 'max_length',\n",
        "        return_tensors = 'pt',\n",
        "    )\n",
        "\n",
        "    summary_ids = summarizer.generate(\n",
        "        encoding['input_ids'].to(device),\n",
        "        num_beams = 15,\n",
        "        min_length = 30,\n",
        "        max_length = 512,\n",
        "        top_k = 80, top_p = 0.97\n",
        "    ).to(device)\n",
        "\n",
        "    for i, summary_id in enumerate(summary_ids):\n",
        "        add_tokens = torch.tensor([18356, 10]).to(device)\n",
        "        summary_ids[i,:] = torch.cat((summary_id, add_tokens), dim=0)[:-2]\n",
        "\n",
        "    summary_atten_mask = torch.ones(summary_ids.shape).to(device)\n",
        "    summary_atten_mask[summary_ids[:,:] == summarizer_tokenizer.pad_token_id] = 0\n",
        "\n",
        "    beam_outputs = simplifier.generate(\n",
        "        input_ids = summary_ids,\n",
        "        attention_mask = summary_atten_mask,\n",
        "        do_sample = True,\n",
        "        max_length = 256,\n",
        "        num_beams = 5, #16\n",
        "        top_k = 80,  #120\n",
        "        top_p = 0.95, #0.95\n",
        "        early_stopping = True,\n",
        "        num_return_sequences = 1,\n",
        "    )\n",
        "\n",
        "    sent = simplifier_tokenizer.decode(beam_outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    return sent\n",
        "\n",
        "\n",
        "def evaluate(orig_filepath, sys_filepath, ref_filepaths):\n",
        "    orig_sents = read_lines(orig_filepath)\n",
        "    refs_sents = [read_lines(ref_filepaths)]\n",
        "\n",
        "    return corpus_sari(orig_sents, read_lines(sys_filepath), refs_sents)\n",
        "\n",
        "def back_translation(text):\n",
        "    X = translator.translate(text, dest = 'de')\n",
        "    return translator.translate(X.text, dest = 'en').text\n",
        "\n",
        "\n",
        "def simplify_file(complex_filepath, output_filepath, features_kwargs=None, model_dirname=None, post_processing=True):\n",
        "    '''\n",
        "    Obtain the simplified sentences (predictions) from the original complex sentences.\n",
        "    '''\n",
        "\n",
        "    total_lines = count_line(complex_filepath)\n",
        "    print(complex_filepath)\n",
        "    print(complex_filepath.stem)\n",
        "\n",
        "    output_file = Path(output_filepath).open(\"w\")\n",
        "\n",
        "    for n_line, complex_sent in enumerate(yield_lines(complex_filepath), start=1):\n",
        "        output_sents = generate(complex_sent, preprocessor=None)\n",
        "\n",
        "\n",
        "        print(f\"{n_line}/{total_lines}\", \" : \", output_sents)\n",
        "        if output_sents:\n",
        "            output_file.write(output_sents + \"\\n\")\n",
        "        else:\n",
        "            output_file.write(\"\\n\")\n",
        "    output_file.close()\n",
        "\n",
        "    if post_processing: post_process(output_filepath)\n",
        "\n",
        "def post_process(filepath):\n",
        "    lines = []\n",
        "    for line in yield_lines(filepath):\n",
        "        lines.append(line.replace(\"''\", '\"'))\n",
        "    write_lines(lines, filepath)\n",
        "\n",
        "def evaluate_on_PSAT(phase, features_kwargs=None,  model_dirname = None):\n",
        "    dataset = PSAT\n",
        "    output_dir = '/content/outputs'\n",
        "\n",
        "    if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "    output_score_filepath = f'{output_dir}/score_{dataset}_{phase}.log.txt'\n",
        "    complex_filepath = get_data_filepath(dataset, phase, 'complex')\n",
        "\n",
        "    if not os.path.exists(output_score_filepath) or count_line(output_score_filepath)==0:\n",
        "        start_time = time.time()\n",
        "        complex_filepath =get_data_filepath(dataset, phase, 'complex')\n",
        "        complex_filepath = Path(complex_filepath)\n",
        "\n",
        "        pred_filepath = f'{output_dir}/{complex_filepath.stem}.txt'\n",
        "        ref_filepaths = get_data_filepath(dataset, phase, 'simple')\n",
        "\n",
        "        if os.path.exists(pred_filepath) and count_line(pred_filepath)==count_line(complex_filepath):\n",
        "            print(\"File is already processed.\")\n",
        "        else:\n",
        "            simplify_file(complex_filepath, pred_filepath, features_kwargs, model_dirname)\n",
        "\n",
        "        print(\"Evaluate: \", pred_filepath)\n",
        "\n",
        "        with log_stdout(output_score_filepath):\n",
        "\n",
        "            scores  = evaluate_system_output(test_set='custom',\n",
        "                                             sys_sents_path=str(pred_filepath),\n",
        "                                             orig_sents_path=str(complex_filepath),\n",
        "                                             refs_sents_paths=str(ref_filepaths),metrics = ['bleu', 'sari', 'fkgl'] )\n",
        "\n",
        "            sys_sents = get_sys_sents(test_set = 'custom', sys_sents_path=str(pred_filepath))\n",
        "            orig_sents, refs_sents = get_orig_and_refs_sents(test_set = 'custom',\n",
        "                                                             orig_sents_path = str(complex_filepath),\n",
        "                                                             refs_sents_paths = str(ref_filepaths))\n",
        "\n",
        "\n",
        "            print(\"SARI: {:.2f}\\t D-SARI: {:.2f} \\t BLEU: {:.2f} \\t FKGL: {:.2f} \".format(scores['sari'],\n",
        "                                                                                          D_SARI_file(orig_sents,sys_sents,refs_sents[0],),\n",
        "                                                                                          scores['bleu'],\n",
        "                                                                                          scores['fkgl']))\n",
        "\n",
        "            print(\"Execution time: --- %s seconds ---\" % (time.time() - start_time))\n",
        "            return None\n",
        "    else:\n",
        "        print(\"Already exists: \", output_score_filepath)\n",
        "        print(\"\".join(read_lines(output_score_filepath)))\n",
        "\n",
        "evaluate_on_PSAT(phase='test', features_kwargs=None, model_dirname=None)"
      ],
      "metadata": {
        "id": "9Wrv8iUJqsH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bad2a2d-49c6-4d52-f619-630185787084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda\n",
            "/content/PSAT/PSAT.test.complex\n",
            "PSAT.test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.97` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:509: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `80` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/33  :  Official high school transcripts from non-US institutions must be sent electronically or in a sealed envelope. If you are eligible to pay instate tuition, you must provide proof of Florida residency. If you are eligible to pay instate tuition, you must provide proof of residency. If you are eligible to pay instate tuition, you must provide proof of residency. If you are eligible to pay instate tuition, you must provide proof of residency. If you are eligible to pay instate tuition, you must provide proof of residency. If you are eligible to pay instate tuition, you must provide proof of residency. If you are eligible to pay instate tuition, you must provide proof of residency, you must provide proof of residency, you must submit a proof of residency, you must provide proof of residency, you must provide proof of residency, you must provide proof of residency, you must provide proof of residency, you must provide proof of residency, you must submit a proof of residency, you must submit a valid proof of residency, you must submit a valid proof of residency, you must submit a valid proof of residency, you must submit a valid proof of residency, you must submit a valid proof of residency, you must submit\n",
            "2/33  :  The first semester of high school coursework is six semesters of high school coursework. You are also applying for merit-based university scholarships. You may apply for admission to Missouri S&T after completing six semesters of high school coursework. You may apply for admission to Missouri S&T after completing six semesters of high school coursework. You may apply for admission to Missouri S&T after completing six semesters of high school coursework. You may also apply for merit-based university scholarships. You may also apply for merit-based university scholarships. You can apply for admissions. You may apply for admissions. You can apply for admissions. You can apply for admissions. You can apply for admissions. You can apply for admissions. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admission. You can apply for admissions. You can apply for admission. You can apply for\n",
            "3/33  :  SAT or American College Testing Program (ACT) score report. You may submit a request to have your results electronically submitted to Radford University. You may submit a request to have your results electronically submitted to Radford University. You may also submit a request to have your results electronically submitted to Radford University. You may also submit a request to have your results electronically submitted to Radford University. You may also submit a request to have your results electronically submitted to Radford University. You may submit a request to have your results electronically submitted to Radford University.\n",
            "4/33  :  if you attended a private high school in a foreign country, you must complete the Test of English as a Foreign Language (TOEFL) or IELTS. If you attended a private high school in a foreign country, you must submit a high school certification form. If you attended a private high school in a foreign country, you must submit a high school certification form. If you attended a private high school in a foreign country, you must submit a high school certification form. If you attended a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school in a private high school\n",
            "5/33  :  Applicants must submit an application through the American Association of Colleges of Osteopathic Medicine Application Service (AACOMAS). Applicants must submit an application through the AACOMAS Application Service (AACOMAS). Applicants must submit an application through the American Association of Colleges of Osteopathic Medicine Application Service (AACOMAS). Applicants must submit an official MCAT score within 3 calendar years of the desired date of matriculation. Applicants must submit an official transcript. Applicants must submit an official transcript. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts. Official transcripts.\n",
            "6/33  :  a fee of $115 must be sent upon certification and submission of the supplemental application. The application fee is $115. The fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115. The application fee is $115.\n",
            "7/33  :  The Common Application can be submitted to multiple colleges, with an additional fee for each college. Self-report your high school grades. If you have questions, you can contact the Admissions Office. You can also contact the Admissions Office. If you have questions, you can contact the Admissions Office. You can contact the Admissions Office. You can contact the Admissions Office. You can contact the Admissions Office. You can contact the Admissions Office. You can contact the Admissions Office. You can contact the Admissions Office. You can contact the Common Application. The Common Application. You can contact the Common Application.\n",
            "8/33  :  if you have questions about your application please visit the FAQs page. The entire BYUH application is online and available at apply.lds.org. The entire application is online and available at apply.lds.org. There are different requirements for Domestic students and International students. There are different requirements for Domestic students and International students. There are different requirements for Domestic students and International students. If you have questions about your application please visit the FAQs page. If you have questions about your application please visit the FAQs page. If you have questions about your application please visit the FAQs page.\n",
            "9/33  :  n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/a n/\n",
            "10/33  :  If english is not your first language, submit TOEFL or IELTS scores. You can submit your application through the Chaminade website or through Common Application, as early as September 1. You can submit your application through the Chaminade website or through Common Application, as early as September 1. You can submit your application through the Chaminade website or through Common Application, as early as September 1. You can submit your application through the Chaminade website or through Common Application, as early as September 1.\n",
            "11/33  :  if you opt to send via U.S. mail, please remit payment to: Student Accounts College of Biblical Studies 7000 Regency Square Blvd. Houston, Texas 77036. If you opt to send via U.S. mail, please remit payment to: Student Accounts College of Biblical Studies 7000 Regency Square Blvd. Houston, Texas 77036. If you opt to send via U.S. mail, please remit payment to: Student Accounts College of Biblical Studies 7000 Regency Square Blvd.\n",
            "12/33  :  The College strongly encourages students to call the Office of Admission at (800) 210-7900 to arrange to meet with an Admission Counselor and to tour the campus. Official high school transcripts from all schools attended Official SAT or ACT scores (optional) Required essay (1-2 pages) Two letters of recommendation (1-2 pages) Required essay (1-2 pages) Required essay (1-2 pages) Required essay (1-2 pages) Required essay (1-2 pages) Required essay (1-2 pages) Required essay (1-2 pages) Required essay (1-2 pages) Required essay (1-2 pages) Required essay(s) Required essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(s) Required Essay(\n",
            "13/33  :  Online application is the most quick and easy way to apply. You can also submit a printable application (pdf) if you prefer to submit a hard copy. You can also submit a printable application (pdf) if you prefer to submit a hard copy. You can also submit a printable application (pdf). You can also submit a printable application (pdf). You can also submit a printable application (pdf) if you prefer to submit a hard copy. You can also submit a printable application (pdf). You can submit a printable application (pdf).\n",
            "14/33  :  How to Apply: You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application using the Common Application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit an application. You must submit\n",
            "15/33  :  Applicants must submit a $25.00 nonrefundable application processing fee. International applicants must submit a $55.00 nonrefundable application processing fee. Readmit applicants must submit a $25.00 nonrefundable application processing fee. Readmit applicants must submit a $25.00 nonrefundable application processing fee. Readmit applicants must submit a $25.00 nonrefundable application processing fee. Readmit applicants must submit a $55.00 nonrefundable application processing fee. Readmit applicants must submit a $25.00 nonrefundable application fee. Readmit applicants must submit a $25.00 nonrefundable application fee.\n",
            "16/33  :  The application deadline is 12/1 Early action deadline 3/1 Regular admission priority date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate response date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate reply date 5/1 National candidate response date 5/1 National candidate reply date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate reply date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date 5/1 National candidate response date\n",
            "17/33  :  if you’re a painter, we want to see your work! If you’re a painter, we want to see your work! If you’re a painter, we want to see your work! If you’re a painter, we want to see your work! If you’re a painter, we want to see your work! If you’re a painter, we want to see your work! If you’re a painter, we want to see your work!\n",
            "18/33  :  CERTAIN APPLICATIONS ALSO REQUIRE ONE OR MORE OF THE FOLLOWING MATERIALS. OFFICIAL TRANSCRIPTS All transcripts may be submitted via e-mail, fax, or regular mail. OFFICIAL TRANSCRIPTS may be submitted via e-mail, fax, or regular mail. OFFICIAL TRANSCRIPTS. If you are a Montserrat resident, you must submit an application. If you are a Montserrat resident, you must submit an application. OFFICIAL TRANSCRIPTS. You must submit an application. OFFICIAL TRANSCRIPTS. You can submit an application. You can submit an application.\n",
            "19/33  :  SAT/ACT scores are required to be submitted if they wish to be considered for cooperative academic programs. All applicants must submit a letter of recommendation from their high school principal. All applicants must submit a letter of recommendation from their high school principal. All applicants must submit a letter of recommendation from their high school principal. All applicants must submit a letter of recommendation from their high school principal. All applicants must submit a letter of recommendation from their high school principal. All applicants must submit a letter of recommendation from their high school principal. All applicants must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of recommendation. You must submit a letter of\n",
            "20/33  :  Applicants must submit an application to the College of Pharmacy or the College of Pharmacy. Applicants must submit an application to the College of Pharmacy or the College of Pharmacy. Applicants must submit an application to the College of Pharmacy or the College of Pharmacy. You must submit an application to the College of Pharmacy or the College of Pharmacy. You will receive an email with a temporary PIN. You will receive an email with a temporary PIN. You will receive an email with a temporary PIN. You will receive an email with a temporary PIN. You will receive a letter of recommendation. You will receive a letter of recommendation. You will receive a letter of recommendation. You will receive a letter of recommendation. You will receive a letter of recommendation. You will receive a letter of recommendation. You will receive a letter of recommendation. You will be a letter of recommendation. You will be a letter of recommendation. You will be a letter of recommendation. You will be a letter of recommendation. You will be a letter of recommendation. You will be a letter of recommendation. You will be a letter of recommendation. You will be a letter of recommendation. You will be a\n",
            "21/33  :  Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application Common Application\n",
            "22/33  :  How to Apply: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application using the following steps: You must submit an application. You must submit an application. You must submit an application. You must submit a copy of the following: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You must submit: You\n",
            "23/33  :  ACT and/or SAT scores are considered superscores in admissions and scholarship decisions. ACT and/or SAT scores are not considered superscores. ACT and/or SAT scores are not considered superscores. ACT and/or SAT scores are not considered superscores. ACT and/or SAT scores are not considered superscores. ACT and/or SAT scores are not considered superscores. SAT scores are not considered superscores are not considered superscores are not considered superscores are not considered superscores are not considered superscores are not considered.\n",
            "24/33  :  Richmond Superscores both the ACT and the SAT administrations. The final test dates accepted for Regular Decision are the December ACT and SAT administrations; scores from the February SAT administration may be self-reported via the Spider Portal.\n",
            "25/33  :  Official transcript sent by the high school, listing all courses and grades received to date; Official General Education Diploma (GED); Official High School Equivalency Test (HiSET) if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official GED if homeschooled; Official High School Equivalency if homeschooled; Official GED if homeschooled; Official High School Equivalency if homeschooled; Official High School Equivalency if homeschooled; Official High School Equivalency if homeschooled; Official High School Equivalency if homeschool\n",
            "26/33  :  Homeschooled students must present a diploma that meets the requirements of the state in which it was issued. Homeschooled students must present a diploma that meets the requirements of the state in which it was issued. Homeschooled students must present a diploma that meets the requirements of the state in which it was issued. Homeschooled students must present a diploma that meets the requirements of the state in which it was issued. Homeschooled students must present a diploma that meets the requirements of the state in which it was issued. Homeschooled students must submit a diploma that meets the requirements of the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which the state in which they are required. The state in which they are required.\n",
            "27/33  :  a personal essay and a short, Wellesley-specific essay are required to be submitted. a personal essay and a short, Wellesley-specific essay. a personal essay and a short, Wellesley-specific essay. a personal essay and a short, Wellesley-specific essay. a personal essay. a personal essay. a short, Wellesley-specific essay. a personal essay. a personal essay. a short, Wellesley-specific essay. If you plan to apply for financial aid. You can apply for financial aid. You can apply for financial aid. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You can apply for financial aid application. You\n",
            "28/33  :  You can find your checklist here. $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1). $0 if you apply Regular Decision by Dec. 1). $0 if you apply Regular Decision by Dec. 1). $50 application fee ($0 if you apply Regular Decision by Dec. 1) Application Fee(s)((s)(s)(s)(s)(s)(s)(s)(s)(s)(s)(s)(s)(s)(s)(s)\n",
            "29/33  :  How to Apply: You must submit an application using the following factors: grade point average, ACT/SAT score, type of college prep courses, and trend of grades. You can submit an application using the following factors: grade point average, ACT/SAT score, type of college prep courses, and trend of grades. You can submit an application using the following factors: grade point average, ACT/SAT score, type of college prep courses and trend of grades. You can submit an application using the following factors: grade point average, ACT/SAT score, grade point average, grade point average, grade point average, type of college prep courses, type of college prep courses, type of college prep courses, type of college prep courses, grade point average, grade point average, grade point average, grade point average, ACT/SAT score, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade point average, grade\n",
            "30/33  :  Applicants must submit a $50 application fee. Official high school transcript(s). Official GED High school diploma(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official college transcript(s). Official\n",
            "31/33  :  Official school transcripts Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of recommendation Letters of\n",
            "32/33  :  UIW will begin making admissions decisions for Fall 2020 beginning Aug. 1, 2019. You can request your score be sent to the Office of Admissions by listing our code when you register for the Fall 2020 exam. You can request your score be sent to the Office of Admissions by listing our code when you register for the Fall 2020 exam. You can request your score be sent to the Office of Admissions. You can request your score to be sent to the Office of Admissions. You can request your score to be sent to the Office of Admissions office. You can request a score report.\n",
            "33/33  :  Sweet Briar accepts the General Education Diploma (GED) in lieu of a high school diploma. You are considered a first-time first-year student if you are a current high school senior or have not attended college since graduating from high school. You are considered a first-time first-year student if you are a current high school senior or have not attended college since graduating from high school. You are considered a first-time first-year student if you are a current high school senior. You are considered a first-year student if you are considered a first-year student if you are considered a first-year student if you are considered a first-year student if you are a first-year student if you are a current high school senior. You are a first-year student if you are a first-year student if you are a first-year student if you are a first-year student a first-year student a first-year student a first-year student a first-year student a first-year student a first-year student a first-year\n",
            "Evaluate:  /content/outputs/PSAT.test.txt\n",
            "SARI: 34.53\t D-SARI: 21.28 \t BLEU: 6.53 \t FKGL: 7.17 \n",
            "Execution time: --- 238.8666353225708 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Outputs"
      ],
      "metadata": {
        "id": "jA17zlpmuPb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the zip file\n",
        "zip_file_path = '/content/outputs.zip'\n",
        "\n",
        "if os.path.exists(zip_file_path):\n",
        "    os.remove(zip_file_path)\n",
        "\n",
        "# Compress the folder into a zip file\n",
        "!zip -r {zip_file_path} {os.path.basename('/content/outputs')}"
      ],
      "metadata": {
        "id": "X0eSICdf4UhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2babd202-d12a-454d-e535-669f1ee1ab18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: outputs/ (stored 0%)\n",
            "  adding: outputs/score_PSAT_test.log.txt (deflated 7%)\n",
            "  adding: outputs/PSAT.test.txt (deflated 91%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(f'/content/outputs.zip')"
      ],
      "metadata": {
        "id": "5CBSoj334r5J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "39b89b39-777b-4391-a320-3d611ae96aa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d9ec600c-7bf3-480b-a20b-af5a5ea56313\", \"outputs.zip\", 3475)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References"
      ],
      "metadata": {
        "id": "tF3aXDHjI2_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  [SimSum GitHub Code](https://github.com/epfml/easy-summary/tree/main)"
      ],
      "metadata": {
        "id": "1-Qzd7f9Jyjd"
      }
    }
  ]
}